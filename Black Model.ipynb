{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\serpo\\Documents\\Python\\Black\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:258: UserWarning: Failed to initialize NumPy: No module named 'numpy.core._exceptions' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_model(F, K, T, sigma, option_type='call'):\n",
    "\t# Parameters\n",
    "\td1 = (np.log(F / K) + (sigma**2 / 2) * T) / (sigma * np.sqrt(T))\n",
    "\td2 = d1 - sigma * np.sqrt(T)\n",
    "\t\n",
    "\t# Discount factor (assuming risk-free rate is 0)\n",
    "\tDF_T = 1\n",
    "\t\n",
    "\tif option_type == 'call':\n",
    "\t\treturn DF_T * (F * norm.cdf(d1) - K * norm.cdf(d2))\n",
    "\telif option_type == 'put':\n",
    "\t\treturn DF_T * (K * norm.cdf(-d2) - F * norm.cdf(-d1))\n",
    "\telse:\n",
    "\t\traise ValueError(\"option_type must be 'call' or 'put'\")\n",
    "\n",
    "def generate_data(num_samples, S=1):\n",
    "\t# Generate random parameters\n",
    "\tK = np.random.uniform(1, 2.5, num_samples)\n",
    "\tT = np.random.uniform(0.004, 4, num_samples)\n",
    "\tsigma = np.random.uniform(0.1, 0.5, num_samples)\n",
    "\n",
    "\tcall_prices = black_model(S, K, T, sigma, option_type='call')\n",
    "\t\n",
    "\t# Prepare input data matrix X\n",
    "\tX = np.vstack((K, T, np.log(K), sigma * np.sqrt(T), sigma**2 * T)).T\n",
    "\ty = call_prices\n",
    "\t\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_static_test_data(num_test_samples=100000):\n",
    "\tX_test, y_test = generate_data(num_samples=num_test_samples)\n",
    "\n",
    "\t# Преобразуем в тензоры\n",
    "\tX_test_tensor = torch.tensor(X_test, dtype=torch.float64, requires_grad=True)\n",
    "\ty_test_tensor = torch.tensor(y_test, dtype=torch.float64, requires_grad=True).unsqueeze(1)\n",
    "\n",
    "\t# Сохраняем данные\n",
    "\ttorch.save((X_test_tensor, y_test_tensor), 'static_test_data.pt')\n",
    "\n",
    "def load_static_test_data():\n",
    "\t# Загружаем данные из файла\n",
    "\tX_test_tensor, y_test_tensor = torch.load('static_test_data.pt')\n",
    "\n",
    "\treturn X_test_tensor, y_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_prepare_training_data(num_train_samples=1000000, batch_size=128):\n",
    "\tX_train, y_train = generate_data(num_samples=num_train_samples)\n",
    "\n",
    "\tX_train_tensor = torch.tensor(X_train, dtype=torch.float64)\n",
    "\ty_train_tensor = torch.tensor(y_train, dtype=torch.float64).unsqueeze(1)\n",
    "\n",
    "\ttrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\ttrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\treturn train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackScholesNet(nn.Module):\n",
    "\tdef __init__(self, input_size=1, hidden_size=128, output_size=1, dropout_p = 0.33):\n",
    "\t\tsuper(BlackScholesNet, self).__init__()\n",
    "\t\tself.fc1 = nn.Linear(input_size, hidden_size, dtype=torch.float64)\n",
    "\t\tself.bn1 = nn.BatchNorm1d(hidden_size, dtype=torch.float64)  # Batch Normalization\n",
    "\t\tself.fc2 = nn.Linear(hidden_size, hidden_size, dtype=torch.float64)\n",
    "\t\tself.bn2 = nn.BatchNorm1d(hidden_size, dtype=torch.float64)  # Batch Normalization\n",
    "\t\tself.fc3 = nn.Linear(hidden_size, output_size, dtype=torch.float64)\n",
    "\t\tself.dropout = nn.Dropout(p=dropout_p)  # Dropout for regularization\n",
    "\t\tself.name = 'Black Model'\n",
    "\n",
    "\tdef forward(self, x, K):\n",
    "\t\tx = F.tanh(self.bn1(self.fc1(x)))  # Tanh and Batch Normalization\n",
    "\t\tx = self.dropout(x)  # Dropout\n",
    "\t\tx = F.tanh(self.bn2(self.fc2(x)))  # Tanh and Normalization\n",
    "\t\tx = self.fc3(x)\n",
    "\t\tx1, x2 = x[:, [0]], x[:, [1]]\n",
    "\t\t\n",
    "\t\treturn F.sigmoid(x1) - K * F.sigmoid(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 500000\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_static_test_data(num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor, y_test_tensor = load_static_test_data()\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding optimal hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = generate_and_prepare_training_data(1000000, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor, y_test_tensor = load_static_test_data()\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def objective(trial):\n",
    "\t# Define hyperparameters to be optimized\n",
    "\tinput_size = 5\n",
    "\thidden_size = 128\n",
    "\t# dropout_p = trial.suggest_float('dropout_p', 0.1, 0.5)\n",
    "\t# lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "\tdropout_p = 0.20862014926048447\n",
    "\tlr = 0.0002448376394581503\n",
    "\t\n",
    "\tmodel = BlackScholesNet(input_size=input_size, hidden_size=hidden_size, output_size=2)\n",
    "\tmodel.dropout.p = dropout_p\n",
    "\n",
    "\toptimizer = torch.optim.NAdam(model.parameters(), lr=lr)\n",
    "\t\n",
    "\tscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\n",
    "\tnum_epochs = 30\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tmodel.train()\n",
    "\t\tepoch_mse = 0\n",
    "\t\tepoch_mae = 0\n",
    "\t\tepoch_mre = 0\n",
    "\t\t\n",
    "\t\tfor X_batch, y_batch in train_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\t\t\t\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\n",
    "\t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\t\toutputs = (outputs[:, 0] + outputs[:, 1]) / 2\n",
    "\t\t\ty = y_batch[:, 0]\n",
    "\t\t\t\n",
    "\t\t\t# mse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "\t\t\t# relative_errors = torch.abs(outputs - y) / (y + 1e-8)\n",
    "\t\t\t# mre_loss = relative_errors.mean()\n",
    "\t\t\t\n",
    "\t\t\tmae_loss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t\n",
    "\t\t\t# epoch_mse += mse_loss.item()\n",
    "\t\t\tepoch_mae += mae_loss.item()\n",
    "\t\t\t# epoch_mre += mre_loss.item()\n",
    "\t\t\n",
    "\t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "\t\tscheduler.step(avg_epoch_mae)\n",
    "\t\t\n",
    "\ttest_losses = 0.\n",
    "\ttest_maes = 0.\n",
    "\ttest_max_aes = 0.\n",
    "\ttest_mres = 0.\n",
    "\ttest_max_res = 0.\n",
    "\n",
    "\tmodel.eval()\n",
    "\n",
    "\twith torch.inference_mode():\n",
    "\t\tfor X_batch, y_batch in test_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\t\t\t# Forward pass\n",
    "\t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\t\toutputs = (outputs[:, 0] + outputs[:, 1]) / 2\n",
    "\t\t\t\n",
    "\t\t\ty = y_batch[:, 0]\n",
    "\n",
    "\t\t\t# Mean Squared Error (MSE)\n",
    "\t\t\t# mse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\t# test_losses += mse_loss.item()\n",
    "\n",
    "\t\t\t# Mean Absolute Error (MAE)\n",
    "\t\t\tabs_errors = torch.abs(outputs - y)\n",
    "\t\t\ttest_maes += abs_errors.sum().item()\n",
    "\n",
    "\t\t\t# # Maximum Absolute Error (Max AE)\n",
    "\t\t\t# max_ae = abs_errors.max().item()\n",
    "\t\t\t# test_max_aes = max(test_max_aes, max_ae)\n",
    "\n",
    "\t\t\t# # Mean Relative Error (MRE)\n",
    "\t\t\t# mask = y == 0\n",
    "\t\t\t# zero_price_mre = abs_errors[mask]\n",
    "\t\t\t# price_mre = abs_errors[~mask]\n",
    "\n",
    "\t\t\t# # Avoid division by zero for non-zero y values\n",
    "\t\t\t# nonzero_y = y[~mask]\n",
    "\t\t\t# price_mre = price_mre / nonzero_y if nonzero_y.numel() > 0 else price_mre\n",
    "\n",
    "\t\t\t# # Calculate MRE\n",
    "\t\t\t# total_mre = zero_price_mre.sum() + price_mre.sum()\n",
    "\t\t\t# test_mres += total_mre.item() if zero_price_mre.numel() > 0 or price_mre.numel() > 0 else 0\n",
    "\n",
    "\t\t\t# # Handle empty tensors and `inf` values for Max RE\n",
    "\t\t\t# zero_price_max = zero_price_mre.max() if zero_price_mre.numel() > 0 else 0\n",
    "\t\t\t# price_max = price_mre.max() if price_mre.numel() > 0 else 0\n",
    "\n",
    "\t\t\t# # Calculate max relative error\n",
    "\t\t\t# max_re = max(zero_price_max.item(), price_max.item())\n",
    "\t\t\t# test_max_res = max(test_max_res, max_re)\n",
    "\n",
    "\t# avg_test_loss = test_losses / len(test_loader.dataset)\n",
    "\tavg_test_mae = test_maes / len(test_loader.dataset)\n",
    "\t# avg_test_mre = test_mres / len(test_loader.dataset)\n",
    "\t\t\t\n",
    "\t# Return the average MAE as the objective to be minimized\n",
    "\treturn avg_test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print best parameters and best value\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best MAE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters: {'dropout_p': 0.20862014926048447, 'lr': 0.0002448376394581503}\n",
    "Best MAE: 0.00049047276004533371"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_p = 0.20862014926048447\n",
    "lr = 0.0002448376394581503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BlackScholesNet(input_size=5, hidden_size=128, output_size=2)\n",
    "model.dropout.p = dropout_p\n",
    "optimizer = optim.NAdam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('models\\\\Black Model_mae.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlackScholesNet(\n",
       "  (fc1): Linear(in_features=5, out_features=128, bias=True)\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.20862014926048447, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters: {'hidden_size': 256, 'dropout_p': 0.16165214075232218, 'lr': 0.0024867405570057574, 'batch_size': 64, 'optimizer': 'NAdam'}\n",
    "Best MAE: 0.003318011008932989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters: {'hidden_size': 128, 'dropout_p': 0.3974039374569882, 'lr': 0.012408717790861197, 'batch_size': 128, 'optimizer': 'NAdam'}\n",
    "Best MAE: 0.008668262018621945"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = 1000000\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_stages = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = generate_and_prepare_training_data(num_train_samples, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(y_pred, y_true, delta=1.0):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = torch.abs(error) <= delta\n",
    "    small_error_loss = 0.5 * error**2\n",
    "    large_error_loss = delta * (torch.abs(error) - 0.5 * delta)\n",
    "\n",
    "    return torch.where(is_small_error, small_error_loss, large_error_loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 00:06:02 ] ***** Stage [1/1] ******************************************************************************************************************************************************\n",
      "[ 00:06:25 ] ----- Epoch [1/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 0.0013281913592076415     | MSE: 0.014281047991029644      | MAE: 0.07564859368884934       | MRE: 2563086.7334536947        |\n",
      "[ 00:06:46 ] ----- Epoch [2/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 0.0001464802591491307     | MSE: 0.00039560540899037113    | MAE: 0.013887068970326384      | MRE: 389942.72485454736        |\n",
      "[ 00:07:07 ] ----- Epoch [3/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 3.7360749609779754e-05    | MSE: 7.916499391277605e-05     | MAE: 0.006272347743460072      | MRE: 111941.18452400409        |\n",
      "[ 00:07:27 ] ----- Epoch [4/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.5434449868659473e-05    | MSE: 5.2383720942966306e-05    | MAE: 0.005079757103731125      | MRE: 86621.62057860213         |\n",
      "[ 00:07:47 ] ----- Epoch [5/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 1.9575694036888847e-05    | MSE: 3.973276334533357e-05     | MAE: 0.0044453287087901205     | MRE: 75193.90381006939         |\n",
      "[ 00:08:08 ] ----- Epoch [6/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 1.6210761379790794e-05    | MSE: 3.2704247035817784e-05    | MAE: 0.004044504785703482      | MRE: 67277.46493432322         |\n",
      "[ 00:08:29 ] ----- Epoch [7/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 1.4364776790755686e-05    | MSE: 2.889978583558631e-05     | MAE: 0.0037897657472800066     | MRE: 61537.4356967432          |\n",
      "[ 00:08:49 ] ----- Epoch [8/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 1.3209969678058821e-05    | MSE: 2.653627463817614e-05     | MAE: 0.0036277116549213026     | MRE: 56507.369366623           |\n",
      "[ 00:09:10 ] ----- Epoch [9/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 1.2117761970410002e-05    | MSE: 2.4333837578342772e-05    | MAE: 0.003462655986474588      | MRE: 52758.17769010526         |\n",
      "[ 00:09:30 ] ----- Epoch [10/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 1.157629940684833e-05     | MSE: 2.3229975727418598e-05    | MAE: 0.0033710456257436076     | MRE: 48515.77245860444         |\n",
      "[ 00:09:52 ] ----- Epoch [11/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 1.0914956155438777e-05    | MSE: 2.1893721752026866e-05    | MAE: 0.003267757457914116      | MRE: 46012.092374696054        |\n",
      "[ 00:10:17 ] ----- Epoch [12/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 1.0247308453696369e-05    | MSE: 2.0546172922032927e-05    | MAE: 0.0031576222516595358     | MRE: 43029.46498333478         |\n",
      "[ 00:10:42 ] ----- Epoch [13/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 9.792087540759152e-06     | MSE: 1.9626796646115772e-05    | MAE: 0.003076526518273502      | MRE: 40659.06055492036         |\n",
      "[ 00:11:08 ] ----- Epoch [14/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 9.205098934842451e-06     | MSE: 1.8442745223274228e-05    | MAE: 0.0029868384696010264     | MRE: 39550.25123937736         |\n",
      "[ 00:11:32 ] ----- Epoch [15/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 8.93994107076593e-06      | MSE: 1.7910388346753192e-05    | MAE: 0.0029374574352998197     | MRE: 38224.3992570807          |\n",
      "[ 00:11:57 ] ----- Epoch [16/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 8.728197224289888e-06     | MSE: 1.7485834386412274e-05    | MAE: 0.0028941286879434567     | MRE: 36109.91157936873         |\n",
      "[ 00:12:21 ] ----- Epoch [17/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 8.3707581601009e-06       | MSE: 1.6771176948250898e-05    | MAE: 0.0028214515922489474     | MRE: 33977.60914287794         |\n",
      "[ 00:12:47 ] ----- Epoch [18/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 8.06638855416611e-06      | MSE: 1.615560926641122e-05     | MAE: 0.0027729473899735747     | MRE: 33393.63968451838         |\n",
      "[ 00:13:12 ] ----- Epoch [19/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 7.9009115788194e-06       | MSE: 1.5821332176329276e-05    | MAE: 0.002740418665922536      | MRE: 32102.999496968107        |\n",
      "[ 00:13:37 ] ----- Epoch [20/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 7.679306904141917e-06     | MSE: 1.5380291537331116e-05    | MAE: 0.0026971213552527597     | MRE: 30925.895653330103        |\n",
      "[ 00:14:02 ] ----- Epoch [21/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 7.416871286016987e-06     | MSE: 1.485643008356388e-05     | MAE: 0.0026368571115951735     | MRE: 29456.403165850475        |\n",
      "[ 00:14:27 ] ----- Epoch [22/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 7.320991690280851e-06     | MSE: 1.4658838550436427e-05    | MAE: 0.002630386508778719      | MRE: 29124.7729456904          |\n",
      "[ 00:14:51 ] ----- Epoch [23/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 7.1586366449316e-06       | MSE: 1.4335797099718884e-05    | MAE: 0.002592593421134384      | MRE: 28353.835759482074        |\n",
      "[ 00:15:16 ] ----- Epoch [24/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 6.9508426709584716e-06    | MSE: 1.3916666298151529e-05    | MAE: 0.002553016717570494      | MRE: 27522.91190822754         |\n",
      "[ 00:15:41 ] ----- Epoch [25/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 6.8475497414308806e-06    | MSE: 1.370666407774303e-05     | MAE: 0.002530652525604254      | MRE: 26583.876833904054        |\n",
      "[ 00:16:05 ] ----- Epoch [26/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 6.768619935783014e-06     | MSE: 1.3554513659572505e-05    | MAE: 0.002511978992212048      | MRE: 26282.50725599802         |\n",
      "[ 00:16:30 ] ----- Epoch [27/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 6.666131759754692e-06     | MSE: 1.3349030742422875e-05    | MAE: 0.0024851332992640706     | MRE: 25585.24328688928         |\n",
      "[ 00:16:54 ] ----- Epoch [28/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 6.513473101255701e-06     | MSE: 1.3043211375126804e-05    | MAE: 0.0024539840150868413     | MRE: 24493.618988788014        |\n",
      "[ 00:17:18 ] ----- Epoch [29/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 6.417291350869716e-06     | MSE: 1.2848883717377025e-05    | MAE: 0.0024328038064243313     | MRE: 23843.525176457933        |\n",
      "[ 00:17:42 ] ----- Epoch [30/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 6.304636327896415e-06     | MSE: 1.2619910227905056e-05    | MAE: 0.0024127789060784744     | MRE: 23918.83376949628         |\n",
      "[ 00:18:06 ] ----- Epoch [31/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 6.228050586289235e-06     | MSE: 1.2468024028262793e-05    | MAE: 0.002386429795669143      | MRE: 22722.222119781076        |\n",
      "[ 00:18:31 ] ----- Epoch [32/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 6.143565361287111e-06     | MSE: 1.2300098951781254e-05    | MAE: 0.0023708642715118107     | MRE: 21946.710625450854        |\n",
      "[ 00:18:55 ] ----- Epoch [33/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 6.099964976394334e-06     | MSE: 1.2215490463654192e-05    | MAE: 0.002358909707277604      | MRE: 22283.479195653123        |\n",
      "[ 00:19:19 ] ----- Epoch [34/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.944231855556169e-06     | MSE: 1.189978838269533e-05     | MAE: 0.002327607104147937      | MRE: 21169.39675756656         |\n",
      "[ 00:19:43 ] ----- Epoch [35/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.950511664950528e-06     | MSE: 1.191332657599296e-05     | MAE: 0.0023312587649224285     | MRE: 20700.965968308003        |\n",
      "[ 00:20:07 ] ----- Epoch [36/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.846110427235089e-06     | MSE: 1.1704511736066269e-05    | MAE: 0.002307096051164522      | MRE: 20083.4060025271          |\n",
      "[ 00:20:32 ] ----- Epoch [37/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.764450592975156e-06     | MSE: 1.1538049104714857e-05    | MAE: 0.0022902873500538676     | MRE: 20047.957388500297        |\n",
      "[ 00:20:57 ] ----- Epoch [38/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.791416287695676e-06     | MSE: 1.1593785941495313e-05    | MAE: 0.0022931715396650653     | MRE: 20144.92607579508         |\n",
      "[ 00:21:22 ] ----- Epoch [39/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.663617269300693e-06     | MSE: 1.1334345463030334e-05    | MAE: 0.00226520937225578       | MRE: 19777.489848173405        |\n",
      "[ 00:21:43 ] ----- Epoch [40/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.681991538445345e-06     | MSE: 1.1374327207617844e-05    | MAE: 0.002265373751830562      | MRE: 18930.869287862733        |\n",
      "[ 00:22:04 ] ----- Epoch [41/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.5884313356666865e-06    | MSE: 1.1185085222589558e-05    | MAE: 0.0022460003202098276     | MRE: 18977.50209631165         |\n",
      "[ 00:22:24 ] ----- Epoch [42/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.476573764743327e-06     | MSE: 1.096204604830035e-05     | MAE: 0.002223338534569999      | MRE: 18802.50433293322         |\n",
      "[ 00:22:46 ] ----- Epoch [43/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.395620439750465e-06     | MSE: 1.0800217429649335e-05    | MAE: 0.002196040143580045      | MRE: 17635.239691096136        |\n",
      "[ 00:23:07 ] ----- Epoch [44/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.429607557238906e-06     | MSE: 1.0868736558430916e-05    | MAE: 0.002209264147035309      | MRE: 17508.697800790735        |\n",
      "[ 00:23:27 ] ----- Epoch [45/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.360127363621926e-06     | MSE: 1.072916317604656e-05     | MAE: 0.002196086307637621      | MRE: 17760.436174282386        |\n",
      "[ 00:23:48 ] ----- Epoch [46/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.2584801867533185e-06    | MSE: 1.0526997933029856e-05    | MAE: 0.0021745546092360167     | MRE: 17146.932040658736        |\n",
      "[ 00:24:08 ] ----- Epoch [47/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.331845114153421e-06     | MSE: 1.0670049945454512e-05    | MAE: 0.002182861284086207      | MRE: 16912.709319100497        |\n",
      "[ 00:24:29 ] ----- Epoch [48/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.273794330706246e-06     | MSE: 1.0556577617538422e-05    | MAE: 0.0021668847549240994     | MRE: 16699.663873502206        |\n",
      "[ 00:24:49 ] ----- Epoch [49/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.192692980580203e-06     | MSE: 1.03933243092384e-05      | MAE: 0.002152963408390329      | MRE: 16172.904961449205        |\n",
      "[ 00:25:10 ] ----- Epoch [50/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.154086861175177e-06     | MSE: 1.0317550927297733e-05    | MAE: 0.0021446130891092678     | MRE: 16107.305025863243        |\n",
      "[ 00:25:31 ] ----- Epoch [51/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.070072140515364e-06     | MSE: 1.0149499488297998e-05    | MAE: 0.0021188284300118383     | MRE: 15801.244429577813        |\n",
      "[ 00:25:51 ] ----- Epoch [52/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 5.018964194886568e-06     | MSE: 1.0045227025965799e-05    | MAE: 0.002108630308053286      | MRE: 15542.657547596436        |\n",
      "[ 00:26:12 ] ----- Epoch [53/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.976498176721521e-06     | MSE: 9.961731291746087e-06     | MAE: 0.0021071565887561747     | MRE: 15354.500619088205        |\n",
      "[ 00:26:33 ] ----- Epoch [54/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.979752879578502e-06     | MSE: 9.969849523793578e-06     | MAE: 0.0021020690693550224     | MRE: 15222.190005285229        |\n",
      "[ 00:26:53 ] ----- Epoch [55/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.9723072476553955e-06    | MSE: 9.952103689567577e-06     | MAE: 0.0021036621148378385     | MRE: 14821.524333232326        |\n",
      "[ 00:27:14 ] ----- Epoch [56/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.8595630319835936e-06    | MSE: 9.726958668570371e-06     | MAE: 0.0020722815830459627     | MRE: 14676.18386816647         |\n",
      "[ 00:27:35 ] ----- Epoch [57/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.834220651044807e-06     | MSE: 9.67783249812659e-06      | MAE: 0.0020632234287004773     | MRE: 14689.540390567112        |\n",
      "[ 00:27:56 ] ----- Epoch [58/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.809677405166775e-06     | MSE: 9.625021946804073e-06     | MAE: 0.0020684973438926855     | MRE: 14407.497804860901        |\n",
      "[ 00:28:16 ] ----- Epoch [59/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.72922045559823e-06      | MSE: 9.465022551485424e-06     | MAE: 0.0020444946095263517     | MRE: 14342.116413644395        |\n",
      "[ 00:28:37 ] ----- Epoch [60/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.699134797348752e-06     | MSE: 9.403769014064875e-06     | MAE: 0.002038050274701579      | MRE: 14177.18360057498         |\n",
      "[ 00:28:58 ] ----- Epoch [61/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.7204688737517265e-06    | MSE: 9.446823064133977e-06     | MAE: 0.002038574995279478      | MRE: 13869.765491699667        |\n",
      "[ 00:29:18 ] ----- Epoch [62/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.701947840237859e-06     | MSE: 9.411479610360594e-06     | MAE: 0.0020401629340286646     | MRE: 14078.400236763908        |\n",
      "[ 00:29:40 ] ----- Epoch [63/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.643562179160985e-06     | MSE: 9.29340192310408e-06      | MAE: 0.002024689952608005      | MRE: 13693.929841967729        |\n",
      "[ 00:30:07 ] ----- Epoch [64/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.6327765151590605e-06    | MSE: 9.271980910947967e-06     | MAE: 0.002022450446982783      | MRE: 13207.635672983508        |\n",
      "[ 00:30:28 ] ----- Epoch [65/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.523796731179643e-06     | MSE: 9.053205318875296e-06     | MAE: 0.0019926288807902174     | MRE: 13151.922212526371        |\n",
      "[ 00:30:49 ] ----- Epoch [66/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.587185542028277e-06     | MSE: 9.181542063648497e-06     | MAE: 0.0020091737426323436     | MRE: 13227.198223526111        |\n",
      "[ 00:31:10 ] ----- Epoch [67/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.56082163458634e-06      | MSE: 9.129400736825315e-06     | MAE: 0.0020039461882562517     | MRE: 13169.800569322015        |\n",
      "[ 00:31:29 ] ----- Epoch [68/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.589955778198119e-06     | MSE: 9.18563688876116e-06      | MAE: 0.0020106510268744207     | MRE: 13294.907358541934        |\n",
      "[ 00:31:48 ] ----- Epoch [69/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.48312912188566e-06      | MSE: 8.971267244543172e-06     | MAE: 0.0019879692321084184     | MRE: 13128.093082885096        |\n",
      "[ 00:32:07 ] ----- Epoch [70/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.4723130088212e-06       | MSE: 8.95107375265793e-06      | MAE: 0.0019789305116604977     | MRE: 13223.793947004728        |\n",
      "[ 00:32:33 ] ----- Epoch [71/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.390467615249628e-06     | MSE: 8.788146041131273e-06     | MAE: 0.0019664863458995624     | MRE: 12861.850990688943        |\n",
      "[ 00:32:55 ] ----- Epoch [72/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.376171586138726e-06     | MSE: 8.758309333084517e-06     | MAE: 0.001960139819703752      | MRE: 12531.687434099631        |\n",
      "[ 00:33:18 ] ----- Epoch [73/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.389144174904968e-06     | MSE: 8.78621870485936e-06      | MAE: 0.0019601785422028776     | MRE: 12264.013510150842        |\n",
      "[ 00:33:40 ] ----- Epoch [74/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.390153333934822e-06     | MSE: 8.784677407562758e-06     | MAE: 0.001965034761099474      | MRE: 12832.304761515901        |\n",
      "[ 00:34:02 ] ----- Epoch [75/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.314184078813041e-06     | MSE: 8.635103358145804e-06     | MAE: 0.0019412094774599877     | MRE: 12514.770741226175        |\n",
      "[ 00:34:25 ] ----- Epoch [76/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.265143065404139e-06     | MSE: 8.536853504515025e-06     | MAE: 0.001936924568593299      | MRE: 12342.959272119888        |\n",
      "[ 00:34:48 ] ----- Epoch [77/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.329670786206314e-06     | MSE: 8.665786543344604e-06     | MAE: 0.0019459226734853594     | MRE: 12195.786043221418        |\n",
      "[ 00:35:16 ] ----- Epoch [78/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.2866731570632e-06       | MSE: 8.577871577039871e-06     | MAE: 0.0019379370549254848     | MRE: 11991.351831280996        |\n",
      "[ 00:36:04 ] ----- Epoch [79/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.241329840151971e-06     | MSE: 8.488190656038692e-06     | MAE: 0.0019281732216346367     | MRE: 12226.583385939952        |\n",
      "[ 00:36:52 ] ----- Epoch [80/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.203806616033856e-06     | MSE: 8.412598946261711e-06     | MAE: 0.0019238609018528909     | MRE: 12100.172491048941        |\n",
      "[ 00:37:40 ] ----- Epoch [81/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.173689693157993e-06     | MSE: 8.35201147654296e-06      | MAE: 0.0019140193319762307     | MRE: 12031.663563852277        |\n",
      "[ 00:38:19 ] ----- Epoch [82/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.177355014777347e-06     | MSE: 8.36007644832026e-06      | MAE: 0.001910658678026392      | MRE: 11670.175857834989        |\n",
      "[ 00:38:56 ] ----- Epoch [83/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.124876512831714e-06     | MSE: 8.253670697274908e-06     | MAE: 0.0019026899746371576     | MRE: 11778.355775155711        |\n",
      "[ 00:39:56 ] ----- Epoch [84/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.136922278475775e-06     | MSE: 8.280251016413278e-06     | MAE: 0.0018994549771758338     | MRE: 11387.175614798263        |\n",
      "[ 00:40:40 ] ----- Epoch [85/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.084699391569866e-06     | MSE: 8.17439147604545e-06      | MAE: 0.001889995147863993      | MRE: 11377.266740194602        |\n",
      "[ 00:41:18 ] ----- Epoch [86/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.070914930513325e-06     | MSE: 8.147045672547036e-06     | MAE: 0.0018883325552814312     | MRE: 11346.503729301729        |\n",
      "[ 00:41:57 ] ----- Epoch [87/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.059771531097621e-06     | MSE: 8.12324487009372e-06      | MAE: 0.0018835892689280879     | MRE: 10970.773417187507        |\n",
      "[ 00:42:38 ] ----- Epoch [88/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.039483697416819e-06     | MSE: 8.082633413732147e-06     | MAE: 0.001879333950224917      | MRE: 11280.064801606117        |\n",
      "[ 00:43:22 ] ----- Epoch [89/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.056664032640274e-06     | MSE: 8.11848013169413e-06      | MAE: 0.0018785082919528056     | MRE: 11146.72712734123         |\n",
      "[ 00:43:57 ] ----- Epoch [90/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.029339771910949e-06     | MSE: 8.062690928475817e-06     | MAE: 0.001877712362541739      | MRE: 11408.29676286417         |\n",
      "[ 00:44:48 ] ----- Epoch [91/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 3.985360825945201e-06     | MSE: 7.974546008657421e-06     | MAE: 0.0018645413173512557     | MRE: 11224.369474225745        |\n",
      "[ 00:45:42 ] ----- Epoch [92/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 3.954367187620986e-06     | MSE: 7.912178582929128e-06     | MAE: 0.0018601955245451584     | MRE: 11165.573124439812        |\n",
      "[ 00:46:29 ] ----- Epoch [93/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.044497038790889e-06     | MSE: 8.093926930923273e-06     | MAE: 0.0018744301726170028     | MRE: 10826.919579057154        |\n",
      "[ 00:47:12 ] ----- Epoch [94/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 3.936800103425413e-06     | MSE: 7.877143818250223e-06     | MAE: 0.0018554457720046816     | MRE: 11159.479291688793        |\n",
      "[ 00:47:44 ] ----- Epoch [95/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 4.038176510817156e-06     | MSE: 8.079429092456863e-06     | MAE: 0.0018704498024676647     | MRE: 10969.890249368445        |\n",
      "[ 00:48:32 ] ----- Epoch [96/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 3.908536720688435e-06     | MSE: 7.820159471591458e-06     | MAE: 0.001847193883823717      | MRE: 11305.489653366349        |\n",
      "[ 00:49:21 ] ----- Epoch [97/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 3.9092339582955505e-06    | MSE: 7.822432104525398e-06     | MAE: 0.0018466848296391748     | MRE: 11073.411080964948        |\n",
      "[ 00:50:03 ] ----- Epoch [98/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 3.8407669089317815e-06    | MSE: 7.684976440705773e-06     | MAE: 0.0018322592655679172     | MRE: 10788.170060135108        |\n",
      "[ 00:50:43 ] ----- Epoch [99/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 3.842831512765996e-06     | MSE: 7.690451973465372e-06     | MAE: 0.001832729883843625      | MRE: 10835.000600995732        |\n",
      "[ 00:51:25 ] ----- Epoch [100/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 3.902472625798521e-06     | MSE: 7.809732501801518e-06     | MAE: 0.0018400658764048464     | MRE: 10936.135150039798        |\n"
     ]
    }
   ],
   "source": [
    "for stage in range(num_stages):\n",
    "\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ***** Stage [{stage+1}/{num_stages}] {'*'*150}\")\n",
    "\t\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tcnt = 0\n",
    "\t\tepoch_huber = 0.\n",
    "\t\tepoch_mae = 0.\n",
    "\t\tepoch_mre = 0.\n",
    "\t\tepoch_mse = 0.\n",
    "\t\t\n",
    "\t\tfor X_batch, y_batch in train_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\t\t\tmodel.train()\n",
    "\t\t\t\n",
    "\t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\t\toutputs = (outputs[:, 0] + outputs[:, 1] ) / 2\n",
    "\t\t\ty = y_batch[:, 0]\n",
    "            \n",
    "\t\t\t# Calculate losses\n",
    "\t\t\thub_loss = huber_loss(outputs, y, 0.02)\n",
    "\t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "\t\t\tmask = y >= 1e-10\n",
    "\t\t\ty_m = y[mask]\n",
    "\t\t\trelative_errors = torch.abs(outputs[mask] - y_m ) / y_m\n",
    "\t\t\tmre_loss = relative_errors.sum()\n",
    "\n",
    "\t\t\tcnt += len(relative_errors)\n",
    "\t\t\t\n",
    "\t\t\t# Backpropagation\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\thub_loss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t\n",
    "\t\t\t# Accumulate losses\n",
    "\t\t\tepoch_mse += mse_loss.item()\n",
    "\t\t\tepoch_mae += mae_loss.item()\n",
    "\t\t\tepoch_mre += mre_loss.item()\n",
    "\t\t\tepoch_huber += hub_loss\n",
    "\t\t\n",
    "\t\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "\n",
    "\t\tavg_epoch_huber = epoch_huber / len(train_loader)\n",
    "\t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "\t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "\t\tavg_epoch_mre = epoch_mre / cnt\n",
    "\t\t\n",
    "\t\tprint(f\"{model.name:<50} | Huber loss: {avg_epoch_huber:<25} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\t\t\n",
    "\t\tscheduler.step(avg_epoch_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-cosh loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18:51:10 ] ***** Stage [1/1] ******************************************************************************************************************************************************\n",
      "[ 18:51:30 ] ----- Epoch [1/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 0.01731447072122037       | MAE: 0.089106594409645         | MRE: 3058633.5212305137        |\n",
      "[ 18:51:50 ] ----- Epoch [2/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 0.0010450003118724588     | MAE: 0.023971658696214888      | MRE: 771303.588995485          |\n",
      "[ 18:52:09 ] ----- Epoch [3/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 0.0001512994754532175     | MAE: 0.00895387339441951       | MRE: 210626.51115082315        |\n",
      "[ 18:52:27 ] ----- Epoch [4/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 6.892608815181244e-05     | MAE: 0.005883380302780205      | MRE: 111147.05435583208        |\n",
      "[ 18:52:45 ] ----- Epoch [5/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 4.9353556588203586e-05    | MAE: 0.004968252232131193      | MRE: 89373.80513092178         |\n",
      "[ 18:53:02 ] ----- Epoch [6/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 3.903264970802214e-05     | MAE: 0.004442454011402691      | MRE: 77508.10814262812         |\n",
      "[ 18:53:19 ] ----- Epoch [7/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 3.368304325566162e-05     | MAE: 0.0041201268446925815     | MRE: 69080.51673518943         |\n",
      "[ 18:53:36 ] ----- Epoch [8/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.956845673858399e-05     | MAE: 0.00385377370228547       | MRE: 63424.132843474166        |\n",
      "[ 18:53:53 ] ----- Epoch [9/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.7425744214238394e-05    | MAE: 0.0036998401798948245     | MRE: 58765.5387860732          |\n",
      "[ 18:54:10 ] ----- Epoch [10/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.4939494013544563e-05    | MAE: 0.003519000832304912      | MRE: 53088.027463344246        |\n",
      "[ 18:54:27 ] ----- Epoch [11/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.3431339014483393e-05    | MAE: 0.0033873751352765423     | MRE: 49596.209813927715        |\n",
      "[ 18:54:44 ] ----- Epoch [12/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.2073221655830494e-05    | MAE: 0.0032872964734381215     | MRE: 45795.7671171294          |\n",
      "[ 18:55:01 ] ----- Epoch [13/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.084050045904518e-05     | MAE: 0.0031834157982392804     | MRE: 44370.02082890216         |\n",
      "[ 18:55:18 ] ----- Epoch [14/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.9599185384201923e-05    | MAE: 0.003092811103534611      | MRE: 40402.83255294311         |\n",
      "[ 18:55:35 ] ----- Epoch [15/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.942398345676197e-05     | MAE: 0.003049764804336584      | MRE: 38675.91596824273         |\n",
      "[ 18:55:52 ] ----- Epoch [16/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.8326963362392304e-05    | MAE: 0.0029648561416231053     | MRE: 37599.43025517452         |\n",
      "[ 18:56:09 ] ----- Epoch [17/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.7815382839989627e-05    | MAE: 0.002926117903623292      | MRE: 36467.50197642514         |\n",
      "[ 18:56:27 ] ----- Epoch [18/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.7085708220998428e-05    | MAE: 0.0028566735476514334     | MRE: 34857.12117580216         |\n",
      "[ 18:56:47 ] ----- Epoch [19/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.664699292385959e-05     | MAE: 0.0028183495533419126     | MRE: 33416.366910919016        |\n",
      "[ 18:57:06 ] ----- Epoch [20/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.617160993766033e-05     | MAE: 0.0027698345718942087     | MRE: 32453.09566223582         |\n",
      "[ 18:57:24 ] ----- Epoch [21/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.568822873353176e-05     | MAE: 0.002725351934926964      | MRE: 30692.10454301053         |\n",
      "[ 18:57:42 ] ----- Epoch [22/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.541930846803333e-05     | MAE: 0.002688442294558928      | MRE: 29721.88937755512         |\n",
      "[ 18:58:00 ] ----- Epoch [23/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.523920125001209e-05     | MAE: 0.0026733518137175855     | MRE: 29054.824303924455        |\n",
      "[ 18:58:18 ] ----- Epoch [24/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.4769747799491174e-05    | MAE: 0.0026342328758102098     | MRE: 28172.53923078817         |\n",
      "[ 18:58:35 ] ----- Epoch [25/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.4599723825824199e-05    | MAE: 0.002613716768853416      | MRE: 27587.680738012714        |\n",
      "[ 18:58:53 ] ----- Epoch [26/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.4126480054870121e-05    | MAE: 0.002568947940246465      | MRE: 26875.012025421187        |\n",
      "[ 18:59:10 ] ----- Epoch [27/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.3942346808017669e-05    | MAE: 0.0025501496988805466     | MRE: 25503.138978476985        |\n",
      "[ 18:59:28 ] ----- Epoch [28/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.3692698933634936e-05    | MAE: 0.0025199557347813984     | MRE: 25726.191536663966        |\n",
      "[ 18:59:46 ] ----- Epoch [29/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.3380714134394212e-05    | MAE: 0.0024847053966230237     | MRE: 24492.420727477875        |\n",
      "[ 19:00:03 ] ----- Epoch [30/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.3421092845980374e-05    | MAE: 0.0024886848291776017     | MRE: 23859.429674730753        |\n"
     ]
    }
   ],
   "source": [
    "for stage in range(num_stages):\n",
    "\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ***** Stage [{stage+1}/{num_stages}] {'*'*150}\")\n",
    "\t\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tcnt = 0\n",
    "\t\tepoch_lcosh = 0.\n",
    "\t\tepoch_mae = 0.\n",
    "\t\tepoch_mre = 0.\n",
    "\t\tepoch_mse = 0.\n",
    "\t\t\n",
    "\t\tfor X_batch, y_batch in train_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\t\t\tmodel.train()\n",
    "\t\t\t\n",
    "\t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\t\toutputs = (outputs[:, 0] + outputs[:, 1] ) / 2\n",
    "\t\t\ty = y_batch[:, 0]\n",
    "            \n",
    "\t\t\t# Calculate losses\n",
    "\t\t\tlcosh_loss = torch.mean(torch.log(torch.cosh(outputs-y)))\n",
    "\t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "\t\t\tmask = y >= 1e-10\n",
    "\t\t\ty_m = y[mask]\n",
    "\t\t\trelative_errors = torch.abs(outputs[mask] - y_m ) / y_m\n",
    "\t\t\tmre_loss = relative_errors.sum()\n",
    "\n",
    "\t\t\tcnt += len(relative_errors)\n",
    "\t\t\t\n",
    "\t\t\t# Backpropagation\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tlcosh_loss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t\n",
    "\t\t\t# Accumulate losses\n",
    "\t\t\tepoch_mse += mse_loss.item()\n",
    "\t\t\tepoch_mae += mae_loss.item()\n",
    "\t\t\tepoch_mre += mre_loss.item()\n",
    "\t\t\tepoch_lcosh += hub_loss\n",
    "\t\t\n",
    "\t\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "\n",
    "\t\tavg_epoch_lcosh = epoch_lcosh / len(train_loader)\n",
    "\t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "\t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "\t\tavg_epoch_mre = epoch_mre / cnt\n",
    "\t\t\n",
    "\t\tprint(f\"{model.name:<50} | Huber loss: {avg_epoch_lcosh:<25} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\t\t\n",
    "\t\tscheduler.step(avg_epoch_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "# \t# Initialize epoch metrics for each model\n",
    "# \tepoch_mae = [0.] * len(models)\n",
    "# \tepoch_mre = [0.] * len(models)\n",
    "# \tepoch_mse = [0.] * len(models)\n",
    "\t\n",
    "# \tfor X_batch, y_batch in train_loader:\n",
    "# \t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\t\t\n",
    "# \t\t# Loop over each model\n",
    "# \t\tfor i, model in enumerate(models):\n",
    "# \t\t\tmodel.train()\n",
    "\t\t\t\n",
    "# \t\t\t# Forward pass\n",
    "# \t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "# \t\t\toutputs = (outputs[:, 0] + outputs[:, 1] ) / 2\n",
    "# \t\t\ty = y_batch[:, 0]\n",
    "\t\t\t\n",
    "# \t\t\t# Calculate losses\n",
    "# \t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "# \t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "# \t\t\trelative_errors = torch.abs(outputs - y) / (y + 1e-8)\n",
    "# \t\t\tmre_loss = relative_errors.mean()\n",
    "\t\t\t\n",
    "# \t\t\t# Backpropagation\n",
    "# \t\t\toptimizers.zero_grad()\n",
    "# \t\t\tmse_loss.backward()\n",
    "# \t\t\toptimizers.step()\n",
    "\t\t\t\n",
    "# \t\t\t# Accumulate losses for this model\n",
    "# \t\t\tepoch_mse += mse_loss.item()\n",
    "# \t\t\tepoch_mae += mae_loss.item()\n",
    "# \t\t\tepoch_mre += mre_loss.item()\n",
    "\t\n",
    "# \tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "# \t# Average metrics for each model\n",
    "# \tfor i in range(len(models)):\n",
    "# \t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "# \t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "# \t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\t\t\n",
    "# \t\tprint(f\"{models.name:<50} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\t\t\n",
    "# \t\t# Scheduler step\n",
    "# \t\tschedulers.step(avg_epoch_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 16:48:38 ] ***** Stage [1/1] ******************************************************************************************************************************************************\n",
      "[ 16:48:57 ] ----- Epoch [1/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.713444032667776e-06     | MAE: 0.0016893021870960276     | MRE: 2130.8338195002457        |\n",
      "[ 16:49:15 ] ----- Epoch [2/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.673566564483985e-06     | MAE: 0.0016866326802013854     | MRE: 2116.790267773122         |\n",
      "[ 16:49:34 ] ----- Epoch [3/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.626361016490285e-06     | MAE: 0.0016783767686892406     | MRE: 2052.3916372588237        |\n",
      "[ 16:49:52 ] ----- Epoch [4/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.609244414642811e-06     | MAE: 0.001677038718845492      | MRE: 2056.6905103701424        |\n",
      "[ 16:50:10 ] ----- Epoch [5/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.6003545539628654e-06    | MAE: 0.0016747101183376444     | MRE: 2064.359918605055         |\n",
      "[ 16:50:29 ] ----- Epoch [6/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.659663374058184e-06     | MAE: 0.0016791866940246319     | MRE: 2096.7424275561634        |\n",
      "[ 16:50:46 ] ----- Epoch [7/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.534470195050147e-06     | MAE: 0.0016691452537308878     | MRE: 2133.366322433748         |\n",
      "[ 16:51:04 ] ----- Epoch [8/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.515615476823782e-06     | MAE: 0.001666222213428555      | MRE: 2115.983013023734         |\n",
      "[ 16:51:21 ] ----- Epoch [9/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.492492234591444e-06     | MAE: 0.0016595058295736911     | MRE: 2063.863028631606         |\n",
      "[ 16:51:38 ] ----- Epoch [10/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.431373554155808e-06     | MAE: 0.001653930834652259      | MRE: 1991.0684594904506        |\n",
      "[ 16:51:56 ] ----- Epoch [11/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.4158005012885666e-06    | MAE: 0.001647271900802624      | MRE: 2015.831275687749         |\n",
      "[ 16:52:15 ] ----- Epoch [12/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.400038858267167e-06     | MAE: 0.0016494816155680288     | MRE: 2024.8061007242836        |\n",
      "[ 16:52:32 ] ----- Epoch [13/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.388449601034199e-06     | MAE: 0.0016455952648866607     | MRE: 1968.5967449371635        |\n",
      "[ 16:52:50 ] ----- Epoch [14/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.523117342350244e-06     | MAE: 0.0016596386466875065     | MRE: 2070.084676289044         |\n",
      "[ 16:53:08 ] ----- Epoch [15/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.282070438136995e-06     | MAE: 0.0016404102222159806     | MRE: 2108.5823527119246        |\n",
      "[ 16:53:26 ] ----- Epoch [16/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.3282253061139705e-06    | MAE: 0.001638272376132771      | MRE: 1954.827128510674         |\n",
      "[ 16:53:44 ] ----- Epoch [17/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.274419042060498e-06     | MAE: 0.0016313781796438599     | MRE: 1963.967127311012         |\n",
      "[ 16:54:02 ] ----- Epoch [18/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.177428726314665e-06     | MAE: 0.001623416521195353      | MRE: 2000.1714892705133        |\n",
      "[ 16:54:20 ] ----- Epoch [19/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.12614118441572e-06      | MAE: 0.0016217121801751088     | MRE: 2020.7870763284593        |\n",
      "[ 16:54:38 ] ----- Epoch [20/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.102396773843646e-06     | MAE: 0.0016130941847388685     | MRE: 2033.562345954983         |\n",
      "[ 16:54:56 ] ----- Epoch [21/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.1489342995179084e-06    | MAE: 0.0016167234412184112     | MRE: 1977.5702606549864        |\n",
      "[ 16:55:13 ] ----- Epoch [22/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.123123964113697e-06     | MAE: 0.0016140510799372582     | MRE: 2041.9207881943744        |\n",
      "[ 16:55:31 ] ----- Epoch [23/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 6.951283497436717e-06     | MAE: 0.0015959029260199618     | MRE: 2026.8158371071731        |\n",
      "[ 16:55:50 ] ----- Epoch [24/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 7.176188630510861e-06     | MAE: 0.0016170107379440918     | MRE: 2032.870301479998         |\n",
      "[ 16:56:08 ] ----- Epoch [25/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 6.912622833565889e-06     | MAE: 0.0015922496108178009     | MRE: 2038.7782054890708        |\n",
      "[ 16:56:26 ] ----- Epoch [26/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 6.942858242388869e-06     | MAE: 0.0015917118321752447     | MRE: 1954.1671683553836        |\n",
      "[ 16:56:44 ] ----- Epoch [27/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 6.961381328926417e-06     | MAE: 0.0015942439815289171     | MRE: 1957.6117625481081        |\n",
      "[ 16:57:02 ] ----- Epoch [28/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 6.863359235292024e-06     | MAE: 0.0015815621034718879     | MRE: 1914.553698927285         |\n",
      "[ 16:57:20 ] ----- Epoch [29/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 6.991854185067032e-06     | MAE: 0.0015959163277068273     | MRE: 1994.4338290018184        |\n",
      "[ 16:57:38 ] ----- Epoch [30/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 6.979999225732519e-06     | MAE: 0.0015978252385204644     | MRE: 1957.4766630425452        |\n",
      "[ 16:57:55 ] ----- Epoch [31/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 6.924970250663871e-06     | MAE: 0.0015921227672733784     | MRE: 2068.2719434375           |\n",
      "[ 16:58:12 ] ----- Epoch [32/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 6.880145440448321e-06     | MAE: 0.0015834895756404951     | MRE: 1962.8388654763414        |\n",
      "[ 16:58:29 ] ----- Epoch [33/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 5.874320240020052e-06     | MAE: 0.0014761759612222818     | MRE: 1976.282826393426         |\n",
      "[ 16:58:46 ] ----- Epoch [34/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 5.777133375566496e-06     | MAE: 0.00146580563102952       | MRE: 1975.4587944021907        |\n"
     ]
    }
   ],
   "source": [
    "for stage in range(num_stages):\n",
    "\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ***** Stage [{stage+1}/{num_stages}] {'*'*150}\")\n",
    "\t\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tepoch_mae = 0.\n",
    "\t\tepoch_mre = 0.\n",
    "\t\tepoch_mse = 0.\n",
    "\t\t\n",
    "\t\tfor X_batch, y_batch in train_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\t\t\tmodel.train()\n",
    "\t\t\t\n",
    "\t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\t\toutputs = (outputs[:, 0] + outputs[:, 1] ) / 2\n",
    "\t\t\ty = y_batch[:, 0]\n",
    "\t\t\t\n",
    "\t\t\t# Calculate losses\n",
    "\t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "\t\t\tmask = y >= 1e-10\n",
    "\t\t\ty_m = y[mask]\n",
    "\t\t\trelative_errors = torch.abs(outputs[mask] - y_m ) / y_m\n",
    "\t\t\tmre_loss = relative_errors.mean()\n",
    "\t\t\t\n",
    "\t\t\t# Backpropagation\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tmae_loss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t\n",
    "\t\t\t# Accumulate losses\n",
    "\t\t\tepoch_mse += mse_loss.item()\n",
    "\t\t\tepoch_mae += mae_loss.item()\n",
    "\t\t\tepoch_mre += mre_loss.item()\n",
    "\t\t\n",
    "\t\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "\n",
    "\t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "\t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "\t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\t\t\n",
    "\t\tprint(f\"{model.name:<50} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\t\t\n",
    "\t\tscheduler.step(avg_epoch_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRE Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "# \t# Initialize epoch metrics for each model\n",
    "# \tepoch_mae = [0.] * len(models)\n",
    "# \tepoch_mre = [0.] * len(models)\n",
    "# \tepoch_mse = [0.] * len(models)\n",
    "\t\n",
    "# \tfor X_batch, y_batch in train_loader:\n",
    "# \t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\t\t\n",
    "# \t\t# Loop over each model\n",
    "# \t\tfor i, model in enumerate(models):\n",
    "# \t\t\tmodel.train()\n",
    "\t\t\t\n",
    "# \t\t\t# Forward pass\n",
    "# \t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "# \t\t\toutputs = outputs[:, 0] + outputs[:, 1] / X_batch[:, 0]\n",
    "# \t\t\ty = y_batch[:, 0]\n",
    "\t\t\t\n",
    "# \t\t\t# Calculate losses\n",
    "# \t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "# \t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "# \t\t\trelative_errors = torch.abs(outputs - y) / (y + 1e-8)\n",
    "# \t\t\tmre_loss = relative_errors.mean()\n",
    "\t\t\t\n",
    "# \t\t\t# Backpropagation\n",
    "# \t\t\toptimizers.zero_grad()\n",
    "# \t\t\tmre_loss.backward()\n",
    "# \t\t\toptimizers.step()\n",
    "\t\t\t\n",
    "# \t\t\t# Accumulate losses for this model\n",
    "# \t\t\tepoch_mse += mse_loss.item()\n",
    "# \t\t\tepoch_mae += mae_loss.item()\n",
    "# \t\t\tepoch_mre += mre_loss.item()\n",
    "\t\n",
    "# \tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "# \t# Average metrics for each model\n",
    "# \tfor i in range(len(models)):\n",
    "# \t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "# \t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "# \t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\t\t\n",
    "# \t\tprint(f\"{models.name:<50} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\t\t\n",
    "# \t\t# Scheduler step\n",
    "# \t\tschedulers.step(avg_epoch_mre)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "# \t# Initialize epoch metrics for each model\n",
    "# \tepoch_mae = [0.] * len(models)\n",
    "# \tepoch_mre = [0.] * len(models)\n",
    "# \tepoch_mse = [0.] * len(models)\n",
    "\t\n",
    "# \tfor X_batch, y_batch in train_loader:\n",
    "# \t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\t\t\n",
    "# \t\t# Loop over each model\n",
    "# \t\tfor i, model in enumerate(models):\n",
    "# \t\t\tmodel.train()\n",
    "\t\t\t\n",
    "# \t\t\t# Forward pass\n",
    "# \t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "# \t\t\toutputs = outputs[:, 0] + outputs[:, 1] / X_batch[:, 0]\n",
    "# \t\t\ty = y_batch[:, 0]\n",
    "\t\t\t\n",
    "# \t\t\t# Calculate losses\n",
    "# \t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "# \t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "# \t\t\trelative_errors = torch.abs(outputs - y) / (y + 1e-8)\n",
    "# \t\t\tmre_loss = relative_errors.mean()\n",
    "\t\t\t\n",
    "# \t\t\t# Composite loss\n",
    "# \t\t\tcomposite_loss = (weights_mse * mse_loss + \n",
    "# \t\t\t\t\t\t\t  weights_mae * mae_loss + \n",
    "# \t\t\t\t\t\t\t  weights_mre * mre_loss)\n",
    "\t\t\t\n",
    "# \t\t\t# Backpropagation\n",
    "# \t\t\toptimizers.zero_grad()\n",
    "# \t\t\tcomposite_loss.backward()\n",
    "# \t\t\toptimizers.step()\n",
    "\t\t\t\n",
    "# \t\t\t# Accumulate losses for this model\n",
    "# \t\t\tepoch_mse += mse_loss.item()\n",
    "# \t\t\tepoch_mae += mae_loss.item()\n",
    "# \t\t\tepoch_mre += mre_loss.item()\n",
    "\t\n",
    "# \tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "# \t# Compute average metrics for each model\n",
    "# \tfor i in range(len(models)):\n",
    "# \t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "# \t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "# \t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\t\t\n",
    "# \t\tprint(f\"{models.name:<50} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\t\t\n",
    "# \t\t# Update weights for loss adjustment\n",
    "# \t\tweights_mse = avg_epoch_mse / target_loss\n",
    "# \t\tweights_mae = avg_epoch_mae / target_loss\n",
    "# \t\tweights_mre = avg_epoch_mre / target_loss\n",
    "\t\t\n",
    "# \t\t# Scheduler step\n",
    "# \t\tschedulers.step(composite_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"models/{model.name}_mae22.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = 'models'\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for model_name in [m for m in os.listdir(models_path) if m.endswith('pth')]:\n",
    "    print(model_name)\n",
    "    # model = BlackScholesNet(input_size=5, hidden_size=128, output_size=2)\n",
    "    # model.load_state_dict(torch.load(os.path.join(models_path, model_name)))\n",
    "    # model.to(device)\n",
    "\n",
    "    # models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BlackScholesNet(input_size=5, hidden_size=128, output_size=2)\n",
    "model.load_state_dict(torch.load(f\"models\\\\black.pth\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 10000000\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_static_test_data(num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serpo\\AppData\\Local\\Temp\\ipykernel_1664\\2013377624.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_test_tensor, y_test_tensor = torch.load('static_test_data.pt')\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor, y_test_tensor = load_static_test_data()\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        Results | MSE: 2.274582276520626e-09     | MAE: 0.0004704560497335352     | Max AE: 0.018316124494919095      | MRE: 1748.9047678411978        | Max RE: 13818380.02413941        \n"
     ]
    }
   ],
   "source": [
    "# Initialize metrics for each model\n",
    "test_losses = 0.\n",
    "test_maes = 0.\n",
    "test_max_aes = 0.\n",
    "test_mres = 0.\n",
    "test_max_res = 0.\n",
    "cnt = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "\tfor X_batch, y_batch in test_loader:\n",
    "\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\t\t# Forward pass\n",
    "\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\toutputs = (outputs[:, 0] + outputs[:, 1]) / 2\n",
    "\t\t\n",
    "\t\ty = y_batch[:, 0]\n",
    "\n",
    "\t\t# Mean Squared Error (MSE)\n",
    "\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "\t\ttest_losses += mse_loss.item()\n",
    "\n",
    "\t\t# Mean Absolute Error (MAE)\n",
    "\t\tabs_errors = torch.abs(outputs - y)\n",
    "\t\ttest_maes += abs_errors.sum().item()\n",
    "\n",
    "\t\t# Maximum Absolute Error (Max AE)\n",
    "\t\tmax_ae = abs_errors.max().item()\n",
    "\t\ttest_max_aes = max(test_max_aes, max_ae)\n",
    "\n",
    "\t\t# Mean Relative Error (MRE)\n",
    "\t\tmask = y >= 1e-10\n",
    "\t\ty_m = y[mask]\n",
    "\t\trelative_errors = torch.abs(outputs[mask] - y_m ) / y_m\n",
    "\n",
    "\t\t# Calculate MRE\n",
    "\t\ttest_mres += relative_errors.sum().item()\n",
    "\t\tcnt += len(relative_errors)\n",
    "\n",
    "\t\t# Calculate max relative error\n",
    "\t\ttest_max_res = max(test_max_res, relative_errors.max().item())\n",
    "\n",
    "\n",
    "# Calculate the average metrics over all test samples for each model\n",
    "avg_test_loss = test_losses / len(test_loader.dataset)\n",
    "avg_test_mae = test_maes / len(test_loader.dataset)\n",
    "avg_test_mre = test_mres / cnt\n",
    "\n",
    "print('-'*250)\n",
    "print(f\"{model.name:<50} Results | MSE: {avg_test_loss:<25} | MAE: {avg_test_mae:<25} | Max AE: {test_max_aes:<25} | MRE: {avg_test_mre:<25} | Max RE: {test_max_res:<25}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model                                        Results | MSE: 4.767372257527874e-09     | MAE: 0.0008842677848565959     | Max AE: 0.010480693476281389      | MRE: 8610.273830920263         | Max RE: 24765156.665712476   \n",
    "</br>\n",
    "delta 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model                                        Results | MSE: 1.7072262899170862e-08    | MAE: 0.0014622379697655967     | Max AE: 0.012304333512939192      | MRE: 19133.356655940905        | Max RE: 32084991.04810058        \n",
    "</br>\n",
    "Huber loss delta = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model                                        Results | MSE: 6.5584848876120205e-09    | MAE: 0.0010204205638990932     | Max AE: 0.01436321507469207       | MRE: 21704.53521771374         | Max RE: 39553088.01572265\n",
    "</br>\n",
    "Huber loss delta = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model                                        Results | MSE: 9.577022434796093e-09     | MAE: 0.001128070044492659      | Max AE: 0.01750700016971668       | MRE: 0.0                       | Max RE: 0.0   \n",
    "with grad norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model                                        Results | MSE: 3.437281101835667e-08     | MAE: 0.0014345937355705574     | Max AE: 0.026702327077854637      | MRE: 0.0                       | Max RE: 0.0          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model                                        Results | MSE: 4.870335576499605e-09     | MAE: 0.0006644182282886656     | Max AE: 0.02035231469468729       | MRE: 0.0                       | Max RE: 0.0     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model                                        Results | MSE: 3.0745519796730916e-09    | MAE: 0.0006669217488797097     | Max AE: 0.01045388565348454       | MRE: 0.0                       | Max RE: 0.0    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model                                        Results | MSE: 5.394526925641141e-09     | MAE: 0.0007469986503670395     | Max AE: 0.024494726553518364      | MRE: 0.0                       | Max RE: 0.0   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model                                        Results | MSE: 9.944437335789435e-10     | MAE: 0.0002790903619311921     | Max AE: 0.020291466710218475      | MRE: 0.0                       | Max RE: 5.520420072604463e+31    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Base Model\t\t\t\t\t\t\t\t\t\t Results | MSE: 3.700808076204782e-09\t | MAE: 0.0006494232504191063\t | Max AE: 0.02520344930434637\t   | MRE: 207.39712310149338\t\t| Max RE: 115508.51118180675 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Normal\n",
    "\n",
    "def d1(K, T, sigma, F):\n",
    "\treturn (torch.log(F / K) + (0.5 * sigma**2) * T) / (sigma * torch.sqrt(T))\n",
    "\n",
    "def d2(d1, T, sigma):\n",
    "\treturn d1 - sigma * torch.sqrt(T)\n",
    "\n",
    "def delta(d1, F=1, option_type='call'):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\n",
    "\tif option_type == 'call':\n",
    "\t\treturn normal_dist.cdf(d1)\n",
    "\telif option_type == 'put':\n",
    "\t\treturn normal_dist.cdf(d1) - 1\n",
    "\telse:\n",
    "\t\traise ValueError(\"Option type must be 'call' or 'put'\")\n",
    "\n",
    "def gamma(T, sigma, d1, F=1):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\tpdf_d1 = torch.exp(normal_dist.log_prob(d1)) \n",
    "\n",
    "\treturn pdf_d1 / (F * sigma * torch.sqrt(T))\n",
    "\n",
    "def theta(K, T, sigma, d1, d2, F=1, r=0, option_type='call'):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\tpdf_d1 = torch.exp(normal_dist.log_prob(d1)) \n",
    "\n",
    "\tif option_type == 'call':\n",
    "\t\treturn (-F * pdf_d1 * sigma / (2 * torch.sqrt(T)) - r * K * torch.exp(-r * T) * normal_dist.cdf(d2))\n",
    "\telif option_type == 'put':\n",
    "\t\treturn (-F * pdf_d1 * sigma / (2 * torch.sqrt(T)) + r * K * torch.exp(-r * T) * normal_dist.cdf(-d2))\n",
    "\telse:\n",
    "\t\traise ValueError(\"Option type must be 'call' or 'put'\")\n",
    "\n",
    "def vega(T, d1, F=1):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\tpdf_d1 = torch.exp(normal_dist.log_prob(d1))\n",
    "\t\n",
    "\treturn F * pdf_d1 * torch.sqrt(T)\n",
    "\n",
    "def greeks(K, T, sigma, F=1, r=0, option_type='call'):\n",
    "\tdp = d1(K, T, sigma, F)\n",
    "\tdm = d2(dp, T, sigma)\n",
    "\t\n",
    "\treturn delta(dp, F, option_type), gamma(T, sigma, dp, F), theta(K, T, sigma, dp, dm, F, r, option_type), vega(T, dp, F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "K = np.random.uniform(1, 2.5, num_samples)\n",
    "T = np.random.uniform(0.004, 4, num_samples)\n",
    "sigma = np.random.uniform(0.1, 0.5, num_samples)\n",
    "\n",
    "# Подготовка данных\n",
    "X = np.vstack((K, T, np.log(K), sigma * np.sqrt(T), sigma**2 * T)).T\n",
    "X_tensor = torch.tensor(X, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "prices = torch.tensor(black_model(1, K, T, sigma), dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    # Входные данные для модели\n",
    "    y = model(X_tensor, X_tensor[:, 0])\n",
    "    y = (y[:, 0] + y[:, 1] ) / 2\n",
    "\n",
    "    abs_errors = torch.abs(y - prices)\n",
    "    relative_errors = abs_errors / (prices+1)\n",
    "\n",
    "    # Mean Squared Error (MSE)\n",
    "    mse = F.mse_loss(y, prices).item()\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = F.l1_loss(y, prices)\n",
    "\n",
    "    # Mean Relative Error (MRE)\n",
    "    mre = relative_errors.mean().item()\n",
    "    max_mre = relative_errors.max().item()\n",
    "\n",
    "    print(model.name)\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae.item()}\")\n",
    "    print(f\"Max Absolute Error (MAE): {abs_errors.max().item()}\")\n",
    "    print(f\"Mean Relative Error (MRE): {mre}\")\n",
    "    print(f\"Max Relative Error (MRE): {max_mre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor(X, dtype=torch.float64)\n",
    "greeks_result = greeks(X_test[:, 0], X_test[:, 1], X_test[:, 3] / torch.sqrt(X_test[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Фиксируем seed для повторяемости\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_delta_loss = float('inf')\n",
    "\n",
    "for model in models:\n",
    "    model.zero_grad()  # Сброс градиентов модели\n",
    "    \n",
    "    y = model(X_tensor, X_tensor[:, 0])\n",
    "    y = (y[:, 0] + y[:, 1] ) / 2\n",
    "\n",
    "    y.backward(torch.ones_like(y), retain_graph=True)\n",
    "    K_grad = X_tensor.grad[:, 0].clone()  \n",
    "    # T_grad = X_tensor.grad[:, 1].clone()  \n",
    "    # sigma_grad = (X_tensor.grad[:, 3] / torch.sqrt(X_tensor[:, 1])).clone()\n",
    "\n",
    "    X_tensor.grad.zero_()\n",
    "\n",
    "    y = model(X_tensor, X_tensor[:, 0])\n",
    "    y = (y[:, 0] + y[:, 1] ) / 2\n",
    "    y.backward(torch.ones_like(y), retain_graph=True)\n",
    "    delta_grad = X_tensor.grad[:, 0].clone().requires_grad_(True)\n",
    "\n",
    "    X_tensor.grad.zero_()\n",
    "\n",
    "    # Вычисление второго градиента (гамма)\n",
    "    y = model(X_tensor, X_tensor[:, 0])\n",
    "    y = (y[:, 0] + y[:, 1] ) / 2\n",
    "    y.backward(torch.ones_like(y), retain_graph=True)\n",
    "    delta_grad.backward(torch.ones_like(delta_grad), retain_graph=True)\n",
    "    gamma_grad = X_tensor.grad[:, 0].clone()\n",
    "\n",
    "    delta_loss = F.mse_loss(delta_grad, greeks_result[0]).item()\n",
    "    gamma_loss = F.mse_loss(gamma_grad, greeks_result[1]).item()\n",
    "    # theta_loss = F.mse_loss(T_grad, greeks_result[2]).item()\n",
    "    # vega_loss = F.mse_loss(sigma_grad, greeks_result[3]).item()\n",
    "\n",
    "    print(\"Losses for current model:\")\n",
    "    print('Delta: ', delta_loss)\n",
    "    print('Gamma: ', gamma_loss)\n",
    "    # print('Theta: ', theta_loss)\n",
    "    # print('Vega: ', vega_loss)\n",
    "\n",
    "    # Обновляем лучшую модель, если текущая потеря меньше\n",
    "    if delta_loss < best_delta_loss:\n",
    "        best_delta_loss = delta_loss\n",
    "        best_model = model\n",
    "        print(\"BEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.31773413313771937\n",
    "# Gamma:  0.4675530959663658\n",
    "# BEST\n",
    "# Losses for current model:\n",
    "# Delta:  0.36055910418366055\n",
    "# Gamma:  0.46662030548794636\n",
    "# Losses for current model:\n",
    "# Delta:  0.18808245800508253\n",
    "# Gamma:  0.6032933942451526\n",
    "# BEST\n",
    "# Losses for current model:\n",
    "# Delta:  0.07482774754537738\n",
    "# Gamma:  0.3696942615925675\n",
    "# BEST\n",
    "# Losses for current model:\n",
    "# Delta:  0.08975779851276083\n",
    "# Gamma:  0.37198183650112987\n",
    "# Losses for current model:\n",
    "# Delta:  0.07410881417557123\n",
    "# Gamma:  0.3720982720526203\n",
    "# BEST\n",
    "# Losses for current model:\n",
    "# Delta:  0.16065372665977634\n",
    "# Gamma:  0.3939146144624482\n",
    "# ...\n",
    "# Gamma:  0.3581884162799414\n",
    "# Losses for current model:\n",
    "# Delta:  0.09569938113053318\n",
    "# Gamma:  0.3626274626164527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.3170565694387127\n",
    "# Gamma:  0.46924481339153173\n",
    "# BEST\n",
    "# Losses for current model:\n",
    "# Delta:  0.3740551989443388\n",
    "# Gamma:  0.4684181799050302\n",
    "# Losses for current model:\n",
    "# Delta:  0.18799129964504166\n",
    "# Gamma:  0.6036873977024664\n",
    "# BEST\n",
    "# Losses for current model:\n",
    "# Delta:  0.0742122219050141\n",
    "# Gamma:  0.3701475459191158\n",
    "# BEST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
