{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\serpo\\Documents\\Python\\Black\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:258: UserWarning: Failed to initialize NumPy: No module named 'numpy.core._exceptions' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_model(F, K, T, sigma, option_type='call'):\n",
    "\t# Parameters\n",
    "\td1 = (np.log(F / K) + (sigma**2 / 2) * T) / (sigma * np.sqrt(T))\n",
    "\td2 = d1 - sigma * np.sqrt(T)\n",
    "\t\n",
    "\t# Discount factor (assuming risk-free rate is 0)\n",
    "\tDF_T = 1\n",
    "\t\n",
    "\tif option_type == 'call':\n",
    "\t\treturn DF_T * (F * norm.cdf(d1) - K * norm.cdf(d2))\n",
    "\telif option_type == 'put':\n",
    "\t\treturn DF_T * (K * norm.cdf(-d2) - F * norm.cdf(-d1))\n",
    "\telse:\n",
    "\t\traise ValueError(\"option_type must be 'call' or 'put'\")\n",
    "\n",
    "def generate_data(num_samples, S=1):\n",
    "\t# Generate random parameters\n",
    "\tK = np.random.uniform(1, 2.5, num_samples)\n",
    "\tT = np.random.uniform(0.004, 4, num_samples)\n",
    "\tsigma = np.random.uniform(0.1, 0.5, num_samples)\n",
    "\n",
    "\tcall_prices = black_model(S, K, T, sigma, option_type='call')\n",
    "\t\n",
    "\t# Prepare input data matrix X\n",
    "\tX = np.vstack((K, T, np.log(K), sigma * np.sqrt(T), sigma**2 * T)).T\n",
    "\ty = call_prices\n",
    "\t\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_static_test_data(num_test_samples=100000):\n",
    "\tX_test, y_test = generate_data(num_samples=num_test_samples)\n",
    "\n",
    "\t# Преобразуем в тензоры\n",
    "\tX_test_tensor = torch.tensor(X_test, dtype=torch.float64, requires_grad=True)\n",
    "\ty_test_tensor = torch.tensor(y_test, dtype=torch.float64, requires_grad=True).unsqueeze(1)\n",
    "\n",
    "\t# Сохраняем данные\n",
    "\ttorch.save((X_test_tensor, y_test_tensor), 'static_test_data.pt')\n",
    "\n",
    "def load_static_test_data():\n",
    "\t# Загружаем данные из файла\n",
    "\tX_test_tensor, y_test_tensor = torch.load('static_test_data.pt')\n",
    "\n",
    "\treturn X_test_tensor, y_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_prepare_training_data(num_train_samples=1000000, batch_size=128):\n",
    "\tX_train, y_train = generate_data(num_samples=num_train_samples)\n",
    "\n",
    "\tX_train_tensor = torch.tensor(X_train, dtype=torch.float64)\n",
    "\ty_train_tensor = torch.tensor(y_train, dtype=torch.float64).unsqueeze(1)\n",
    "\n",
    "\ttrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\ttrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\treturn train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackScholesNet(nn.Module):\n",
    "\tdef __init__(self, input_size=1, hidden_size=128, output_size=1, dropout_p = 0.33):\n",
    "\t\tsuper(BlackScholesNet, self).__init__()\n",
    "\t\tself.fc1 = nn.Linear(input_size, hidden_size, dtype=torch.float64)\n",
    "\t\tself.bn1 = nn.BatchNorm1d(hidden_size, dtype=torch.float64)  # Batch Normalization\n",
    "\t\tself.fc2 = nn.Linear(hidden_size, hidden_size, dtype=torch.float64)\n",
    "\t\tself.bn2 = nn.BatchNorm1d(hidden_size, dtype=torch.float64)  # Batch Normalization\n",
    "\t\tself.fc3 = nn.Linear(hidden_size, output_size, dtype=torch.float64)\n",
    "\t\tself.dropout = nn.Dropout(p=dropout_p)  # Dropout for regularization\n",
    "\t\tself.name = 'Black Model'\n",
    "\n",
    "\tdef forward(self, x, K):\n",
    "\t\tx = F.tanh(self.bn1(self.fc1(x)))  # Tanh and Batch Normalization\n",
    "\t\tx = self.dropout(x)  # Dropout\n",
    "\t\tx = F.tanh(self.bn2(self.fc2(x)))  # Tanh and Normalization\n",
    "\t\tx = self.fc3(x)\n",
    "\t\tx1, x2 = x[:, [0]], x[:, [1]]\n",
    "\t\treturn F.sigmoid(x1) - K * F.sigmoid(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackScholesNet(nn.Module):\n",
    "\tdef __init__(self, input_size=1, hidden_size=128, output_size=1, dropout_p=0.3):\n",
    "\t\tsuper(BlackScholesNet, self).__init__()\n",
    "\t\tself.fc1 = nn.Linear(input_size, hidden_size, dtype=torch.float64)\n",
    "\t\tself.bn1 = nn.BatchNorm1d(hidden_size, dtype=torch.float64)\n",
    "\t\tself.fc2 = nn.Linear(hidden_size, hidden_size, dtype=torch.float64)\n",
    "\t\tself.bn2 = nn.BatchNorm1d(hidden_size, dtype=torch.float64)\n",
    "\t\tself.fc_out = nn.Linear(hidden_size, output_size, dtype=torch.float64)\n",
    "\t\tself.dropout = nn.Dropout(p=dropout_p)\n",
    "\t\tself.name = 'Black ResNet Model'\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tresidual = self.fc1(x)  # Transform residual to match shape of x\n",
    "\t\tx = F.relu(self.bn1(self.fc1(x)))\n",
    "\t\tx = self.dropout(x)\n",
    "\t\tx = F.relu(self.bn2(self.fc2(x)))\n",
    "\t\tx = x + residual  # Adding the skip connection after matching dimensions\n",
    "\t\tx = self.fc_out(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackScholesNet(nn.Module):\n",
    "\tdef __init__(self, input_size=1, hidden_size=128, output_size=1, num_layers=2, dropout_p=0.3):\n",
    "\t\tsuper(BlackScholesNet, self).__init__()\n",
    "\t\tself.rnn = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, dtype=torch.float64)\n",
    "\t\tself.fc = nn.Linear(hidden_size, output_size, dtype=torch.float64)\n",
    "\t\tself.dropout = nn.Dropout(p=dropout_p)\n",
    "\t\tself.name = 'Black RNN Model'\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx, _ = self.rnn(x)\n",
    "\t\tx = self.fc(x[:, -1, :])  # Take output of the last time step\n",
    "\t\treturn  F.tanh(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 500000\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_static_test_data(num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor, y_test_tensor = load_static_test_data()\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding optimal hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = generate_and_prepare_training_data(1000000, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor, y_test_tensor = load_static_test_data()\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def objective(trial):\n",
    "\t# Define hyperparameters to be optimized\n",
    "\tinput_size = 5\n",
    "\thidden_size = 128\n",
    "\t# dropout_p = trial.suggest_float('dropout_p', 0.1, 0.5)\n",
    "\t# lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "\tdropout_p = 0.20862014926048447\n",
    "\tlr = 0.0002448376394581503\n",
    "\t\n",
    "\tmodel = BlackScholesNet(input_size=input_size, hidden_size=hidden_size, output_size=2)\n",
    "\tmodel.dropout.p = dropout_p\n",
    "\n",
    "\toptimizer = torch.optim.NAdam(model.parameters(), lr=lr)\n",
    "\t\n",
    "\tscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\n",
    "\tnum_epochs = 30\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tmodel.train()\n",
    "\t\tepoch_mse = 0\n",
    "\t\tepoch_mae = 0\n",
    "\t\tepoch_mre = 0\n",
    "\t\t\n",
    "\t\tfor X_batch, y_batch in train_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\t\t\t\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\n",
    "\t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\t\toutputs = (outputs[:, 0] + outputs[:, 1]) / 2\n",
    "\t\t\ty = y_batch[:, 0]\n",
    "\t\t\t\n",
    "\t\t\t# mse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "\t\t\t# relative_errors = torch.abs(outputs - y) / (y + 1e-8)\n",
    "\t\t\t# mre_loss = relative_errors.mean()\n",
    "\t\t\t\n",
    "\t\t\tmae_loss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t\n",
    "\t\t\t# epoch_mse += mse_loss.item()\n",
    "\t\t\tepoch_mae += mae_loss.item()\n",
    "\t\t\t# epoch_mre += mre_loss.item()\n",
    "\t\t\n",
    "\t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "\t\tscheduler.step(avg_epoch_mae)\n",
    "\t\t\n",
    "\ttest_losses = 0.\n",
    "\ttest_maes = 0.\n",
    "\ttest_max_aes = 0.\n",
    "\ttest_mres = 0.\n",
    "\ttest_max_res = 0.\n",
    "\n",
    "\tmodel.eval()\n",
    "\n",
    "\twith torch.inference_mode():\n",
    "\t\tfor X_batch, y_batch in test_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\t\t\t# Forward pass\n",
    "\t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\t\toutputs = (outputs[:, 0] + outputs[:, 1]) / 2\n",
    "\t\t\t\n",
    "\t\t\ty = y_batch[:, 0]\n",
    "\n",
    "\t\t\t# Mean Squared Error (MSE)\n",
    "\t\t\t# mse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\t# test_losses += mse_loss.item()\n",
    "\n",
    "\t\t\t# Mean Absolute Error (MAE)\n",
    "\t\t\tabs_errors = torch.abs(outputs - y)\n",
    "\t\t\ttest_maes += abs_errors.sum().item()\n",
    "\n",
    "\t\t\t# # Maximum Absolute Error (Max AE)\n",
    "\t\t\t# max_ae = abs_errors.max().item()\n",
    "\t\t\t# test_max_aes = max(test_max_aes, max_ae)\n",
    "\n",
    "\t\t\t# # Mean Relative Error (MRE)\n",
    "\t\t\t# mask = y == 0\n",
    "\t\t\t# zero_price_mre = abs_errors[mask]\n",
    "\t\t\t# price_mre = abs_errors[~mask]\n",
    "\n",
    "\t\t\t# # Avoid division by zero for non-zero y values\n",
    "\t\t\t# nonzero_y = y[~mask]\n",
    "\t\t\t# price_mre = price_mre / nonzero_y if nonzero_y.numel() > 0 else price_mre\n",
    "\n",
    "\t\t\t# # Calculate MRE\n",
    "\t\t\t# total_mre = zero_price_mre.sum() + price_mre.sum()\n",
    "\t\t\t# test_mres += total_mre.item() if zero_price_mre.numel() > 0 or price_mre.numel() > 0 else 0\n",
    "\n",
    "\t\t\t# # Handle empty tensors and `inf` values for Max RE\n",
    "\t\t\t# zero_price_max = zero_price_mre.max() if zero_price_mre.numel() > 0 else 0\n",
    "\t\t\t# price_max = price_mre.max() if price_mre.numel() > 0 else 0\n",
    "\n",
    "\t\t\t# # Calculate max relative error\n",
    "\t\t\t# max_re = max(zero_price_max.item(), price_max.item())\n",
    "\t\t\t# test_max_res = max(test_max_res, max_re)\n",
    "\n",
    "\t# avg_test_loss = test_losses / len(test_loader.dataset)\n",
    "\tavg_test_mae = test_maes / len(test_loader.dataset)\n",
    "\t# avg_test_mre = test_mres / len(test_loader.dataset)\n",
    "\t\t\t\n",
    "\t# Return the average MAE as the objective to be minimized\n",
    "\treturn avg_test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print best parameters and best value\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best MAE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters: {'dropout_p': 0.20862014926048447, 'lr': 0.0002448376394581503}\n",
    "Best MAE: 0.00049047276004533371"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_p = 0.20862014926048447\n",
    "lr = 0.0002448376394581503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BlackScholesNet(input_size=5, hidden_size=128, output_size=2)\n",
    "model.dropout.p = dropout_p\n",
    "optimizer = optim.NAdam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('models\\\\Black Model_mae.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlackScholesNet(\n",
       "  (fc1): Linear(in_features=5, out_features=128, bias=True)\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.20862014926048447, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters: {'hidden_size': 256, 'dropout_p': 0.16165214075232218, 'lr': 0.0024867405570057574, 'batch_size': 64, 'optimizer': 'NAdam'}\n",
    "Best MAE: 0.003318011008932989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters: {'hidden_size': 128, 'dropout_p': 0.3974039374569882, 'lr': 0.012408717790861197, 'batch_size': 128, 'optimizer': 'NAdam'}\n",
    "Best MAE: 0.008668262018621945"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = 2000000\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = generate_and_prepare_training_data(num_train_samples, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "num_stages = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "\tif isinstance(m, nn.Linear):\n",
    "\t\tnn.init.xavier_uniform_(m.weight)\n",
    "\t\tif m.bias is not None:\n",
    "\t\t\tnn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlackScholesNet(\n",
       "  (fc1): Linear(in_features=5, out_features=128, bias=True)\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.20862014926048447, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(y_pred, y_true, delta=1.0):\n",
    "\terror = y_true - y_pred\n",
    "\tis_small_error = torch.abs(error) <= delta\n",
    "\tsmall_error_loss = 0.5 * error**2\n",
    "\tlarge_error_loss = delta * (torch.abs(error) - 0.5 * delta)\n",
    "\n",
    "\treturn torch.where(is_small_error, small_error_loss, large_error_loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stage in range(num_stages):\n",
    "\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ***** Stage [{stage+1}/{num_stages}] {'*'*150}\")\n",
    "\t\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tepoch_huber = 0.\n",
    "\t\tepoch_mae = 0.\n",
    "\t\tepoch_mre = 0.\n",
    "\t\tepoch_mse = 0.\n",
    "\t\t\n",
    "\t\tfor X_batch, y_batch in train_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\t\t\t# X_batch = X_batch.unsqueeze(1)  # Add a dimension for sequence length\n",
    "\t\t\tmodel.train()\n",
    "\t\t\t\n",
    "\t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\t\toutputs = (outputs[:, 0] + outputs[:, 1] ) / 2\n",
    "\t\t\t# outputs = outputs[:, 0]\n",
    "\t\t\ty = y_batch[:, 0]\n",
    "\t\t\t\n",
    "\t\t\t# Calculate losses\n",
    "\t\t\thub_loss = huber_loss(outputs, y, 0.02)\n",
    "\t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "\t\t\tmask = y >= 1e-10\n",
    "\t\t\ty_m = y[mask]\n",
    "\t\t\trelative_errors = torch.abs(outputs[mask] - y_m ) / y_m\n",
    "\t\t\tmre_loss = relative_errors.mean()\n",
    "\t\t\t\n",
    "\t\t\t# Backpropagation\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\thub_loss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t\n",
    "\t\t\t# Accumulate losses\n",
    "\t\t\tepoch_mse += mse_loss.item()\n",
    "\t\t\tepoch_mae += mae_loss.item()\n",
    "\t\t\tepoch_mre += mre_loss.item()\n",
    "\t\t\tepoch_huber += hub_loss\n",
    "\t\t\n",
    "\t\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "\n",
    "\t\tavg_epoch_huber = epoch_huber / len(train_loader)\n",
    "\t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "\t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "\t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\t\t\n",
    "\t\tprint(f\"{model.name:<50} | Huber loss: {avg_epoch_huber:<25} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\t\t\n",
    "\t\tscheduler.step(avg_epoch_huber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Normal\n",
    "\n",
    "def d1(K, T, sigma, F):\n",
    "\treturn (torch.log(F / K) + (0.5 * sigma**2) * T) / (sigma * torch.sqrt(T))\n",
    "\n",
    "def d2(d1, T, sigma):\n",
    "\treturn d1 - sigma * torch.sqrt(T)\n",
    "\n",
    "def delta(d1, F=1, option_type='call'):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\n",
    "\tif option_type == 'call':\n",
    "\t\treturn normal_dist.cdf(d1)\n",
    "\telif option_type == 'put':\n",
    "\t\treturn normal_dist.cdf(d1) - 1\n",
    "\telse:\n",
    "\t\traise ValueError(\"Option type must be 'call' or 'put'\")\n",
    "\n",
    "def gamma(T, sigma, d1, F=1):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\tpdf_d1 = torch.exp(normal_dist.log_prob(d1)) \n",
    "\n",
    "\treturn pdf_d1 / (F * sigma * torch.sqrt(T))\n",
    "\n",
    "def theta(K, T, sigma, d1, d2, F=1, r=0, option_type='call'):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\tpdf_d1 = torch.exp(normal_dist.log_prob(d1)) \n",
    "\n",
    "\tif option_type == 'call':\n",
    "\t\treturn (-F * pdf_d1 * sigma / (2 * torch.sqrt(T)) - r * K * torch.exp(-r * T) * normal_dist.cdf(d2))\n",
    "\telif option_type == 'put':\n",
    "\t\treturn (-F * pdf_d1 * sigma / (2 * torch.sqrt(T)) + r * K * torch.exp(-r * T) * normal_dist.cdf(-d2))\n",
    "\telse:\n",
    "\t\traise ValueError(\"Option type must be 'call' or 'put'\")\n",
    "\n",
    "def vega(T, d1, F=1):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\tpdf_d1 = torch.exp(normal_dist.log_prob(d1))\n",
    "\t\n",
    "\treturn F * pdf_d1 * torch.sqrt(T)\n",
    "\n",
    "def greeks(K, T, sigma, F=1, r=0, option_type='call'):\n",
    "\tdp = d1(K, T, sigma, F)\n",
    "\tdm = d2(dp, T, sigma)\n",
    "\t\n",
    "\treturn delta(dp, F, option_type), gamma(T, sigma, dp, F), theta(K, T, sigma, dp, dm, F, r, option_type), vega(T, dp, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stage in range(num_stages):\n",
    "\tprint(f\"[ {datetime.now().strftime('%H:%M:%S')} ] ***** Stage [{stage+1}/{num_stages}] {'*'*150}\")\n",
    "\t\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tcnt = 0\n",
    "\t\tepoch_huber = 0.\n",
    "\t\tepoch_mae = 0.\n",
    "\t\tepoch_mre = 0.\n",
    "\t\tepoch_mse = 0.\n",
    "\t\tepoch_delta_loss = 0.\n",
    "\t\tepoch_gamma_loss = 0.\n",
    "\t\t\n",
    "\t\tfor X_batch, y_batch in train_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\t\t\tX_batch = X_batch.clone().detach().requires_grad_(True)#torch.tensor(X_batch, dtype=torch.float64, requires_grad=True)\n",
    "\t\t\ty_batch = y_batch.clone().detach().requires_grad_(True)#torch.tensor(y_batch, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "\t\t\tmodel.train()\n",
    "\t\t\t\n",
    "\t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\t\toutputs = (outputs[:, 0] + outputs[:, 1]) / 2\n",
    "\t\t\ty = y_batch[:, 0]\n",
    "\t\t\t\n",
    "\t\t\t# Вычисление основных потерь\n",
    "\t\t\thub_loss = huber_loss(outputs, y, 0.02)\n",
    "\t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "\t\t\tmask = y >= 1e-10\n",
    "\t\t\ty_m = y[mask]\n",
    "\t\t\trelative_errors = torch.abs(outputs[mask] - y_m) / y_m\n",
    "\t\t\tmre_loss = relative_errors.mean()\n",
    "\t\t\t\n",
    "\t\t\t# Обнуление градиентов перед вычислением грека\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\t\t# --- Вычисление дельты и гаммы ---\n",
    "\t\t\tdeltas, gammas, thetas, vegas = greeks(X_batch[:, 0], X_batch[:, 1], X_batch[:, 3] / torch.sqrt(X_batch[:, 1]))\n",
    "\n",
    "\t\t\toutputs.backward(torch.ones_like(outputs), retain_graph=True)\n",
    "\t\t\tK_grad = X_batch.grad[:, 0].clone()  \n",
    "\n",
    "\t\t\tX_batch.grad.zero_()\n",
    "\n",
    "\t\t\ty = model(X_batch, X_batch[:, 0])\n",
    "\t\t\ty = (y[:, 0] + y[:, 1] ) / 2\n",
    "\t\t\t# y = y[:, 0]\n",
    "\t\t\ty.backward(torch.ones_like(y), retain_graph=True)\n",
    "\t\t\tdelta_grad = X_batch.grad[:, 0].clone().requires_grad_(True)\n",
    "\n",
    "\t\t\tX_batch.grad.zero_()\n",
    "\n",
    "\t\t\t# Вычисление второго градиента (гамма)\n",
    "\t\t\ty = model(X_batch, X_batch[:, 0])\n",
    "\t\t\ty = (y[:, 0] + y[:, 1] ) / 2\n",
    "\t\t\t# y = y[:, 0]\n",
    "\t\t\ty.backward(torch.ones_like(y), retain_graph=True)\n",
    "\t\t\tdelta_grad.backward(torch.ones_like(delta_grad), retain_graph=True)\n",
    "\t\t\tgamma_grad = X_tensor.grad[:, 0].clone()\n",
    "\n",
    "\t\t\t# --- Вычисление потерь по дельте ---\n",
    "\t\t\toutputs.backward(torch.ones_like(outputs), retain_graph=True)  # Рассчитываем дельту\n",
    "\t\t\tdelta_pred = X_batch.grad[:, 0].clone().requires_grad_(True)  # Градиент по K — это дельта\n",
    "\t\t\tdelta_loss = F.mse_loss(delta_pred, deltas)\n",
    "\n",
    "\t\t\t# Обнуление градиентов для следующего шага\n",
    "\t\t\tX_batch.grad.zero_()\n",
    "\n",
    "\t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\t\toutputs = (outputs[:, 0] + outputs[:, 1]) / 2\n",
    "\n",
    "\t\t\t# --- Вычисление потерь по гамме ---\n",
    "\t\t\toutputs.backward(torch.ones_like(delta_pred), retain_graph=True)  # Рассчитываем гамму\n",
    "\t\t\tdelta_pred.backward(torch.ones_like(delta_pred), retain_graph=True)\n",
    "\t\t\tgamma_pred = X_batch.grad[:, 0].clone().detach()  # Градиент дельты — это гамма\n",
    "\t\t\tgamma_loss = F.mse_loss(gamma_pred, gammas)\n",
    "\n",
    "\t\t\t# Назад по градиенту для обновления параметров\n",
    "\t\t\tdelta_loss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t\n",
    "\t\t\t# Аккумулируем потери для статистики\n",
    "\t\t\tepoch_mse += mse_loss.item()\n",
    "\t\t\tepoch_mae += mae_loss.item()\n",
    "\t\t\tepoch_mre += mre_loss.item()\n",
    "\t\t\tepoch_huber += hub_loss.item()\n",
    "\t\t\tepoch_delta_loss += delta_loss.item()\n",
    "\t\t\tepoch_gamma_loss += gamma_loss.item()\n",
    "\n",
    "\t\t# Логируем результаты для текущей эпохи\n",
    "\t\tprint(f\"[ {datetime.now().strftime('%H:%M:%S')} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "\t\tavg_epoch_huber = epoch_huber / len(train_loader)\n",
    "\t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "\t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "\t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\t\tavg_delta_loss = epoch_delta_loss / len(train_loader)\n",
    "\t\tavg_gamma_loss = epoch_gamma_loss / len(train_loader)\n",
    "\n",
    "\t\tprint(f\"{model.name:<25} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} | Delta Loss: {avg_delta_loss:<25} | Gamma Loss: {avg_gamma_loss:<25} |\")\n",
    "\t\t\n",
    "\t\tscheduler.step(avg_delta_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stage in range(num_stages):\n",
    "\tprint(f\"[ {datetime.now().strftime('%H:%M:%S')} ] ***** Stage [{stage+1}/{num_stages}] {'*'*150}\")\n",
    "\t\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tepoch_huber, epoch_mae, epoch_mre = 0., 0., 0.\n",
    "\t\tepoch_mse, epoch_delta_loss, epoch_gamma_loss = 0., 0., 0.\n",
    "\t\t\n",
    "\t\tfor X_batch, y_batch in train_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t# Включение градиентов для X_batch\n",
    "\t\t\tX_batch = X_batch.clone().detach().requires_grad_(True)\n",
    "\t\t\ty_batch = y_batch.clone().detach().requires_grad_(True)\n",
    "\n",
    "\t\t\tmodel.train()\n",
    "\t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\t\toutputs = (outputs[:, 0] + outputs[:, 1]) / 2\n",
    "\t\t\ty = y_batch[:, 0]\n",
    "\t\t\t\n",
    "\t\t\t# Основные потери\n",
    "\t\t\thub_loss = huber_loss(outputs, y, 0.02)\n",
    "\t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "\t\t\t\n",
    "\t\t\t# Вычисление относительных ошибок\n",
    "\t\t\tmask = y >= 1e-10\n",
    "\t\t\ty_m = y[mask]\n",
    "\t\t\trelative_errors = torch.abs(outputs[mask] - y_m) / y_m\n",
    "\t\t\tmre_loss = relative_errors.mean()\n",
    "\n",
    "\t\t\t# --- Вычисление дельты ---\n",
    "\t\t\tdeltas, gammas, thetas, vegas = greeks(X_batch[:, 0], X_batch[:, 1], X_batch[:, 3] / torch.sqrt(X_batch[:, 1]))\n",
    "\n",
    "\t\t\t# Рассчитываем градиент по страйку (дельту)\n",
    "\t\t\toutputs.backward(torch.ones_like(outputs), retain_graph=True)\n",
    "\t\t\tdelta_grad = X_batch.grad[:, 0].clone().requires_grad_(True)  # Сохраняем градиенты\n",
    "\n",
    "\t\t\t# # Рассчитываем второй градиент (гамму)\n",
    "\t\t\t# delta_grad.backward(torch.ones_like(delta_grad), retain_graph=True)\n",
    "\t\t\t# gamma_grad = X_batch.grad[:, 0].clone().detach()\n",
    "\n",
    "\t\t\t# Вычисление потерь по дельте и гамме\n",
    "\t\t\tdelta_loss = F.mse_loss(delta_grad, deltas)\n",
    "\t\t\t# gamma_loss = F.mse_loss(gamma_grad, gammas)\n",
    "\n",
    "\t\t\t# Назад по градиенту для обновления параметров\n",
    "\t\t\toptimizer.zero_grad()  # Обнуление градиентов перед шагом\n",
    "\t\t\tdelta_loss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t# Аккумулируем потери для статистики\n",
    "\t\t\tepoch_huber += hub_loss.item()\n",
    "\t\t\tepoch_mse += mse_loss.item()\n",
    "\t\t\tepoch_mae += mae_loss.item()\n",
    "\t\t\tepoch_mre += mre_loss.item()\n",
    "\t\t\tepoch_delta_loss += delta_loss.item()\n",
    "\t\t\t# epoch_gamma_loss += gamma_loss.item()\n",
    "\n",
    "\t\t# Логирование\n",
    "\t\tavg_epoch_huber = epoch_huber / len(train_loader)\n",
    "\t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "\t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "\t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\t\tavg_delta_loss = epoch_delta_loss / len(train_loader)\n",
    "\t\tavg_gamma_loss = 0#epoch_gamma_loss / len(train_loader)\n",
    "\n",
    "\t\tprint(f\"[ {datetime.now().strftime('%H:%M:%S')} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "\t\tprint(f\"{model.name:<25} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} | Delta Loss: {avg_delta_loss:<25} | Gamma Loss: {avg_gamma_loss:<25} |\")\n",
    "\t\t\n",
    "\t\tscheduler.step(avg_delta_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-cosh loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18:51:10 ] ***** Stage [1/1] ******************************************************************************************************************************************************\n",
      "[ 18:51:30 ] ----- Epoch [1/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 0.01731447072122037       | MAE: 0.089106594409645         | MRE: 3058633.5212305137        |\n",
      "[ 18:51:50 ] ----- Epoch [2/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 0.0010450003118724588     | MAE: 0.023971658696214888      | MRE: 771303.588995485          |\n",
      "[ 18:52:09 ] ----- Epoch [3/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 0.0001512994754532175     | MAE: 0.00895387339441951       | MRE: 210626.51115082315        |\n",
      "[ 18:52:27 ] ----- Epoch [4/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 6.892608815181244e-05     | MAE: 0.005883380302780205      | MRE: 111147.05435583208        |\n",
      "[ 18:52:45 ] ----- Epoch [5/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 4.9353556588203586e-05    | MAE: 0.004968252232131193      | MRE: 89373.80513092178         |\n",
      "[ 18:53:02 ] ----- Epoch [6/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 3.903264970802214e-05     | MAE: 0.004442454011402691      | MRE: 77508.10814262812         |\n",
      "[ 18:53:19 ] ----- Epoch [7/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 3.368304325566162e-05     | MAE: 0.0041201268446925815     | MRE: 69080.51673518943         |\n",
      "[ 18:53:36 ] ----- Epoch [8/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.956845673858399e-05     | MAE: 0.00385377370228547       | MRE: 63424.132843474166        |\n",
      "[ 18:53:53 ] ----- Epoch [9/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.7425744214238394e-05    | MAE: 0.0036998401798948245     | MRE: 58765.5387860732          |\n",
      "[ 18:54:10 ] ----- Epoch [10/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.4939494013544563e-05    | MAE: 0.003519000832304912      | MRE: 53088.027463344246        |\n",
      "[ 18:54:27 ] ----- Epoch [11/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.3431339014483393e-05    | MAE: 0.0033873751352765423     | MRE: 49596.209813927715        |\n",
      "[ 18:54:44 ] ----- Epoch [12/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.2073221655830494e-05    | MAE: 0.0032872964734381215     | MRE: 45795.7671171294          |\n",
      "[ 18:55:01 ] ----- Epoch [13/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.084050045904518e-05     | MAE: 0.0031834157982392804     | MRE: 44370.02082890216         |\n",
      "[ 18:55:18 ] ----- Epoch [14/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.9599185384201923e-05    | MAE: 0.003092811103534611      | MRE: 40402.83255294311         |\n",
      "[ 18:55:35 ] ----- Epoch [15/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.942398345676197e-05     | MAE: 0.003049764804336584      | MRE: 38675.91596824273         |\n",
      "[ 18:55:52 ] ----- Epoch [16/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.8326963362392304e-05    | MAE: 0.0029648561416231053     | MRE: 37599.43025517452         |\n",
      "[ 18:56:09 ] ----- Epoch [17/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.7815382839989627e-05    | MAE: 0.002926117903623292      | MRE: 36467.50197642514         |\n",
      "[ 18:56:27 ] ----- Epoch [18/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.7085708220998428e-05    | MAE: 0.0028566735476514334     | MRE: 34857.12117580216         |\n",
      "[ 18:56:47 ] ----- Epoch [19/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.664699292385959e-05     | MAE: 0.0028183495533419126     | MRE: 33416.366910919016        |\n",
      "[ 18:57:06 ] ----- Epoch [20/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.617160993766033e-05     | MAE: 0.0027698345718942087     | MRE: 32453.09566223582         |\n",
      "[ 18:57:24 ] ----- Epoch [21/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.568822873353176e-05     | MAE: 0.002725351934926964      | MRE: 30692.10454301053         |\n",
      "[ 18:57:42 ] ----- Epoch [22/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.541930846803333e-05     | MAE: 0.002688442294558928      | MRE: 29721.88937755512         |\n",
      "[ 18:58:00 ] ----- Epoch [23/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.523920125001209e-05     | MAE: 0.0026733518137175855     | MRE: 29054.824303924455        |\n",
      "[ 18:58:18 ] ----- Epoch [24/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.4769747799491174e-05    | MAE: 0.0026342328758102098     | MRE: 28172.53923078817         |\n",
      "[ 18:58:35 ] ----- Epoch [25/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.4599723825824199e-05    | MAE: 0.002613716768853416      | MRE: 27587.680738012714        |\n",
      "[ 18:58:53 ] ----- Epoch [26/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.4126480054870121e-05    | MAE: 0.002568947940246465      | MRE: 26875.012025421187        |\n",
      "[ 18:59:10 ] ----- Epoch [27/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.3942346808017669e-05    | MAE: 0.0025501496988805466     | MRE: 25503.138978476985        |\n",
      "[ 18:59:28 ] ----- Epoch [28/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.3692698933634936e-05    | MAE: 0.0025199557347813984     | MRE: 25726.191536663966        |\n",
      "[ 18:59:46 ] ----- Epoch [29/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.3380714134394212e-05    | MAE: 0.0024847053966230237     | MRE: 24492.420727477875        |\n",
      "[ 19:00:03 ] ----- Epoch [30/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.3421092845980374e-05    | MAE: 0.0024886848291776017     | MRE: 23859.429674730753        |\n"
     ]
    }
   ],
   "source": [
    "for stage in range(num_stages):\n",
    "\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ***** Stage [{stage+1}/{num_stages}] {'*'*150}\")\n",
    "\t\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tcnt = 0\n",
    "\t\tepoch_lcosh = 0.\n",
    "\t\tepoch_mae = 0.\n",
    "\t\tepoch_mre = 0.\n",
    "\t\tepoch_mse = 0.\n",
    "\t\t\n",
    "\t\tfor X_batch, y_batch in train_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\t\t\tmodel.train()\n",
    "\t\t\t\n",
    "\t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\t\toutputs = (outputs[:, 0] + outputs[:, 1] ) / 2\n",
    "\t\t\ty = y_batch[:, 0]\n",
    "\t\t\t\n",
    "\t\t\t# Calculate losses\n",
    "\t\t\tlcosh_loss = torch.mean(torch.log(torch.cosh(outputs-y)))\n",
    "\t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "\t\t\tmask = y >= 1e-10\n",
    "\t\t\ty_m = y[mask]\n",
    "\t\t\trelative_errors = torch.abs(outputs[mask] - y_m ) / y_m\n",
    "\t\t\tmre_loss = relative_errors.sum()\n",
    "\n",
    "\t\t\tcnt += len(relative_errors)\n",
    "\t\t\t\n",
    "\t\t\t# Backpropagation\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tlcosh_loss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t\n",
    "\t\t\t# Accumulate losses\n",
    "\t\t\tepoch_mse += mse_loss.item()\n",
    "\t\t\tepoch_mae += mae_loss.item()\n",
    "\t\t\tepoch_mre += mre_loss.item()\n",
    "\t\t\tepoch_lcosh += hub_loss\n",
    "\t\t\n",
    "\t\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "\n",
    "\t\tavg_epoch_lcosh = epoch_lcosh / len(train_loader)\n",
    "\t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "\t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "\t\tavg_epoch_mre = epoch_mre / cnt\n",
    "\t\t\n",
    "\t\tprint(f\"{model.name:<50} | Huber loss: {avg_epoch_lcosh:<25} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\t\t\n",
    "\t\tscheduler.step(avg_epoch_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "# \t# Initialize epoch metrics for each model\n",
    "# \tepoch_mae = [0.] * len(models)\n",
    "# \tepoch_mre = [0.] * len(models)\n",
    "# \tepoch_mse = [0.] * len(models)\n",
    "\t\n",
    "# \tfor X_batch, y_batch in train_loader:\n",
    "# \t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\t\t\n",
    "# \t\t# Loop over each model\n",
    "# \t\tfor i, model in enumerate(models):\n",
    "# \t\t\tmodel.train()\n",
    "\t\t\t\n",
    "# \t\t\t# Forward pass\n",
    "# \t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "# \t\t\toutputs = (outputs[:, 0] + outputs[:, 1] ) / 2\n",
    "# \t\t\ty = y_batch[:, 0]\n",
    "\t\t\t\n",
    "# \t\t\t# Calculate losses\n",
    "# \t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "# \t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "# \t\t\trelative_errors = torch.abs(outputs - y) / (y + 1e-8)\n",
    "# \t\t\tmre_loss = relative_errors.mean()\n",
    "\t\t\t\n",
    "# \t\t\t# Backpropagation\n",
    "# \t\t\toptimizers.zero_grad()\n",
    "# \t\t\tmse_loss.backward()\n",
    "# \t\t\toptimizers.step()\n",
    "\t\t\t\n",
    "# \t\t\t# Accumulate losses for this model\n",
    "# \t\t\tepoch_mse += mse_loss.item()\n",
    "# \t\t\tepoch_mae += mae_loss.item()\n",
    "# \t\t\tepoch_mre += mre_loss.item()\n",
    "\t\n",
    "# \tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "# \t# Average metrics for each model\n",
    "# \tfor i in range(len(models)):\n",
    "# \t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "# \t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "# \t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\t\t\n",
    "# \t\tprint(f\"{models.name:<50} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\t\t\n",
    "# \t\t# Scheduler step\n",
    "# \t\tschedulers.step(avg_epoch_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23:44:42 ] ***** Stage [1/1] ******************************************************************************************************************************************************\n",
      "[ 23:45:23 ] ----- Epoch [1/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 0.006428852289180966      | MAE: 0.03766647978385563       | MRE: 1256780.3654474027        |\n",
      "[ 23:46:04 ] ----- Epoch [2/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 5.9861942976728076e-05    | MAE: 0.004866030088063104      | MRE: 45351.62336095607         |\n",
      "[ 23:46:44 ] ----- Epoch [3/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 3.754110637263489e-05     | MAE: 0.0038630588857059387     | MRE: 30780.82100618988         |\n",
      "[ 23:47:25 ] ----- Epoch [4/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 2.8683351241732452e-05    | MAE: 0.0034038164673246118     | MRE: 25597.16780120698         |\n",
      "[ 23:48:05 ] ----- Epoch [5/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 2.4301320454175846e-05    | MAE: 0.003141043299666561      | MRE: 21399.609986172636        |\n",
      "[ 23:48:46 ] ----- Epoch [6/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 2.1742739247897312e-05    | MAE: 0.002959363966451305      | MRE: 18700.393175154368        |\n",
      "[ 23:49:28 ] ----- Epoch [7/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 2.0183560705746644e-05    | MAE: 0.0028399269280874662     | MRE: 16147.501551005564        |\n",
      "[ 23:50:09 ] ----- Epoch [8/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.873963603307975e-05     | MAE: 0.0027306457155196113     | MRE: 14294.119338741035        |\n",
      "[ 23:50:49 ] ----- Epoch [9/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.7905806645370507e-05    | MAE: 0.0026632867795292766     | MRE: 12574.941282701506        |\n",
      "[ 23:51:31 ] ----- Epoch [10/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.6883498583487143e-05    | MAE: 0.0025790184275876144     | MRE: 11554.765816490795        |\n",
      "[ 23:52:11 ] ----- Epoch [11/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.6108105634774496e-05    | MAE: 0.0025161446817281337     | MRE: 10365.487177232635        |\n",
      "[ 23:52:46 ] ----- Epoch [12/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.5427587720128058e-05    | MAE: 0.002461902493020707      | MRE: 9561.859315456815         |\n",
      "[ 23:53:22 ] ----- Epoch [13/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.4894425627816197e-05    | MAE: 0.002415279482557923      | MRE: 8887.773558202753         |\n",
      "[ 23:53:57 ] ----- Epoch [14/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.4171900704938372e-05    | MAE: 0.002349694886114945      | MRE: 8236.525774905844         |\n",
      "[ 23:54:33 ] ----- Epoch [15/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.371168076675061e-05     | MAE: 0.0023149927238347        | MRE: 7520.892761024769         |\n",
      "[ 23:55:08 ] ----- Epoch [16/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.3103862817905267e-05    | MAE: 0.00225630701189683       | MRE: 7050.345152899781         |\n",
      "[ 23:55:44 ] ----- Epoch [17/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.2726875600969471e-05    | MAE: 0.002217570572468209      | MRE: 6576.910470286435         |\n",
      "[ 23:56:19 ] ----- Epoch [18/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.2307271330490339e-05    | MAE: 0.002183238967543828      | MRE: 6229.889560432865         |\n",
      "[ 23:56:55 ] ----- Epoch [19/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.2056902439529598e-05    | MAE: 0.002153745616058385      | MRE: 5714.406836293972         |\n",
      "[ 23:57:30 ] ----- Epoch [20/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.1815251421439492e-05    | MAE: 0.0021317253814855455     | MRE: 5581.137205788548         |\n",
      "[ 23:58:06 ] ----- Epoch [21/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.149964266282215e-05     | MAE: 0.0021016833698065634     | MRE: 5049.0031245261125        |\n",
      "[ 23:58:41 ] ----- Epoch [22/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.1293727971764456e-05    | MAE: 0.002081215763470581      | MRE: 4931.325514458289         |\n",
      "[ 23:59:17 ] ----- Epoch [23/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.1006783558993322e-05    | MAE: 0.002045797083210159      | MRE: 4646.952423835083         |\n",
      "[ 23:59:52 ] ----- Epoch [24/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.090242230709007e-05     | MAE: 0.0020370079082768482     | MRE: 4497.828947260707         |\n",
      "[ 00:00:28 ] ----- Epoch [25/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.0645932888912962e-05    | MAE: 0.002008789297988379      | MRE: 4284.805342449673         |\n",
      "[ 00:01:03 ] ----- Epoch [26/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.0391081805673305e-05    | MAE: 0.001981837751872186      | MRE: 4106.4292060387415        |\n",
      "[ 00:01:38 ] ----- Epoch [27/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.0332439334701431e-05    | MAE: 0.0019768032552777313     | MRE: 4039.2572203599257        |\n",
      "[ 00:02:14 ] ----- Epoch [28/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 1.0154400572570393e-05    | MAE: 0.0019575290467145293     | MRE: 3770.427327006234         |\n",
      "[ 00:02:48 ] ----- Epoch [29/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 9.921857840201669e-06     | MAE: 0.001936295640116809      | MRE: 3742.1759609700366        |\n",
      "[ 00:03:23 ] ----- Epoch [30/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | MSE: 9.8293585768652e-06       | MAE: 0.0019229922992250298     | MRE: 3576.5135518135794        |\n"
     ]
    }
   ],
   "source": [
    "for stage in range(num_stages):\n",
    "\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ***** Stage [{stage+1}/{num_stages}] {'*'*150}\")\n",
    "\t\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tepoch_mae = 0.\n",
    "\t\tepoch_mre = 0.\n",
    "\t\tepoch_mse = 0.\n",
    "\t\t\n",
    "\t\tfor X_batch, y_batch in train_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\t\t\tmodel.train()\n",
    "\t\t\t\n",
    "\t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\t\toutputs = (outputs[:, 0] + outputs[:, 1] ) / 2\n",
    "\t\t\t# outputs=outputs[:, 0]\n",
    "\t\t\ty = y_batch[:, 0]\n",
    "\t\t\t\n",
    "\t\t\t# Calculate losses\n",
    "\t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "\t\t\tmask = y >= 1e-10\n",
    "\t\t\ty_m = y[mask]\n",
    "\t\t\trelative_errors = torch.abs(outputs[mask] - y_m ) / y_m\n",
    "\t\t\tmre_loss = relative_errors.mean()\n",
    "\t\t\t\n",
    "\t\t\t# Backpropagation\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tmae_loss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t\n",
    "\t\t\t# Accumulate losses\n",
    "\t\t\tepoch_mse += mse_loss.item()\n",
    "\t\t\tepoch_mae += mae_loss.item()\n",
    "\t\t\tepoch_mre += mre_loss.item()\n",
    "\t\t\n",
    "\t\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "\n",
    "\t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "\t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "\t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\t\t\n",
    "\t\tprint(f\"{model.name:<50} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\t\t\n",
    "\t\tscheduler.step(avg_epoch_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRE Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "# \t# Initialize epoch metrics for each model\n",
    "# \tepoch_mae = [0.] * len(models)\n",
    "# \tepoch_mre = [0.] * len(models)\n",
    "# \tepoch_mse = [0.] * len(models)\n",
    "\t\n",
    "# \tfor X_batch, y_batch in train_loader:\n",
    "# \t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\t\t\n",
    "# \t\t# Loop over each model\n",
    "# \t\tfor i, model in enumerate(models):\n",
    "# \t\t\tmodel.train()\n",
    "\t\t\t\n",
    "# \t\t\t# Forward pass\n",
    "# \t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "# \t\t\toutputs = outputs[:, 0] + outputs[:, 1] / X_batch[:, 0]\n",
    "# \t\t\ty = y_batch[:, 0]\n",
    "\t\t\t\n",
    "# \t\t\t# Calculate losses\n",
    "# \t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "# \t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "# \t\t\trelative_errors = torch.abs(outputs - y) / (y + 1e-8)\n",
    "# \t\t\tmre_loss = relative_errors.mean()\n",
    "\t\t\t\n",
    "# \t\t\t# Backpropagation\n",
    "# \t\t\toptimizers.zero_grad()\n",
    "# \t\t\tmre_loss.backward()\n",
    "# \t\t\toptimizers.step()\n",
    "\t\t\t\n",
    "# \t\t\t# Accumulate losses for this model\n",
    "# \t\t\tepoch_mse += mse_loss.item()\n",
    "# \t\t\tepoch_mae += mae_loss.item()\n",
    "# \t\t\tepoch_mre += mre_loss.item()\n",
    "\t\n",
    "# \tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "# \t# Average metrics for each model\n",
    "# \tfor i in range(len(models)):\n",
    "# \t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "# \t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "# \t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\t\t\n",
    "# \t\tprint(f\"{models.name:<50} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\t\t\n",
    "# \t\t# Scheduler step\n",
    "# \t\tschedulers.step(avg_epoch_mre)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "# \t# Initialize epoch metrics for each model\n",
    "# \tepoch_mae = [0.] * len(models)\n",
    "# \tepoch_mre = [0.] * len(models)\n",
    "# \tepoch_mse = [0.] * len(models)\n",
    "\t\n",
    "# \tfor X_batch, y_batch in train_loader:\n",
    "# \t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\t\t\n",
    "# \t\t# Loop over each model\n",
    "# \t\tfor i, model in enumerate(models):\n",
    "# \t\t\tmodel.train()\n",
    "\t\t\t\n",
    "# \t\t\t# Forward pass\n",
    "# \t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "# \t\t\toutputs = outputs[:, 0] + outputs[:, 1] / X_batch[:, 0]\n",
    "# \t\t\ty = y_batch[:, 0]\n",
    "\t\t\t\n",
    "# \t\t\t# Calculate losses\n",
    "# \t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "# \t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "# \t\t\trelative_errors = torch.abs(outputs - y) / (y + 1e-8)\n",
    "# \t\t\tmre_loss = relative_errors.mean()\n",
    "\t\t\t\n",
    "# \t\t\t# Composite loss\n",
    "# \t\t\tcomposite_loss = (weights_mse * mse_loss + \n",
    "# \t\t\t\t\t\t\t  weights_mae * mae_loss + \n",
    "# \t\t\t\t\t\t\t  weights_mre * mre_loss)\n",
    "\t\t\t\n",
    "# \t\t\t# Backpropagation\n",
    "# \t\t\toptimizers.zero_grad()\n",
    "# \t\t\tcomposite_loss.backward()\n",
    "# \t\t\toptimizers.step()\n",
    "\t\t\t\n",
    "# \t\t\t# Accumulate losses for this model\n",
    "# \t\t\tepoch_mse += mse_loss.item()\n",
    "# \t\t\tepoch_mae += mae_loss.item()\n",
    "# \t\t\tepoch_mre += mre_loss.item()\n",
    "\t\n",
    "# \tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "# \t# Compute average metrics for each model\n",
    "# \tfor i in range(len(models)):\n",
    "# \t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "# \t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "# \t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\t\t\n",
    "# \t\tprint(f\"{models.name:<50} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\t\t\n",
    "# \t\t# Update weights for loss adjustment\n",
    "# \t\tweights_mse = avg_epoch_mse / target_loss\n",
    "# \t\tweights_mae = avg_epoch_mae / target_loss\n",
    "# \t\tweights_mre = avg_epoch_mre / target_loss\n",
    "\t\t\n",
    "# \t\t# Scheduler step\n",
    "# \t\tschedulers.step(composite_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"models/{model.name}_hub.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = 'models'\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for model_name in [m for m in os.listdir(models_path) if m.endswith('pth')]:\n",
    "\tprint(model_name)\n",
    "\t# model = BlackScholesNet(input_size=5, hidden_size=128, output_size=2)\n",
    "\t# model.load_state_dict(torch.load(os.path.join(models_path, model_name)))\n",
    "\t# model.to(device)\n",
    "\n",
    "\t# models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BlackScholesNet(input_size=5, hidden_size=128, output_size=2)\n",
    "model.load_state_dict(torch.load(f\"models\\\\black.pth\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 10000000\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_static_test_data(num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serpo\\AppData\\Local\\Temp\\ipykernel_1664\\2013377624.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_test_tensor, y_test_tensor = torch.load('static_test_data.pt')\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor, y_test_tensor = load_static_test_data()\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        Results | MSE: 1.860992115070968e-09     | MAE: 0.0004510874317589473     | Max AE: 0.015712605802571444      | MRE: 3039.6012895961358        | Max RE: 24053090.766225673       \n"
     ]
    }
   ],
   "source": [
    "# Initialize metrics for each model\n",
    "test_losses = 0.\n",
    "test_maes = 0.\n",
    "test_max_aes = 0.\n",
    "test_mres = 0.\n",
    "test_max_res = 0.\n",
    "cnt = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "\tfor X_batch, y_batch in test_loader:\n",
    "\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\t\t# X_batch = X_batch.unsqueeze(1)  # Add a dimension for sequence length\n",
    "\n",
    "\t\t# Forward pass\n",
    "\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\toutputs = (outputs[:, 0] + outputs[:, 1]) / 2\n",
    "\t\t# outputs = outputs[:, 0]\n",
    "\t\t\n",
    "\t\ty = y_batch[:, 0]\n",
    "\n",
    "\t\t# Mean Squared Error (MSE)\n",
    "\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "\t\ttest_losses += mse_loss.item()\n",
    "\n",
    "\t\t# Mean Absolute Error (MAE)\n",
    "\t\tabs_errors = torch.abs(outputs - y)\n",
    "\t\ttest_maes += abs_errors.sum().item()\n",
    "\n",
    "\t\t# Maximum Absolute Error (Max AE)\n",
    "\t\tmax_ae = abs_errors.max().item()\n",
    "\t\ttest_max_aes = max(test_max_aes, max_ae)\n",
    "\n",
    "\t\t# Mean Relative Error (MRE)\n",
    "\t\tmask = y >= 1e-10\n",
    "\t\ty_m = y[mask]\n",
    "\t\trelative_errors = torch.abs(outputs[mask] - y_m ) / y_m\n",
    "\n",
    "\t\t# Calculate MRE\n",
    "\t\ttest_mres += relative_errors.sum().item()\n",
    "\t\tcnt += len(relative_errors)\n",
    "\n",
    "\t\t# Calculate max relative error\n",
    "\t\ttest_max_res = max(test_max_res, relative_errors.max().item())\n",
    "\n",
    "\n",
    "# Calculate the average metrics over all test samples for each model\n",
    "avg_test_loss = test_losses / len(test_loader.dataset)\n",
    "avg_test_mae = test_maes / len(test_loader.dataset)\n",
    "avg_test_mre = test_mres / cnt\n",
    "\n",
    "print('-'*250)\n",
    "print(f\"{model.name:<50} Results | MSE: {avg_test_loss:<25} | MAE: {avg_test_mae:<25} | Max AE: {test_max_aes:<25} | MRE: {avg_test_mre:<25} | Max RE: {test_max_res:<25}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model                                        Results | MSE: 1.860992115070968e-09     | MAE: 0.0004510874317589473     | Max AE: 0.015712605802571444      | MRE: 3039.6012895961358        | Max RE: 24053090.766225673       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model                                        Results | MSE: 4.3176854823214384e-08    | MAE: 0.002548539893560493      | Max AE: 0.02216988133309572       | MRE: 52930.97271546223         | Max RE: 74994568.97747828        \n",
    "\n",
    "\n",
    "weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 2.3365065048548754e-08\t| MAE: 0.0019228472067950922\t | Max AE: 0.020785850080788537\t  | MRE: 19540.95551665145\t\t | Max RE: 38428277.40361217\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Deep Model\t\t\t\t\t\t\t\t   Results | MSE: 1.2292241128713081e-08\t| MAE: 0.0014149500863335678\t | Max AE: 0.026046665725385276\t  | MRE: 15973.972288640323\t\t| Max RE: 13644321.567340782\t   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black RNN Model\t\t\t\t\t\t\t\t\tResults | MSE: 1.589732937737662e-11\t | MAE: 3.226697698242954e-05\t | Max AE: 0.001995025861357906\t  | MRE: 1103.9241832972975\t\t| Max RE: 15041726.760521403\t   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black RNN Model\t\t\t\t\t\t\t\t\tResults | MSE: 4.777907308376809e-11\t | MAE: 7.51992950659468e-05\t  | Max AE: 0.0023897778645683085\t | MRE: 2156.166863801692\t\t | Max RE: 16343429.899646066\t   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black RNN Model\t\t\t\t\t\t\t\t\tResults | MSE: 5.004787422430029e-10\t | MAE: 0.00030045160178942263\t| Max AE: 0.003092261246673578\t  | MRE: 8728.737648890628\t\t | Max RE: 21332958.18205698\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black CNN Model\t\t\t\t\t\t\t\t\tResults | MSE: 1.6229420763649162e-08\t| MAE: 0.0016403877602419335\t | Max AE: 0.02096367339459762\t   | MRE: 39130.069827259045\t\t| Max RE: 49456677.41935457\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black ResNet Model\t\t\t\t\t\t\t\t Results | MSE: 1.357335095783607e-07\t | MAE: 0.004738837337220532\t  | Max AE: 0.021764388623186998\t  | MRE: 147254.71198362616\t\t| Max RE: 146963541.83840838\t   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 1.6345862189413596e-07\t| MAE: 0.005929486075345317\t  | Max AE: 0.024445273630216757\t  | MRE: 308086.0669714369\t\t | Max RE: 102909205.05644394\t   \n",
    "\n",
    "\n",
    "hub no activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 6.311032924102108e-08\t | MAE: 0.0024049330370174466\t | Max AE: 0.0486327963291493\t\t| MRE: 0.17257685070773462\t   | Max RE: 13.89843139038193\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 4.767372257527874e-09\t | MAE: 0.0008842677848565959\t | Max AE: 0.010480693476281389\t  | MRE: 8610.273830920263\t\t | Max RE: 24765156.665712476   \n",
    "</br>\n",
    "delta 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 1.7072262899170862e-08\t| MAE: 0.0014622379697655967\t | Max AE: 0.012304333512939192\t  | MRE: 19133.356655940905\t\t| Max RE: 32084991.04810058\t\t\n",
    "</br>\n",
    "Huber loss delta = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 6.5584848876120205e-09\t| MAE: 0.0010204205638990932\t | Max AE: 0.01436321507469207\t   | MRE: 21704.53521771374\t\t | Max RE: 39553088.01572265\n",
    "</br>\n",
    "Huber loss delta = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 9.577022434796093e-09\t | MAE: 0.001128070044492659\t  | Max AE: 0.01750700016971668\t   | MRE: 0.0\t\t\t\t\t   | Max RE: 0.0   \n",
    "with grad norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 3.437281101835667e-08\t | MAE: 0.0014345937355705574\t | Max AE: 0.026702327077854637\t  | MRE: 0.0\t\t\t\t\t   | Max RE: 0.0\t\t  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 4.870335576499605e-09\t | MAE: 0.0006644182282886656\t | Max AE: 0.02035231469468729\t   | MRE: 0.0\t\t\t\t\t   | Max RE: 0.0\t "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 3.0745519796730916e-09\t| MAE: 0.0006669217488797097\t | Max AE: 0.01045388565348454\t   | MRE: 0.0\t\t\t\t\t   | Max RE: 0.0\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 5.394526925641141e-09\t | MAE: 0.0007469986503670395\t | Max AE: 0.024494726553518364\t  | MRE: 0.0\t\t\t\t\t   | Max RE: 0.0   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 9.944437335789435e-10\t | MAE: 0.0002790903619311921\t | Max AE: 0.020291466710218475\t  | MRE: 0.0\t\t\t\t\t   | Max RE: 5.520420072604463e+31\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Base Model\t\t\t\t\t\t\t\t\t\t Results | MSE: 3.700808076204782e-09\t | MAE: 0.0006494232504191063\t | Max AE: 0.02520344930434637\t   | MRE: 207.39712310149338\t\t| Max RE: 115508.51118180675 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Normal\n",
    "\n",
    "def d1(K, T, sigma, F):\n",
    "\treturn (torch.log(F / K) + (0.5 * sigma**2) * T) / (sigma * torch.sqrt(T))\n",
    "\n",
    "def d2(d1, T, sigma):\n",
    "\treturn d1 - sigma * torch.sqrt(T)\n",
    "\n",
    "def delta(d1, F=1, option_type='call'):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\n",
    "\tif option_type == 'call':\n",
    "\t\treturn normal_dist.cdf(d1)\n",
    "\telif option_type == 'put':\n",
    "\t\treturn normal_dist.cdf(d1) - 1\n",
    "\telse:\n",
    "\t\traise ValueError(\"Option type must be 'call' or 'put'\")\n",
    "\n",
    "def gamma(T, sigma, d1, F=1):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\tpdf_d1 = torch.exp(normal_dist.log_prob(d1)) \n",
    "\n",
    "\treturn pdf_d1 / (F * sigma * torch.sqrt(T))\n",
    "\n",
    "def theta(K, T, sigma, d1, d2, F=1, r=0, option_type='call'):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\tpdf_d1 = torch.exp(normal_dist.log_prob(d1)) \n",
    "\n",
    "\tif option_type == 'call':\n",
    "\t\treturn (-F * pdf_d1 * sigma / (2 * torch.sqrt(T)) - r * K * torch.exp(-r * T) * normal_dist.cdf(d2))\n",
    "\telif option_type == 'put':\n",
    "\t\treturn (-F * pdf_d1 * sigma / (2 * torch.sqrt(T)) + r * K * torch.exp(-r * T) * normal_dist.cdf(-d2))\n",
    "\telse:\n",
    "\t\traise ValueError(\"Option type must be 'call' or 'put'\")\n",
    "\n",
    "def vega(T, d1, F=1):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\tpdf_d1 = torch.exp(normal_dist.log_prob(d1))\n",
    "\t\n",
    "\treturn F * pdf_d1 * torch.sqrt(T)\n",
    "\n",
    "def greeks(K, T, sigma, F=1, r=0, option_type='call'):\n",
    "\tdp = d1(K, T, sigma, F)\n",
    "\tdm = d2(dp, T, sigma)\n",
    "\t\n",
    "\treturn delta(dp, F, option_type), gamma(T, sigma, dp, F), theta(K, T, sigma, dp, dm, F, r, option_type), vega(T, dp, F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "K = np.random.uniform(1, 2.5, num_samples)\n",
    "T = np.random.uniform(0.004, 4, num_samples)\n",
    "sigma = np.random.uniform(0.1, 0.5, num_samples)\n",
    "\n",
    "# Подготовка данных\n",
    "X = np.vstack((K, T, np.log(K), sigma * np.sqrt(T), sigma**2 * T)).T\n",
    "X_tensor = torch.tensor(X, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "prices = torch.tensor(black_model(1, K, T, sigma), dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensorcpy = X_tensor.clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = X_tensor.unsqueeze(1)  # Add a dimension for sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Model\n",
      "Mean Squared Error (MSE): 5.279228075025681e-07\n",
      "Mean Absolute Error (MAE): 0.0004881404838354122\n",
      "Max Absolute Error (MAE): 0.007942661994656486\n",
      "Mean Relative Error (MRE): 0.2617813275628902\n",
      "Max Relative Error (MRE): 116.34913356953619\n"
     ]
    }
   ],
   "source": [
    "# Входные данные для модели\n",
    "y = model(X_tensor, X_tensor[:, 0])\n",
    "y = (y[:, 0] + y[:, 1] ) / 2\n",
    "# y = y[:, 0]\n",
    "\n",
    "abs_errors = torch.abs(y - prices)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "mse = F.mse_loss(y, prices).item()\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = F.l1_loss(y, prices)\n",
    "\n",
    "# Mean Relative Error (MRE)\n",
    "mask = y >= 1e-10\n",
    "y_m = y[mask]\n",
    "relative_errors = torch.abs(prices[mask] - y_m ) / y_m\n",
    "mre = relative_errors.mean().item()\n",
    "max_mre = relative_errors.max().item()\n",
    "\n",
    "print(model.name)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae.item()}\")\n",
    "print(f\"Max Absolute Error (MAE): {abs_errors.max().item()}\")\n",
    "print(f\"Mean Relative Error (MRE): {mre}\")\n",
    "print(f\"Max Relative Error (MRE): {max_mre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0007, 0.0012, 0.0391,  ..., 0.0006, 0.0029, 0.3137],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor([7.8225e-07, 2.1521e-04, 4.1783e-02,  ..., 2.5865e-07, 2.3822e-03,\n",
      "        3.0937e-01], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor(X, dtype=torch.float64)\n",
    "greeks_result = greeks(X_test[:, 0], X_test[:, 1], X_test[:, 3] / torch.sqrt(X_test[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Фиксируем seed для повторяемости\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses for current model:\n",
      "Delta:  0.04097502044021693\n",
      "Black Model\n"
     ]
    }
   ],
   "source": [
    "model.zero_grad()  # Сброс градиентов модели\n",
    "\n",
    "y = model(X_tensor, X_tensor[:, 0])\n",
    "y = (y[:, 0] + y[:, 1] ) / 2\n",
    "# y = y[:, 0]\n",
    "\n",
    "# y.backward(torch.ones_like(y), retain_graph=True)\n",
    "# K_grad = X_tensor.grad[:, 0].clone()  \n",
    "# T_grad = X_tensor.grad[:, 1].clone()  \n",
    "# sigma_grad = (X_tensor.grad[:, 3] / torch.sqrt(X_tensor[:, 1])).clone()\n",
    "\n",
    "X_tensor.grad.zero_()\n",
    "\n",
    "y = model(X_tensor, X_tensor[:, 0])\n",
    "y = (y[:, 0] + y[:, 1] ) / 2\n",
    "# y = y[:, 0]\n",
    "y.backward(torch.ones_like(y), retain_graph=True)\n",
    "delta_grad = X_tensor.grad[:, 0].clone()\n",
    "\n",
    "# X_tensor.grad.zero_()\n",
    "\n",
    "# # Вычисление второго градиента (гамма)\n",
    "# y = model(X_tensor, X_tensor[:, 0])\n",
    "# y = (y[:, 0] + y[:, 1] ) / 2\n",
    "# # y = y[:, 0]\n",
    "# y.backward(torch.ones_like(y), retain_graph=True)\n",
    "# delta_grad.backward(torch.ones_like(delta_grad), retain_graph=True)\n",
    "# gamma_grad = X_tensor.grad[:, 0].clone()\n",
    "\n",
    "delta_loss = F.mse_loss(delta_grad, greeks_result[0]).item()\n",
    "# gamma_loss = F.mse_loss(gamma_grad, greeks_result[1]).item()\n",
    "# theta_loss = F.mse_loss(T_grad, greeks_result[2]).item()\n",
    "# vega_loss = F.mse_loss(sigma_grad, greeks_result[3]).item()\n",
    "\n",
    "print(\"Losses for current model:\")\n",
    "print('Delta: ', delta_loss)\n",
    "# print('Gamma: ', gamma_loss)\n",
    "# print('Theta: ', theta_loss)\n",
    "# print('Vega: ', vega_loss)\n",
    "\n",
    "print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.04097502044021693\n",
    "# Black Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.23041457848259805\n",
    "# Black Model\n",
    "# weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.09470602026672634\n",
    "# Gamma:  0.4605984598995799\n",
    "# Black Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses for the RNN model:\n",
      "Delta Loss:  0.08094750341367543\n",
      "Gamma Loss:  0.4721712001137761\n"
     ]
    }
   ],
   "source": [
    "# Zero gradients before starting\n",
    "model.zero_grad()\n",
    "\n",
    "# Forward pass\n",
    "y = model(X_tensor.unsqueeze(1))  # Add sequence dimension for LSTM\n",
    "y = y[:, 0]  # Get the first output\n",
    "\n",
    "# Delta Calculation (First Derivative)\n",
    "y.backward(torch.ones_like(y), retain_graph=True)  # Backpropagate\n",
    "K_grad = X_tensor.grad[:, 0].clone()  # Gradient w.r.t. K (Delta)\n",
    "X_tensor.grad.zero_()  # Clear gradients for the next step\n",
    "\n",
    "# Gamma Calculation (Second Derivative)\n",
    "y = model(X_tensor.unsqueeze(1))  # Forward pass again\n",
    "y = y[:, 0]\n",
    "y.backward(torch.ones_like(y), retain_graph=True)\n",
    "delta_grad = X_tensor.grad[:, 0].clone().requires_grad_(True)  # Delta gradient\n",
    "\n",
    "X_tensor.grad.zero_()\n",
    "\n",
    "# Now backpropagate Delta to calculate Gamma\n",
    "delta_grad.backward(torch.ones_like(delta_grad), retain_graph=True)\n",
    "gamma_grad = X_tensor.grad[:, 0].clone()  # Gamma\n",
    "\n",
    "# Calculate MSE loss for Delta and Gamma against target Greeks\n",
    "delta_loss = F.mse_loss(delta_grad, greeks_result[0]).item()  # Replace with actual target values for Delta\n",
    "gamma_loss = F.mse_loss(gamma_grad, greeks_result[1]).item()  # Replace with actual target values for Gamma\n",
    "\n",
    "print(\"Losses for the RNN model:\")\n",
    "print('Delta Loss: ', delta_loss)\n",
    "print('Gamma Loss: ', gamma_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.07544267106592446\n",
    "# Gamma:  0.4395989266865998\n",
    "# Black Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for the RNN model:\n",
    "# Delta Loss:  0.08094750341367543\n",
    "# Gamma Loss:  0.4721712001137761"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.03421519741554771\n",
    "# Gamma:  0.37361078598119973\n",
    "# Black ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.02984523250068021\n",
    "# Gamma:  0.32884577927187386 hub no act "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
