{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_model(F, K, T, sigma, option_type='call'):\n",
    "\t# Parameters\n",
    "\td1 = (np.log(F / K) + (sigma**2 / 2) * T) / (sigma * np.sqrt(T))\n",
    "\td2 = d1 - sigma * np.sqrt(T)\n",
    "\n",
    "\t# Discount factor (assuming risk-free rate is 0)\n",
    "\tDF_T = 1\n",
    "\n",
    "\tif option_type == 'call':\n",
    "\t\treturn DF_T * (F * norm.cdf(d1) - K * norm.cdf(d2))\n",
    "\telif option_type == 'put':\n",
    "\t\treturn DF_T * (K * norm.cdf(-d2) - F * norm.cdf(-d1))\n",
    "\telse:\n",
    "\t\traise ValueError(\"option_type must be 'call' or 'put'\")\n",
    "\n",
    "def generate_data(num_samples, S=1):\n",
    "\t# Generate random parameters\n",
    "\tK = np.random.uniform(1, 2.5, num_samples)\n",
    "\tT = np.random.uniform(0.004, 4, num_samples)\n",
    "\tsigma = np.random.uniform(0.1, 0.5, num_samples)\n",
    "\n",
    "\n",
    "\tcall_prices = black_model(S, K, T, sigma, option_type='call')\n",
    "\n",
    "\t# Prepare input data matrix X\n",
    "\td1 = (np.log(S/K) + sigma**2*T/2) / (sigma * np.sqrt(T))\n",
    "\tX = np.vstack((K, T, sigma, np.log(S/K), np.sqrt(T), T*sigma**2)).T\n",
    "\ty = call_prices\n",
    "\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_static_test_data(num_test_samples=100000, file_name='static_test_data.pt'):\n",
    "\tglobal scaler\n",
    "\n",
    "\t# Generate test data\n",
    "\tX_test, y_test = generate_data(num_samples=num_test_samples)\n",
    "\n",
    "\t# Apply the same scaling as used for training\n",
    "\tX_test_scaled = scaler.transform(X_test)  # Use scaler fitted on training data\n",
    "\n",
    "\t# Convert to tensors\n",
    "\tX_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float64)\n",
    "\ty_test_tensor = torch.tensor(y_test, dtype=torch.float64).unsqueeze(1)\n",
    "\n",
    "\t# Save the test data\n",
    "\ttorch.save((X_test_tensor, y_test_tensor), file_name)\n",
    "\n",
    "def load_static_test_data(file_name='static_test_data.pt'):\n",
    "\t# Load test data from the file\n",
    "\tX_test_tensor, y_test_tensor = torch.load(file_name)\n",
    "\treturn X_test_tensor, y_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_prepare_training_data(num_train_samples=1000000, batch_size=128):\n",
    "\tglobal scaler\n",
    "\n",
    "\t# Generate training data\n",
    "\tX_train, y_train = generate_data(num_samples=num_train_samples)\n",
    "\n",
    "\t# Fit the scaler on the training data\n",
    "\tX_train_scaled = scaler.fit_transform(X_train)  # Fit and scale training data\n",
    "\n",
    "\t# Convert to tensors\n",
    "\tX_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float64)\n",
    "\ty_train_tensor = torch.tensor(y_train, dtype=torch.float64).unsqueeze(1)\n",
    "\n",
    "\t# Create DataLoader\n",
    "\ttrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\ttrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\treturn train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FeedforwardNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size, dtype=torch.float64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size, dtype=torch.float64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size, dtype=torch.float64)\n",
    "        )\n",
    "        self.name = \"FFN model\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float64)  # Ensure input is float64\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(dim, dim, dtype=torch.float64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim, dim, dtype=torch.float64)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float64)  # Ensure input is float64\n",
    "        return x + self.layer(x)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_blocks):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size, dtype=torch.float64)\n",
    "        self.blocks = nn.Sequential(*[ResidualBlock(hidden_size) for _ in range(num_blocks)])\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size, dtype=torch.float64)\n",
    "        self.name = \"ResNet model\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float64)  # Ensure input is float64\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        x = self.blocks(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIRENLayer(nn.Module):\n",
    "    def __init__(self, input_size, out_size, omega=30.0, is_first=False):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.out_size = out_size\n",
    "        self.is_first = is_first\n",
    "        self.omega = omega\n",
    "\n",
    "        # Linear layer\n",
    "        self.linear = nn.Linear(input_size, out_size, dtype=torch.float64)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.input_size, 1 / self.input_size)\n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.input_size) / self.omega,\n",
    "                                             np.sqrt(6 / self.input_size) / self.omega)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float64)  # Ensure input is float64\n",
    "        return torch.sin(self.omega * self.linear(x))\n",
    "\n",
    "class SIREN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, hidden_layers, out_size, omega=30.0):\n",
    "        super().__init__()\n",
    "\n",
    "        # First layer\n",
    "        self.layers = [SIRENLayer(input_size, hidden_size, omega=omega, is_first=True)]\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(hidden_layers):\n",
    "            self.layers.append(SIRENLayer(hidden_size, hidden_size, omega=omega))\n",
    "\n",
    "        # Final layer\n",
    "        self.layers.append(nn.Linear(hidden_size, out_size, dtype=torch.float64))\n",
    "\n",
    "        # Combine into a sequential module\n",
    "        self.net = nn.Sequential(*self.layers)\n",
    "        self.name = \"SIREN model\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float64)  # Ensure input is float64\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 16, kernel_size=3, padding=1, dtype=torch.float64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1, dtype=torch.float64),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 8 * 8, output_size, dtype=torch.float64)  # Assuming input is 8x8 grid\n",
    "        )\n",
    "        self.name = \"CNN model\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float64)  # Ensure input is float64\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_heads, num_layers, output_size):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_size, hidden_size, dtype=torch.float64)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_size, nhead=num_heads, dtype=torch.float64\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size, dtype=torch.float64)\n",
    "        self.name = \"Transformer model\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float64)  # Ensure input is float64\n",
    "        x = self.embedding(x).unsqueeze(1)  # Add sequence dimension\n",
    "        x = self.transformer(x)\n",
    "        return self.output_layer(x.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size, dtype=torch.float64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, latent_dim, dtype=torch.float64)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_size, dtype=torch.float64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, input_size, dtype=torch.float64)\n",
    "        )\n",
    "        self.name = \"Autoencoder model\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float64)  # Ensure input is float64\n",
    "        latent = self.encoder(x)\n",
    "        return self.decoder(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(PINN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size, dtype=torch.float64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size, dtype=torch.float64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, output_size, dtype=torch.float64)\n",
    "        )\n",
    "        self.name = \"PINN model\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float64)  # Ensure input is float64\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_components, output_size):\n",
    "        super(MDN, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size, hidden_size, dtype=torch.float64)\n",
    "        self.alpha_layer = nn.Linear(hidden_size, num_components, dtype=torch.float64)  # Mixing coefficients\n",
    "        self.mu_layer = nn.Linear(hidden_size, num_components * output_size, dtype=torch.float64)  # Means\n",
    "        self.sigma_layer = nn.Linear(hidden_size, num_components * output_size, dtype=torch.float64)  # Variances\n",
    "        self.name = \"MDN model\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float64)  # Ensure input is float64\n",
    "        x = torch.relu(self.hidden_layer(x))\n",
    "        alphas = torch.softmax(self.alpha_layer(x), dim=-1)\n",
    "        mus = self.mu_layer(x)\n",
    "        sigmas = torch.exp(self.sigma_layer(x))  # Ensure positivity\n",
    "        return alphas, mus, sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelAttentionLayer(nn.Module):\n",
    "\tdef __init__(self, input_size, output_size):\n",
    "\t\tsuper(KernelAttentionLayer, self).__init__()\n",
    "\t\tself.query_layer = nn.Linear(input_size, output_size, dtype=torch.float64)\n",
    "\t\tself.key_layer = nn.Linear(input_size, output_size, dtype=torch.float64)\n",
    "\t\tself.value_layer = nn.Linear(input_size, output_size, dtype=torch.float64)\n",
    "\t\tself.scale = 1.0 / np.sqrt(output_size)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tQ = self.query_layer(x)\n",
    "\t\tK = self.key_layer(x)\n",
    "\t\tV = self.value_layer(x)\n",
    "\n",
    "\t\tattention_weights = torch.softmax(Q @ K.T * self.scale, dim=-1)\n",
    "\t\toutput = attention_weights @ V\n",
    "\n",
    "\t\treturn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackScholesNet(nn.Module):\n",
    "\tdef __init__(self, input_size, hidden_size):\n",
    "\t\tsuper(BlackScholesNet, self).__init__()\n",
    "\t\tself.kernel_attention = KernelAttentionLayer(input_size, hidden_size)\n",
    "\t\tself.fc1 = nn.Linear(hidden_size, hidden_size, dtype=torch.float64)\n",
    "\t\tself.fc2 = nn.Linear(hidden_size, 1, dtype=torch.float64)\n",
    "\t\tself.name = 'KAN Black Scholes'\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.kernel_attention(x)\n",
    "\t\tx = torch.tanh(self.fc1(x))\n",
    "\t\toutput = self.fc2(x)\n",
    "\n",
    "\t\treturn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackScholesNet(nn.Module):\n",
    "\tdef __init__(self, input_size=1, hidden_size=128, output_size=1, dropout_p = 0.33):\n",
    "\t\tsuper(BlackScholesNet, self).__init__()\n",
    "\t\tself.fc1 = nn.Linear(input_size, hidden_size, dtype=torch.float64)\n",
    "\t\tself.bn1 = nn.BatchNorm1d(hidden_size, dtype=torch.float64)  # Batch Normalization\n",
    "\t\tself.fc2 = nn.Linear(hidden_size, hidden_size, dtype=torch.float64)\n",
    "\t\tself.bn2 = nn.BatchNorm1d(hidden_size, dtype=torch.float64)  # Batch Normalization\n",
    "\t\tself.fc3 = nn.Linear(hidden_size, output_size, dtype=torch.float64)\n",
    "\t\tself.dropout = nn.Dropout(p=dropout_p)  # Dropout for regularization\n",
    "\t\tself.name = 'Black Model'\n",
    "\n",
    "\tdef forward(self, x, K):\n",
    "\t\tx = F.tanh(self.bn1(self.fc1(x)))  # Tanh and Batch Normalization\n",
    "\t\tx = self.dropout(x)  # Dropout\n",
    "\t\tx = F.tanh(self.bn2(self.fc2(x)))  # Tanh and Batch Normalization\n",
    "\t\tx = self.fc3(x)\n",
    "\t\tx1, x2 = x[:, [0]], x[:, [1]]\n",
    "\t\treturn F.sigmoid(x1) - K * F.sigmoid(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackScholesNet(nn.Module):\n",
    "\tdef __init__(self, input_size=1, hidden_size=128, output_size=1, dropout_p = 0.33):\n",
    "\t\tsuper(BlackScholesNet, self).__init__()\n",
    "\t\tself.fc1 = nn.Linear(input_size, hidden_size, dtype=torch.float64)\n",
    "\t\tself.bn1 = nn.BatchNorm1d(hidden_size, dtype=torch.float64)  # Batch Normalization\n",
    "\t\tself.fc2 = nn.Linear(hidden_size, hidden_size, dtype=torch.float64)\n",
    "\t\tself.bn2 = nn.BatchNorm1d(hidden_size, dtype=torch.float64)  # Batch Normalization\n",
    "\t\tself.fc3 = nn.Linear(hidden_size, output_size, dtype=torch.float64)\n",
    "\t\tself.dropout = nn.Dropout(p=dropout_p)  # Dropout for regularization\n",
    "\t\tself.name = 'Black Model without activation'\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = F.tanh(self.bn1(self.fc1(x)))  # Tanh and Batch Normalization\n",
    "\t\tx = self.dropout(x)  # Dropout\n",
    "\t\tx = F.tanh(self.bn2(self.fc2(x)))  # Tanh and Batch Normalization\n",
    "\t\tx = self.fc3(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackScholesNet(nn.Module):\n",
    "\tdef __init__(self, input_size=1, hidden_size=128, output_size=1, dropout_p=0.3):\n",
    "\t\tsuper(BlackScholesNet, self).__init__()\n",
    "\t\tself.fc1 = nn.Linear(input_size, hidden_size, dtype=torch.float64)\n",
    "\t\tself.bn1 = nn.BatchNorm1d(hidden_size, dtype=torch.float64)\n",
    "\t\tself.fc2 = nn.Linear(hidden_size, hidden_size, dtype=torch.float64)\n",
    "\t\tself.bn2 = nn.BatchNorm1d(hidden_size, dtype=torch.float64)\n",
    "\t\tself.fc_out = nn.Linear(hidden_size, output_size, dtype=torch.float64)\n",
    "\t\tself.dropout = nn.Dropout(p=dropout_p)\n",
    "\t\tself.name = 'Black ResNet Model'\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tresidual = self.fc1(x)  # Transform residual to match shape of x\n",
    "\t\tx = F.relu(self.bn1(self.fc1(x)))\n",
    "\t\tx = self.dropout(x)\n",
    "\t\tx = F.relu(self.bn2(self.fc2(x)))\n",
    "\t\tx = x + residual  # Adding the skip connection after matching dimensions\n",
    "\t\tx = self.fc_out(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 2000\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_static_test_data(num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor, y_test_tensor = load_static_test_data()\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding optimal hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = generate_and_prepare_training_data(10000, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serpo\\AppData\\Local\\Temp\\ipykernel_9160\\2451699335.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_test_tensor, y_test_tensor = torch.load(file_name)\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor, y_test_tensor = load_static_test_data('static_test_data_s.pt')\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\serpo\\Documents\\Python\\Black\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def objective(trial):\n",
    "\t# Define hyperparameters to be optimized\n",
    "\tinput_size = 4\n",
    "\thidden_size = 128\n",
    "\tdropout_p = trial.suggest_float('dropout_p', 0.1, 0.5)\n",
    "\tlr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "\n",
    "\tmodel = BlackScholesNet(input_size=input_size, hidden_size=hidden_size, output_size=1)\n",
    "\tmodel.dropout.p = dropout_p\n",
    "\n",
    "\toptimizer = torch.optim.NAdam(model.parameters(), lr=lr)\n",
    "\n",
    "\tscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\n",
    "\tnum_epochs = 100\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tmodel.train()\n",
    "\t\tepoch_mse = 0\n",
    "\t\tepoch_mae = 0\n",
    "\t\tepoch_mre = 0\n",
    "\n",
    "\t\tfor X_batch, y_batch in train_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\t\toutputs = model(X_batch)\n",
    "\t\t\t# outputs = (outputs[:, 0] + outputs[:, 1]) / 2\n",
    "\t\t\ty = y_batch\n",
    "\n",
    "\t\t\t# mse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "\t\t\t# relative_errors = torch.abs(outputs - y) / (y + 1e-8)\n",
    "\t\t\t# mre_loss = relative_errors.mean()\n",
    "\n",
    "\t\t\tmae_loss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t# epoch_mse += mse_loss.item()\n",
    "\t\t\tepoch_mae += mae_loss.item()\n",
    "\t\t\t# epoch_mre += mre_loss.item()\n",
    "\n",
    "\t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "\t\tscheduler.step(avg_epoch_mae)\n",
    "\n",
    "\ttest_losses = 0.\n",
    "\ttest_maes = 0.\n",
    "\ttest_max_aes = 0.\n",
    "\ttest_mres = 0.\n",
    "\ttest_max_res = 0.\n",
    "\n",
    "\tmodel.eval()\n",
    "\n",
    "\twith torch.inference_mode():\n",
    "\t\tfor X_batch, y_batch in test_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\t\t\t# Forward pass\n",
    "\t\t\toutputs = model(X_batch)\n",
    "\t\t\t# outputs = (outputs[:, 0] + outputs[:, 1]) / 2\n",
    "\n",
    "\t\t\ty = y_batch\n",
    "\n",
    "\t\t\t# Mean Absolute Error (MAE)\n",
    "\t\t\tabs_errors = torch.abs(outputs - y)\n",
    "\t\t\ttest_maes += abs_errors.sum().item()\n",
    "\n",
    "\t# avg_test_loss = test_losses / len(test_loader.dataset)\n",
    "\tavg_test_mae = test_maes / len(test_loader.dataset)\n",
    "\t# avg_test_mre = test_mres / len(test_loader.dataset)\n",
    "\n",
    "\t# Return the average MAE as the objective to be minimized\n",
    "\treturn avg_test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-13 02:13:30,923] A new study created in memory with name: no-name-4d12a20f-78bb-4a37-b8de-b1d08383787d\n",
      "[I 2024-11-13 02:13:49,594] Trial 0 finished with value: 0.008538148411389517 and parameters: {'dropout_p': 0.29188936206204374, 'lr': 3.6650461245806255e-05}. Best is trial 0 with value: 0.008538148411389517.\n",
      "[I 2024-11-13 02:14:08,364] Trial 1 finished with value: 0.01606481424222981 and parameters: {'dropout_p': 0.4927096150720369, 'lr': 2.0102768896209213e-05}. Best is trial 0 with value: 0.008538148411389517.\n",
      "[I 2024-11-13 02:14:27,561] Trial 2 finished with value: 0.006898602722963613 and parameters: {'dropout_p': 0.2903698277645128, 'lr': 0.0002805596088872334}. Best is trial 2 with value: 0.006898602722963613.\n",
      "[I 2024-11-13 02:14:46,363] Trial 3 finished with value: 0.001978334345428275 and parameters: {'dropout_p': 0.32277925052099243, 'lr': 0.009128901482677115}. Best is trial 3 with value: 0.001978334345428275.\n",
      "[I 2024-11-13 02:15:05,228] Trial 4 finished with value: 0.0045206870652618174 and parameters: {'dropout_p': 0.41972771333224557, 'lr': 0.028268204612110517}. Best is trial 3 with value: 0.001978334345428275.\n",
      "[I 2024-11-13 02:15:23,833] Trial 5 finished with value: 0.009480188980720361 and parameters: {'dropout_p': 0.485384934656647, 'lr': 0.00036046609822513613}. Best is trial 3 with value: 0.001978334345428275.\n",
      "[I 2024-11-13 02:15:43,143] Trial 6 finished with value: 0.0043727431472812125 and parameters: {'dropout_p': 0.16294133626704738, 'lr': 4.5953036934599265e-05}. Best is trial 3 with value: 0.001978334345428275.\n",
      "[I 2024-11-13 02:16:02,239] Trial 7 finished with value: 0.0019131091972225155 and parameters: {'dropout_p': 0.207048028299732, 'lr': 0.007520386235357659}. Best is trial 7 with value: 0.0019131091972225155.\n",
      "[I 2024-11-13 02:16:21,476] Trial 8 finished with value: 0.0069676333987785215 and parameters: {'dropout_p': 0.29407815978813, 'lr': 5.419378807245617e-05}. Best is trial 7 with value: 0.0019131091972225155.\n",
      "[I 2024-11-13 02:16:40,694] Trial 9 finished with value: 0.002864048938572033 and parameters: {'dropout_p': 0.4143894466111283, 'lr': 0.007095786282681401}. Best is trial 7 with value: 0.0019131091972225155.\n",
      "[I 2024-11-13 02:16:59,332] Trial 10 finished with value: 0.0026176758996038817 and parameters: {'dropout_p': 0.10066437507755227, 'lr': 0.09473431042269814}. Best is trial 7 with value: 0.0019131091972225155.\n",
      "[I 2024-11-13 02:17:19,205] Trial 11 finished with value: 0.0010954511769258983 and parameters: {'dropout_p': 0.2255672780418764, 'lr': 0.0037221420099071384}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:17:39,176] Trial 12 finished with value: 0.0014653271526508683 and parameters: {'dropout_p': 0.20094865843374618, 'lr': 0.0027074309593549443}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:17:59,546] Trial 13 finished with value: 0.0019544752979632537 and parameters: {'dropout_p': 0.21085309199024976, 'lr': 0.0016484554077270336}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:18:20,725] Trial 14 finished with value: 0.0027220839761363694 and parameters: {'dropout_p': 0.22957778568359746, 'lr': 0.0014682943441362937}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:18:42,533] Trial 15 finished with value: 0.003442074129315929 and parameters: {'dropout_p': 0.14227193848386993, 'lr': 0.00046590565270537523}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:19:00,210] Trial 16 finished with value: 0.002323798407808003 and parameters: {'dropout_p': 0.2428835597636506, 'lr': 0.002839954806329702}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:19:17,889] Trial 17 finished with value: 0.0017080772496517803 and parameters: {'dropout_p': 0.351336000962006, 'lr': 0.024891648027875697}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:19:37,799] Trial 18 finished with value: 0.00443805360649407 and parameters: {'dropout_p': 0.1542313855345605, 'lr': 0.00017296199695441612}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:19:57,097] Trial 19 finished with value: 0.001669504881125463 and parameters: {'dropout_p': 0.2562218574846231, 'lr': 0.0037055366458541524}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:20:17,812] Trial 20 finished with value: 0.0024500930435385473 and parameters: {'dropout_p': 0.18758937374002643, 'lr': 0.0009340678792124561}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:20:38,416] Trial 21 finished with value: 0.0025134075259679394 and parameters: {'dropout_p': 0.25734992221505815, 'lr': 0.0039551334974140965}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:20:56,865] Trial 22 finished with value: 0.0024875213459143145 and parameters: {'dropout_p': 0.25734736066720304, 'lr': 0.015227412291127696}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:21:15,100] Trial 23 finished with value: 0.002724309031354308 and parameters: {'dropout_p': 0.3537279566812428, 'lr': 0.0030043027717781127}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:21:33,843] Trial 24 finished with value: 0.003870603792057902 and parameters: {'dropout_p': 0.11563884097382646, 'lr': 0.0007684825517529174}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:21:51,880] Trial 25 finished with value: 0.0011568209198647068 and parameters: {'dropout_p': 0.1731995706364613, 'lr': 0.0037449429027283845}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:22:11,108] Trial 26 finished with value: 0.002879611609335023 and parameters: {'dropout_p': 0.18612556878145098, 'lr': 0.0017649160148790867}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:22:32,851] Trial 27 finished with value: 0.001207551923572684 and parameters: {'dropout_p': 0.17683155292137603, 'lr': 0.019179751305240904}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:22:55,162] Trial 28 finished with value: 0.0027406128659722795 and parameters: {'dropout_p': 0.12835432098332478, 'lr': 0.06860225105237926}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:23:15,084] Trial 29 finished with value: 0.0013487343637004882 and parameters: {'dropout_p': 0.17320432331182778, 'lr': 0.04522745458724966}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:23:36,598] Trial 30 finished with value: 0.0014087035657831025 and parameters: {'dropout_p': 0.22650592830112623, 'lr': 0.015709691810497837}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:23:57,011] Trial 31 finished with value: 0.003054292708733693 and parameters: {'dropout_p': 0.17042545347983107, 'lr': 0.04184207742131839}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:24:16,058] Trial 32 finished with value: 0.0018817630678408326 and parameters: {'dropout_p': 0.1751164549458061, 'lr': 0.04771013312759419}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:24:35,116] Trial 33 finished with value: 0.0012290192331393319 and parameters: {'dropout_p': 0.13639731267404095, 'lr': 0.015587058856961605}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:24:54,278] Trial 34 finished with value: 0.0014173243110492777 and parameters: {'dropout_p': 0.13528820070881334, 'lr': 0.016297108005133815}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:25:13,324] Trial 35 finished with value: 0.001508586406217061 and parameters: {'dropout_p': 0.10055119659473592, 'lr': 0.008756194798622961}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:25:32,716] Trial 36 finished with value: 0.0015611095028707906 and parameters: {'dropout_p': 0.1470544638264932, 'lr': 0.005307477204346366}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:25:51,774] Trial 37 finished with value: 0.0016315514815890145 and parameters: {'dropout_p': 0.3181625591169225, 'lr': 0.012619226937862304}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:26:10,780] Trial 38 finished with value: 0.011566827095278306 and parameters: {'dropout_p': 0.27859925613823133, 'lr': 1.0965650491002295e-05}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:26:29,893] Trial 39 finished with value: 0.0015589839409035893 and parameters: {'dropout_p': 0.1954756530951457, 'lr': 0.026651172864287438}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:26:48,904] Trial 40 finished with value: 0.005689124245736185 and parameters: {'dropout_p': 0.22169073940501788, 'lr': 0.00014054684091218924}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:27:07,964] Trial 41 finished with value: 0.0015590927349048696 and parameters: {'dropout_p': 0.16559774937351193, 'lr': 0.03659440460564476}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:27:27,018] Trial 42 finished with value: 0.0012318592094897793 and parameters: {'dropout_p': 0.12618094126290813, 'lr': 0.005633011522727618}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:27:46,115] Trial 43 finished with value: 0.001580111564942493 and parameters: {'dropout_p': 0.13142067785963454, 'lr': 0.005891207495394056}. Best is trial 11 with value: 0.0010954511769258983.\n",
      "[I 2024-11-13 02:28:05,184] Trial 44 finished with value: 0.0010858949047961408 and parameters: {'dropout_p': 0.15893722692373702, 'lr': 0.010656198323176637}. Best is trial 44 with value: 0.0010858949047961408.\n",
      "[I 2024-11-13 02:28:25,170] Trial 45 finished with value: 0.0011957709751578309 and parameters: {'dropout_p': 0.15893320342934086, 'lr': 0.01036615220207879}. Best is trial 44 with value: 0.0010858949047961408.\n",
      "[I 2024-11-13 02:28:43,338] Trial 46 finished with value: 0.0017593030104553907 and parameters: {'dropout_p': 0.20934116851904075, 'lr': 0.010846621514301836}. Best is trial 44 with value: 0.0010858949047961408.\n",
      "[I 2024-11-13 02:29:01,357] Trial 47 finished with value: 0.0016617753154598476 and parameters: {'dropout_p': 0.1856193072437315, 'lr': 0.023089592287843335}. Best is trial 44 with value: 0.0010858949047961408.\n",
      "[I 2024-11-13 02:29:19,636] Trial 48 finished with value: 0.004721152275158539 and parameters: {'dropout_p': 0.4749864746620099, 'lr': 0.0017120377964480286}. Best is trial 44 with value: 0.0010858949047961408.\n",
      "[I 2024-11-13 02:29:38,016] Trial 49 finished with value: 0.0021223146881750366 and parameters: {'dropout_p': 0.2381637285549988, 'lr': 0.008754629542675344}. Best is trial 44 with value: 0.0010858949047961408.\n",
      "[I 2024-11-13 02:29:57,088] Trial 50 finished with value: 0.0009493477657886635 and parameters: {'dropout_p': 0.15411387423783107, 'lr': 0.004148557791987595}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:30:16,538] Trial 51 finished with value: 0.0011419711626967728 and parameters: {'dropout_p': 0.16125528569072164, 'lr': 0.0047353691765247155}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:30:34,557] Trial 52 finished with value: 0.0011621532867009301 and parameters: {'dropout_p': 0.1551867357641944, 'lr': 0.004173014979931206}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:30:52,663] Trial 53 finished with value: 0.002412174567805591 and parameters: {'dropout_p': 0.11706129281515829, 'lr': 0.0021280167762277587}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:31:10,704] Trial 54 finished with value: 0.0014920284676162678 and parameters: {'dropout_p': 0.150643205936705, 'lr': 0.004169124787830558}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:31:28,909] Trial 55 finished with value: 0.003911742844104656 and parameters: {'dropout_p': 0.20409303169136475, 'lr': 0.0010324596999542234}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:31:46,961] Trial 56 finished with value: 0.0030090494977995912 and parameters: {'dropout_p': 0.1574020692621316, 'lr': 0.002594449534842614}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:32:05,408] Trial 57 finished with value: 0.004927460373134224 and parameters: {'dropout_p': 0.21683584588413113, 'lr': 0.0005488853826106714}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:32:23,692] Trial 58 finished with value: 0.002729959876845785 and parameters: {'dropout_p': 0.1126973283162418, 'lr': 0.0012599169530598503}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:32:42,092] Trial 59 finished with value: 0.001794274465286206 and parameters: {'dropout_p': 0.19143814413779273, 'lr': 0.004239666840480065}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:33:00,515] Trial 60 finished with value: 0.0020113794401695442 and parameters: {'dropout_p': 0.14722581767119308, 'lr': 0.0063385457061312656}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:33:18,871] Trial 61 finished with value: 0.001978004282266604 and parameters: {'dropout_p': 0.16045932637200097, 'lr': 0.0030693624674796452}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:33:37,179] Trial 62 finished with value: 0.0018073886272737083 and parameters: {'dropout_p': 0.16024464918283807, 'lr': 0.01088184353487525}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:33:55,915] Trial 63 finished with value: 0.00217183778356593 and parameters: {'dropout_p': 0.18128094803199135, 'lr': 0.007650429763001718}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:34:14,434] Trial 64 finished with value: 0.001394458225545744 and parameters: {'dropout_p': 0.2012562304598457, 'lr': 0.004698686600047383}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:34:32,848] Trial 65 finished with value: 0.0014386198686410527 and parameters: {'dropout_p': 0.11772562495159207, 'lr': 0.003203504625111177}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:34:51,749] Trial 66 finished with value: 0.0020920004947764686 and parameters: {'dropout_p': 0.14389402427144343, 'lr': 0.002045561311362275}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:35:10,004] Trial 67 finished with value: 0.0014688238211363878 and parameters: {'dropout_p': 0.169377425549849, 'lr': 0.0075343110680889626}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:35:29,003] Trial 68 finished with value: 0.0022251186996793022 and parameters: {'dropout_p': 0.19509234007143184, 'lr': 0.0022546502883033564}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:35:47,969] Trial 69 finished with value: 0.001089653365571149 and parameters: {'dropout_p': 0.24206104841264317, 'lr': 0.012430916972250527}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:36:07,220] Trial 70 finished with value: 0.0017236788254709574 and parameters: {'dropout_p': 0.2730003973864744, 'lr': 0.0035471799667357085}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:36:25,818] Trial 71 finished with value: 0.002136742711425479 and parameters: {'dropout_p': 0.24158423684202573, 'lr': 0.012346888043780856}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:36:44,275] Trial 72 finished with value: 0.0013187935703632934 and parameters: {'dropout_p': 0.23125163241760727, 'lr': 0.010610108051157037}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:37:03,807] Trial 73 finished with value: 0.001181193314985497 and parameters: {'dropout_p': 0.17663627901073037, 'lr': 0.00661337178667386}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:37:22,846] Trial 74 finished with value: 0.0017281017070995444 and parameters: {'dropout_p': 0.2144318065794892, 'lr': 0.004983935789171234}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:37:41,013] Trial 75 finished with value: 0.0028750645814940314 and parameters: {'dropout_p': 0.3169492267457017, 'lr': 0.019782338494406384}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:38:00,757] Trial 76 finished with value: 0.0029748310258453764 and parameters: {'dropout_p': 0.30408754122766635, 'lr': 0.006486045385224082}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:38:19,419] Trial 77 finished with value: 0.0024012875043727434 and parameters: {'dropout_p': 0.17731152044824988, 'lr': 0.0025242258068849423}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:38:37,674] Trial 78 finished with value: 0.0038642659880917226 and parameters: {'dropout_p': 0.2531757630332759, 'lr': 0.0011992695605715935}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:38:56,267] Trial 79 finished with value: 0.0010912898008899278 and parameters: {'dropout_p': 0.2737771292638171, 'lr': 0.03363709240527956}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:39:14,564] Trial 80 finished with value: 0.0016918898290192437 and parameters: {'dropout_p': 0.2680855395116492, 'lr': 0.05245550099824717}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:39:33,301] Trial 81 finished with value: 0.001081719546988674 and parameters: {'dropout_p': 0.13856635513952947, 'lr': 0.03355497954710884}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:39:52,100] Trial 82 finished with value: 0.0030942076160513222 and parameters: {'dropout_p': 0.3587521782599571, 'lr': 0.06766081699411361}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:40:10,510] Trial 83 finished with value: 0.0017519928285655375 and parameters: {'dropout_p': 0.14000437705851682, 'lr': 0.03468290511580103}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:40:28,880] Trial 84 finished with value: 0.003203326261693159 and parameters: {'dropout_p': 0.12516341233359904, 'lr': 0.08308452944498311}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:40:47,361] Trial 85 finished with value: 0.0011304913313578665 and parameters: {'dropout_p': 0.2989854578067066, 'lr': 0.02998681008014062}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:41:05,949] Trial 86 finished with value: 0.0014309049436849917 and parameters: {'dropout_p': 0.264695345307713, 'lr': 0.03024800185406193}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:41:24,150] Trial 87 finished with value: 0.002082466885275229 and parameters: {'dropout_p': 0.30775620029598366, 'lr': 0.0229716915228693}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:41:42,634] Trial 88 finished with value: 0.0019440636905882379 and parameters: {'dropout_p': 0.28483186610153427, 'lr': 0.06063481158415881}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:42:01,253] Trial 89 finished with value: 0.0027860890398687926 and parameters: {'dropout_p': 0.3380308209521926, 'lr': 0.01823529621959363}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:42:19,659] Trial 90 finished with value: 0.0016011394834273415 and parameters: {'dropout_p': 0.2937115881340651, 'lr': 0.013875617082412422}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:42:38,888] Trial 91 finished with value: 0.0024946277942390883 and parameters: {'dropout_p': 0.2506119403491817, 'lr': 0.041113621823329595}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:42:58,404] Trial 92 finished with value: 0.0015251563939702197 and parameters: {'dropout_p': 0.2808540411733371, 'lr': 0.02962631404503857}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:43:16,696] Trial 93 finished with value: 0.002602199972742588 and parameters: {'dropout_p': 0.3339110672779263, 'lr': 0.008415351080457741}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:43:35,115] Trial 94 finished with value: 0.001811744375696724 and parameters: {'dropout_p': 0.16670954231428448, 'lr': 0.0037439782557883348}. Best is trial 50 with value: 0.0009493477657886635.\n",
      "[I 2024-11-13 02:43:54,328] Trial 95 finished with value: 0.0009141122047890547 and parameters: {'dropout_p': 0.1061956636454461, 'lr': 0.0049514802746423794}. Best is trial 95 with value: 0.0009141122047890547.\n",
      "[I 2024-11-13 02:44:13,197] Trial 96 finished with value: 0.0009924178104953713 and parameters: {'dropout_p': 0.11177969951251343, 'lr': 0.022720504967228654}. Best is trial 95 with value: 0.0009141122047890547.\n",
      "[I 2024-11-13 02:44:33,378] Trial 97 finished with value: 0.0011451813650887573 and parameters: {'dropout_p': 0.12087812699756102, 'lr': 0.09682118495125541}. Best is trial 95 with value: 0.0009141122047890547.\n",
      "[I 2024-11-13 02:44:52,296] Trial 98 finished with value: 0.0009308916334594824 and parameters: {'dropout_p': 0.10311549053525114, 'lr': 0.023219368424635824}. Best is trial 95 with value: 0.0009141122047890547.\n",
      "[I 2024-11-13 02:45:10,640] Trial 99 finished with value: 0.0016804180252259061 and parameters: {'dropout_p': 0.11237291291560925, 'lr': 0.020555438651050625}. Best is trial 95 with value: 0.0009141122047890547.\n",
      "[I 2024-11-13 02:45:28,917] Trial 100 finished with value: 0.001053128094287467 and parameters: {'dropout_p': 0.10164093292746547, 'lr': 0.034165341490604524}. Best is trial 95 with value: 0.0009141122047890547.\n",
      "[I 2024-11-13 02:45:47,124] Trial 101 finished with value: 0.001049975939243144 and parameters: {'dropout_p': 0.10277324098450388, 'lr': 0.03454768074926592}. Best is trial 95 with value: 0.0009141122047890547.\n",
      "[I 2024-11-13 02:46:06,052] Trial 102 finished with value: 0.0012179672655780426 and parameters: {'dropout_p': 0.10752537778912818, 'lr': 0.036980696487178076}. Best is trial 95 with value: 0.0009141122047890547.\n",
      "[I 2024-11-13 02:46:25,428] Trial 103 finished with value: 0.00074258090234948 and parameters: {'dropout_p': 0.10162494477364468, 'lr': 0.05474557147316799}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:46:44,493] Trial 104 finished with value: 0.0012497678775479513 and parameters: {'dropout_p': 0.10361726622785064, 'lr': 0.05296357115650512}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:47:03,614] Trial 105 finished with value: 0.00234396714511138 and parameters: {'dropout_p': 0.10109248144831721, 'lr': 0.022812526542630093}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:47:22,624] Trial 106 finished with value: 0.0014795519491736353 and parameters: {'dropout_p': 0.13146456465973042, 'lr': 0.015937910631403304}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:47:41,519] Trial 107 finished with value: 0.0014542501299048755 and parameters: {'dropout_p': 0.10956696346548313, 'lr': 0.026121933022599617}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:48:00,426] Trial 108 finished with value: 0.0017565554042029646 and parameters: {'dropout_p': 0.12287339571984947, 'lr': 0.044831058718891835}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:48:18,997] Trial 109 finished with value: 0.001178291903898066 and parameters: {'dropout_p': 0.13882642358132088, 'lr': 0.03481536806840924}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:48:38,271] Trial 110 finished with value: 0.00219648829195487 and parameters: {'dropout_p': 0.12835142714887235, 'lr': 0.07543007897963652}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:48:58,376] Trial 111 finished with value: 0.001434490892378976 and parameters: {'dropout_p': 0.10027370082898715, 'lr': 0.06011927262519587}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:49:18,202] Trial 112 finished with value: 0.0018155580224908459 and parameters: {'dropout_p': 0.1177405578125467, 'lr': 0.01264930246576686}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:49:37,364] Trial 113 finished with value: 0.0014080547541322197 and parameters: {'dropout_p': 0.11269418281774428, 'lr': 0.01797515245856063}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:49:56,390] Trial 114 finished with value: 0.0008058307184796732 and parameters: {'dropout_p': 0.10991993934070582, 'lr': 0.02673851618756972}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:50:14,970] Trial 115 finished with value: 0.0010767394943506296 and parameters: {'dropout_p': 0.13516499656884326, 'lr': 0.024552869530522898}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:50:33,935] Trial 116 finished with value: 0.0012765484431479413 and parameters: {'dropout_p': 0.13359092942948853, 'lr': 0.02576254620904204}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:50:52,589] Trial 117 finished with value: 0.0010385771827960083 and parameters: {'dropout_p': 0.14607795643871058, 'lr': 0.04362171787058805}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:51:11,769] Trial 118 finished with value: 0.0011318987980239912 and parameters: {'dropout_p': 0.14301710568662432, 'lr': 0.05387776116706006}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:51:31,193] Trial 119 finished with value: 0.0018445761071488472 and parameters: {'dropout_p': 0.10930679537729099, 'lr': 0.04355091959693234}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:51:49,968] Trial 120 finished with value: 0.0010829519127190856 and parameters: {'dropout_p': 0.12385469828367698, 'lr': 0.04079418924286216}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:52:08,905] Trial 121 finished with value: 0.0017964375103130799 and parameters: {'dropout_p': 0.12185643546372586, 'lr': 0.03938706012322295}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:52:27,917] Trial 122 finished with value: 0.0013668831913669608 and parameters: {'dropout_p': 0.14911179450813541, 'lr': 0.021736694718413576}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:52:47,856] Trial 123 finished with value: 0.0023028729292821765 and parameters: {'dropout_p': 0.12993397381557498, 'lr': 0.028779751413369616}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:53:06,567] Trial 124 finished with value: 0.0017400730488147645 and parameters: {'dropout_p': 0.11843211245974616, 'lr': 0.0776716071919777}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:53:24,805] Trial 125 finished with value: 0.0017848092363135662 and parameters: {'dropout_p': 0.10609716806051386, 'lr': 0.05174602845789122}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:53:43,065] Trial 126 finished with value: 0.0008987520188177364 and parameters: {'dropout_p': 0.13609100914943284, 'lr': 0.0638912039167076}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:54:01,360] Trial 127 finished with value: 0.0016730139130832508 and parameters: {'dropout_p': 0.13884737649839857, 'lr': 0.06472426410128143}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:54:19,597] Trial 128 finished with value: 0.001018886768422348 and parameters: {'dropout_p': 0.12585496973166213, 'lr': 0.046552181426594716}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:54:37,894] Trial 129 finished with value: 0.0038660090226284257 and parameters: {'dropout_p': 0.1506263118653422, 'lr': 0.00026123999836714115}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:54:56,352] Trial 130 finished with value: 0.001200129343591673 and parameters: {'dropout_p': 0.11424432813326893, 'lr': 0.04799293115465787}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:55:14,565] Trial 131 finished with value: 0.0016644351506918825 and parameters: {'dropout_p': 0.12974618065276558, 'lr': 0.08816496027935775}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:55:32,823] Trial 132 finished with value: 0.0023747305521499276 and parameters: {'dropout_p': 0.1245116524445857, 'lr': 0.03318175774664284}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:55:51,025] Trial 133 finished with value: 0.001599850951960088 and parameters: {'dropout_p': 0.10047047080078338, 'lr': 0.042022378461386914}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:56:09,289] Trial 134 finished with value: 0.002185198546488188 and parameters: {'dropout_p': 0.13585478288359493, 'lr': 0.06047072472031672}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:56:27,505] Trial 135 finished with value: 0.0015351974604884073 and parameters: {'dropout_p': 0.10912648253305253, 'lr': 0.02598944962100206}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:56:45,772] Trial 136 finished with value: 0.0009565674054875872 and parameters: {'dropout_p': 0.12043246953609059, 'lr': 0.03504033210874657}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:57:04,075] Trial 137 finished with value: 0.004226914211035277 and parameters: {'dropout_p': 0.1158225489939076, 'lr': 5.74378892876617e-05}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:57:22,295] Trial 138 finished with value: 0.0024311628644577738 and parameters: {'dropout_p': 0.14428826111109544, 'lr': 0.0006639433454462732}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:57:40,511] Trial 139 finished with value: 0.001372217992469382 and parameters: {'dropout_p': 0.10896022485090576, 'lr': 0.03242225018554942}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:57:58,752] Trial 140 finished with value: 0.001657704888987942 and parameters: {'dropout_p': 0.13336945631916192, 'lr': 0.07407704669473708}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:58:17,100] Trial 141 finished with value: 0.0013932868582202543 and parameters: {'dropout_p': 0.3866671914635035, 'lr': 0.037020858678641036}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:58:35,975] Trial 142 finished with value: 0.0012721086179758117 and parameters: {'dropout_p': 0.1251391962247167, 'lr': 0.04364192650154359}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:58:55,390] Trial 143 finished with value: 0.002216973908879479 and parameters: {'dropout_p': 0.12031822580830773, 'lr': 0.025350123499958566}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:59:13,923] Trial 144 finished with value: 0.0015172049112708965 and parameters: {'dropout_p': 0.4441804887831796, 'lr': 0.018921356229251857}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:59:32,678] Trial 145 finished with value: 0.0023755124669272627 and parameters: {'dropout_p': 0.10039950788691684, 'lr': 0.055956256202489486}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 02:59:52,222] Trial 146 finished with value: 0.0008370008238951186 and parameters: {'dropout_p': 0.11420456311236961, 'lr': 0.03735767011277715}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:00:12,059] Trial 147 finished with value: 0.0010267123076111951 and parameters: {'dropout_p': 0.11239231818422928, 'lr': 0.02857661250037918}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:00:32,708] Trial 148 finished with value: 0.0016526581824627328 and parameters: {'dropout_p': 0.11249479549295886, 'lr': 0.016041737542074577}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:00:52,008] Trial 149 finished with value: 0.001659762111301465 and parameters: {'dropout_p': 0.10594169173418894, 'lr': 0.028817078362682137}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:01:11,491] Trial 150 finished with value: 0.001721440067474338 and parameters: {'dropout_p': 0.1167074669187898, 'lr': 0.022759737528452676}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:01:30,807] Trial 151 finished with value: 0.0011405211486301742 and parameters: {'dropout_p': 0.13592710890574478, 'lr': 0.03405834741893488}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:01:50,578] Trial 152 finished with value: 0.0016852546900049436 and parameters: {'dropout_p': 0.15454102595431776, 'lr': 0.047324041442998815}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:02:08,909] Trial 153 finished with value: 0.001516333334131283 and parameters: {'dropout_p': 0.1266637468389077, 'lr': 0.06671305540146563}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:02:26,763] Trial 154 finished with value: 0.0014849533213772323 and parameters: {'dropout_p': 0.10056596070557727, 'lr': 0.029451422923570808}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:02:44,507] Trial 155 finished with value: 0.0014047877651380003 and parameters: {'dropout_p': 0.14265013672928384, 'lr': 0.021515495918574993}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:03:02,913] Trial 156 finished with value: 0.0017146658047720495 and parameters: {'dropout_p': 0.11069913507064688, 'lr': 0.039258087399573434}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:03:22,176] Trial 157 finished with value: 0.0016580294824459297 and parameters: {'dropout_p': 0.12114658423469535, 'lr': 0.053700964633457415}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:03:41,499] Trial 158 finished with value: 0.0011761536595313066 and parameters: {'dropout_p': 0.13022007181723838, 'lr': 0.025615960311855864}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:04:01,124] Trial 159 finished with value: 0.0023434885982424078 and parameters: {'dropout_p': 0.11387238992301645, 'lr': 0.018556161154748386}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:04:20,013] Trial 160 finished with value: 0.0019125841189146073 and parameters: {'dropout_p': 0.10763600665647843, 'lr': 0.0320941781846494}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:04:40,242] Trial 161 finished with value: 0.0010884379091845244 and parameters: {'dropout_p': 0.12347333921702966, 'lr': 0.039723490683128665}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:05:01,659] Trial 162 finished with value: 0.00256699164329638 and parameters: {'dropout_p': 0.11938320701524242, 'lr': 0.04846006616561419}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:05:21,116] Trial 163 finished with value: 0.0022981361902101637 and parameters: {'dropout_p': 0.13885094287288197, 'lr': 0.04254770493399197}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:05:41,172] Trial 164 finished with value: 0.003971012713924347 and parameters: {'dropout_p': 0.15032120068142998, 'lr': 0.09620439011707627}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:06:01,844] Trial 165 finished with value: 0.0009441233519531593 and parameters: {'dropout_p': 0.1293958345402765, 'lr': 0.03367176400541863}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:06:20,713] Trial 166 finished with value: 0.0018229849080599536 and parameters: {'dropout_p': 0.1326975267562902, 'lr': 0.029487424796871976}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:06:39,682] Trial 167 finished with value: 0.0009598015739039343 and parameters: {'dropout_p': 0.10804215541309525, 'lr': 0.022273776600027072}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:06:58,873] Trial 168 finished with value: 0.0016159517303841616 and parameters: {'dropout_p': 0.10648061972215399, 'lr': 0.014431189950598894}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:07:16,926] Trial 169 finished with value: 0.0012525114902202645 and parameters: {'dropout_p': 0.1001601349986902, 'lr': 0.022560819550990444}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:07:35,671] Trial 170 finished with value: 0.0009303547635291395 and parameters: {'dropout_p': 0.11577750726288516, 'lr': 0.018813770561182254}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:07:55,151] Trial 171 finished with value: 0.0014044303216393277 and parameters: {'dropout_p': 0.11646916794717233, 'lr': 0.01801057009906259}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:08:13,476] Trial 172 finished with value: 0.0022434686680944276 and parameters: {'dropout_p': 0.10986106811386079, 'lr': 0.02523754056617261}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:08:31,642] Trial 173 finished with value: 0.0012996755456618787 and parameters: {'dropout_p': 0.11980616817892023, 'lr': 0.01984850931772186}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:08:50,769] Trial 174 finished with value: 0.000980738380483153 and parameters: {'dropout_p': 0.1274877351458779, 'lr': 0.03624735823361199}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:09:09,073] Trial 175 finished with value: 0.0011643442069854556 and parameters: {'dropout_p': 0.11322772628816595, 'lr': 0.03698907205789024}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:09:27,508] Trial 176 finished with value: 0.0021062481974082475 and parameters: {'dropout_p': 0.10011550731334776, 'lr': 0.06556510577123337}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:09:45,423] Trial 177 finished with value: 0.0013813598885358256 and parameters: {'dropout_p': 0.1277284932740172, 'lr': 0.053726145917310696}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:10:03,873] Trial 178 finished with value: 0.001364559672648446 and parameters: {'dropout_p': 0.10695247704702905, 'lr': 0.03178114121726948}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:10:21,976] Trial 179 finished with value: 0.0015924120281105372 and parameters: {'dropout_p': 0.1255253580509729, 'lr': 0.049030947424276716}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:10:39,977] Trial 180 finished with value: 0.0017699434070985358 and parameters: {'dropout_p': 0.1149413302916979, 'lr': 0.036841317060559056}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:10:58,500] Trial 181 finished with value: 0.0016777913627177138 and parameters: {'dropout_p': 0.133239059194363, 'lr': 0.027035214904917095}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:11:16,337] Trial 182 finished with value: 0.0015731810197450414 and parameters: {'dropout_p': 0.11860105490339544, 'lr': 0.022639246447366153}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:11:34,374] Trial 183 finished with value: 0.0018985698475352426 and parameters: {'dropout_p': 0.14524051949233938, 'lr': 0.015205337892973075}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:11:52,447] Trial 184 finished with value: 0.0012390616479231377 and parameters: {'dropout_p': 0.10624107933368963, 'lr': 0.03036607577090464}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:12:10,110] Trial 185 finished with value: 0.0018456421290966108 and parameters: {'dropout_p': 0.12635826670144681, 'lr': 0.04422357555563989}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:12:27,906] Trial 186 finished with value: 0.0012201281449852113 and parameters: {'dropout_p': 0.11237692112353809, 'lr': 0.02456712977249895}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:12:45,557] Trial 187 finished with value: 0.0013824868709004356 and parameters: {'dropout_p': 0.13734108177623344, 'lr': 0.034034737194042694}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:13:03,733] Trial 188 finished with value: 0.0011390652540344143 and parameters: {'dropout_p': 0.11949273280402442, 'lr': 0.05941134567239062}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:13:21,483] Trial 189 finished with value: 0.0037181828098608763 and parameters: {'dropout_p': 0.10665605487954145, 'lr': 0.07510239705158639}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:13:39,202] Trial 190 finished with value: 0.0020974713867938943 and parameters: {'dropout_p': 0.13021225427177813, 'lr': 0.01981244646742602}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:13:57,247] Trial 191 finished with value: 0.0017282343602396549 and parameters: {'dropout_p': 0.14169926756218496, 'lr': 0.03754219487486615}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:14:14,920] Trial 192 finished with value: 0.001949718362621125 and parameters: {'dropout_p': 0.1507955864868096, 'lr': 0.028149167603734496}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:14:32,743] Trial 193 finished with value: 0.0020713394240541596 and parameters: {'dropout_p': 0.11553227859115493, 'lr': 0.03543029992217711}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:14:50,955] Trial 194 finished with value: 0.00191278195178347 and parameters: {'dropout_p': 0.13348436112079648, 'lr': 0.0451658010767865}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:15:08,647] Trial 195 finished with value: 0.0010779715984111657 and parameters: {'dropout_p': 0.12480718423510294, 'lr': 0.028023599929913445}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:15:26,483] Trial 196 finished with value: 0.0016050182135135481 and parameters: {'dropout_p': 0.1007469497998727, 'lr': 0.016946775745828622}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:15:44,147] Trial 197 finished with value: 0.0010718787515829724 and parameters: {'dropout_p': 0.12142859136838124, 'lr': 0.023159139645399056}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:16:02,199] Trial 198 finished with value: 0.0012575512850816755 and parameters: {'dropout_p': 0.10857194085142607, 'lr': 0.020752810765568674}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:16:19,966] Trial 199 finished with value: 0.0012791082371552444 and parameters: {'dropout_p': 0.12099637160601973, 'lr': 0.02449251327262366}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:16:37,635] Trial 200 finished with value: 0.001588953105023219 and parameters: {'dropout_p': 0.11367501664570494, 'lr': 0.014827008050486742}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:16:55,845] Trial 201 finished with value: 0.0012259655599913195 and parameters: {'dropout_p': 0.12643016620265568, 'lr': 0.03348256207991722}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:17:13,516] Trial 202 finished with value: 0.0011499401090578336 and parameters: {'dropout_p': 0.12284308429913574, 'lr': 0.026994998011245785}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:17:31,274] Trial 203 finished with value: 0.0012144983154737485 and parameters: {'dropout_p': 0.10680296343434188, 'lr': 0.028821663422697773}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:17:49,272] Trial 204 finished with value: 0.0010452831020535608 and parameters: {'dropout_p': 0.1161334444903264, 'lr': 0.021860869032162316}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:18:07,063] Trial 205 finished with value: 0.0011634796372564146 and parameters: {'dropout_p': 0.10057249198079167, 'lr': 0.021671298996137508}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:18:24,880] Trial 206 finished with value: 0.001381439892228816 and parameters: {'dropout_p': 0.1141828172824732, 'lr': 0.017416226693305295}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:18:42,542] Trial 207 finished with value: 0.001653129479154858 and parameters: {'dropout_p': 0.13266092962539816, 'lr': 0.012909042001567934}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:19:00,719] Trial 208 finished with value: 0.0017441160000533028 and parameters: {'dropout_p': 0.11149238961902745, 'lr': 0.009575934625327319}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:19:18,656] Trial 209 finished with value: 0.0009898958878901856 and parameters: {'dropout_p': 0.1183828453774321, 'lr': 0.0408561619836245}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:19:36,394] Trial 210 finished with value: 0.00148781273134428 and parameters: {'dropout_p': 0.12038085555082179, 'lr': 0.052045215691988216}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:19:54,568] Trial 211 finished with value: 0.0016727906557376007 and parameters: {'dropout_p': 0.10005268384470677, 'lr': 0.0416663755523732}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:20:12,409] Trial 212 finished with value: 0.0009426395317371223 and parameters: {'dropout_p': 0.11602954632953769, 'lr': 0.03824092088915893}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:20:30,244] Trial 213 finished with value: 0.0008560203200612218 and parameters: {'dropout_p': 0.1129627032300488, 'lr': 0.03947753789658881}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:20:48,244] Trial 214 finished with value: 0.001111884923926195 and parameters: {'dropout_p': 0.11260746964797787, 'lr': 0.045720402257888315}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:21:06,244] Trial 215 finished with value: 0.0032865871128408873 and parameters: {'dropout_p': 0.10748597079921322, 'lr': 0.05833913307358643}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:21:24,192] Trial 216 finished with value: 0.0012016326158268303 and parameters: {'dropout_p': 0.1156554602143362, 'lr': 0.035886993322088515}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:21:42,070] Trial 217 finished with value: 0.001380148023865119 and parameters: {'dropout_p': 0.1069730174693192, 'lr': 0.04375102103907065}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:22:00,353] Trial 218 finished with value: 0.0022582921908324656 and parameters: {'dropout_p': 0.12510591942984994, 'lr': 0.001429080298631298}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:22:18,274] Trial 219 finished with value: 0.0016664601752587752 and parameters: {'dropout_p': 0.11631636956656288, 'lr': 0.03876452557029469}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:22:36,213] Trial 220 finished with value: 0.0010951415716937058 and parameters: {'dropout_p': 0.10612523139390971, 'lr': 0.05240044071598058}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:22:54,499] Trial 221 finished with value: 0.0011808363219036608 and parameters: {'dropout_p': 0.11911394445471532, 'lr': 0.029870357083432286}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:23:12,171] Trial 222 finished with value: 0.0013850259680480048 and parameters: {'dropout_p': 0.12634318221486887, 'lr': 0.03570839209734109}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:23:29,961] Trial 223 finished with value: 0.0010825957826102212 and parameters: {'dropout_p': 0.11042813412460999, 'lr': 0.031578637993795275}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:23:47,770] Trial 224 finished with value: 0.002255933381762061 and parameters: {'dropout_p': 0.1190592916529164, 'lr': 0.062317345050284974}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:24:05,672] Trial 225 finished with value: 0.000985514816808717 and parameters: {'dropout_p': 0.10084767718152997, 'lr': 0.022107650220189817}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:24:23,450] Trial 226 finished with value: 0.0017796537358738015 and parameters: {'dropout_p': 0.10010974192003513, 'lr': 0.046685706687473676}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:24:41,107] Trial 227 finished with value: 0.002131655562406915 and parameters: {'dropout_p': 0.10842886143033088, 'lr': 0.039624298196680646}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:24:59,336] Trial 228 finished with value: 0.007297101455838771 and parameters: {'dropout_p': 0.11127204316745339, 'lr': 2.0118109166853416e-05}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:25:17,177] Trial 229 finished with value: 0.0017551995313735678 and parameters: {'dropout_p': 0.10097844096831929, 'lr': 0.025899853956230734}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:25:34,993] Trial 230 finished with value: 0.0016262757539885714 and parameters: {'dropout_p': 0.1304679154793499, 'lr': 0.019291732603485802}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:25:53,045] Trial 231 finished with value: 0.001092379343598004 and parameters: {'dropout_p': 0.12040057651161405, 'lr': 0.022242910544537572}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:26:10,716] Trial 232 finished with value: 0.0015416284533088375 and parameters: {'dropout_p': 0.11452044686152882, 'lr': 0.031744633372447414}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:26:28,491] Trial 233 finished with value: 0.0024096130079978685 and parameters: {'dropout_p': 0.10728086552284231, 'lr': 0.024750974661464812}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:26:46,141] Trial 234 finished with value: 0.0011650014025888992 and parameters: {'dropout_p': 0.12644811498838532, 'lr': 0.03289384111794825}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:27:04,364] Trial 235 finished with value: 0.0013276262948439302 and parameters: {'dropout_p': 0.13839004444812986, 'lr': 0.021177626512103122}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:27:22,150] Trial 236 finished with value: 0.0021790455117200267 and parameters: {'dropout_p': 0.11803902163314661, 'lr': 0.04002422245416929}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:27:39,786] Trial 237 finished with value: 0.0027054128323395817 and parameters: {'dropout_p': 0.4905145669650608, 'lr': 0.027103328322911933}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:27:57,851] Trial 238 finished with value: 0.0026782452252225265 and parameters: {'dropout_p': 0.10583080005459505, 'lr': 0.06969106076875961}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:28:15,556] Trial 239 finished with value: 0.0022903211796762167 and parameters: {'dropout_p': 0.11473372047069139, 'lr': 0.04789764307640095}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:28:33,332] Trial 240 finished with value: 0.0013156989195259106 and parameters: {'dropout_p': 0.10034515183779505, 'lr': 0.03093326435194505}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:28:51,487] Trial 241 finished with value: 0.0010011801470102995 and parameters: {'dropout_p': 0.1359528019891428, 'lr': 0.02444418614859905}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:29:09,127] Trial 242 finished with value: 0.0017375963648594474 and parameters: {'dropout_p': 0.14258288669738833, 'lr': 0.022986692943625455}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:29:26,900] Trial 243 finished with value: 0.0018418280070987127 and parameters: {'dropout_p': 0.1310844554795268, 'lr': 0.026975324828930176}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:29:44,569] Trial 244 finished with value: 0.0012833878205689392 and parameters: {'dropout_p': 0.12597572430089524, 'lr': 0.01704309167632943}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:30:02,586] Trial 245 finished with value: 0.0008519412370716974 and parameters: {'dropout_p': 0.11230395315100171, 'lr': 0.03639932301270784}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:30:20,345] Trial 246 finished with value: 0.0027486301922642854 and parameters: {'dropout_p': 0.11128952495492546, 'lr': 0.0008914904951599922}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:30:37,995] Trial 247 finished with value: 0.0014129918952453808 and parameters: {'dropout_p': 0.10810866495754065, 'lr': 0.03801564518127014}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:30:56,161] Trial 248 finished with value: 0.0020164735291868224 and parameters: {'dropout_p': 0.1200225933249062, 'lr': 0.05293846915317115}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:31:13,817] Trial 249 finished with value: 0.0016358812554350208 and parameters: {'dropout_p': 0.13391414411797592, 'lr': 0.03329080629140632}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:31:31,606] Trial 250 finished with value: 0.004001708444309862 and parameters: {'dropout_p': 0.10029855078857536, 'lr': 0.00040808628112097654}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:31:49,589] Trial 251 finished with value: 0.0026729430546574315 and parameters: {'dropout_p': 0.11637575255534688, 'lr': 0.04034846644499461}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:32:07,378] Trial 252 finished with value: 0.001020751348287769 and parameters: {'dropout_p': 0.1477006617986222, 'lr': 0.045106872700311836}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:32:25,173] Trial 253 finished with value: 0.001648680345464788 and parameters: {'dropout_p': 0.1576464029088382, 'lr': 0.049683821036869136}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:32:42,836] Trial 254 finished with value: 0.0018120818221664821 and parameters: {'dropout_p': 0.14468146428960324, 'lr': 0.046130518623180884}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:33:00,985] Trial 255 finished with value: 0.0024916215732490327 and parameters: {'dropout_p': 0.14796480624179456, 'lr': 0.05886050353818415}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:33:18,701] Trial 256 finished with value: 0.0011514889895361856 and parameters: {'dropout_p': 0.1646976163667176, 'lr': 0.039367382042959795}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:33:36,440] Trial 257 finished with value: 0.001686306543115581 and parameters: {'dropout_p': 0.12646105672507996, 'lr': 0.028816649277113984}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:33:54,465] Trial 258 finished with value: 0.0018378295149424455 and parameters: {'dropout_p': 0.1375485219965148, 'lr': 0.032457438548152646}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:34:12,132] Trial 259 finished with value: 0.0008051710040107706 and parameters: {'dropout_p': 0.1304643833429106, 'lr': 0.07481007820076771}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:34:29,907] Trial 260 finished with value: 0.0009058557134552374 and parameters: {'dropout_p': 0.1507999767666121, 'lr': 0.05569377962773074}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:34:47,686] Trial 261 finished with value: 0.001836072144987721 and parameters: {'dropout_p': 0.14851437132584777, 'lr': 0.06586227605660983}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:35:05,638] Trial 262 finished with value: 0.0012395325451630538 and parameters: {'dropout_p': 0.1602061853991008, 'lr': 0.08442333628383575}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:35:23,439] Trial 263 finished with value: 0.003249460230778038 and parameters: {'dropout_p': 0.13980160471645786, 'lr': 0.07816014972225517}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:35:41,104] Trial 264 finished with value: 0.0022811511809334517 and parameters: {'dropout_p': 0.15017319409581473, 'lr': 0.06143135952874215}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:35:59,276] Trial 265 finished with value: 0.001733339726672562 and parameters: {'dropout_p': 0.15532309114180648, 'lr': 0.09421349234491597}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:36:16,945] Trial 266 finished with value: 0.001945299402667568 and parameters: {'dropout_p': 0.13164327397614545, 'lr': 0.054961621778660895}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:36:34,738] Trial 267 finished with value: 0.002041799427321339 and parameters: {'dropout_p': 0.14103138683654975, 'lr': 0.08094035557974451}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:36:52,766] Trial 268 finished with value: 0.004411115172706962 and parameters: {'dropout_p': 0.1304900626785238, 'lr': 0.0001030680860593605}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:37:10,422] Trial 269 finished with value: 0.0019280457267073752 and parameters: {'dropout_p': 0.12478514710545682, 'lr': 0.046447381781684845}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:37:28,219] Trial 270 finished with value: 0.0011506165099014714 and parameters: {'dropout_p': 0.39045465028419957, 'lr': 0.07248442190133805}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:37:45,865] Trial 271 finished with value: 0.0016117015680147423 and parameters: {'dropout_p': 0.13391602432653077, 'lr': 0.061644472346655654}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:38:04,054] Trial 272 finished with value: 0.0013445011080349726 and parameters: {'dropout_p': 0.1436608971457855, 'lr': 0.04674840929916495}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:38:21,857] Trial 273 finished with value: 0.002835252578741371 and parameters: {'dropout_p': 0.47052822481391404, 'lr': 0.03910391160549703}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:38:39,523] Trial 274 finished with value: 0.003334053673232018 and parameters: {'dropout_p': 0.16746910338273416, 'lr': 0.054449175268865606}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:38:57,574] Trial 275 finished with value: 0.0021008424669689955 and parameters: {'dropout_p': 0.11845762998784481, 'lr': 0.04401722143553607}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:39:15,236] Trial 276 finished with value: 0.0010982101616958983 and parameters: {'dropout_p': 0.12612808992849436, 'lr': 0.07147826018530914}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:39:33,092] Trial 277 finished with value: 0.0016561842607791932 and parameters: {'dropout_p': 0.11032873014448444, 'lr': 0.03596113155704731}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:39:51,302] Trial 278 finished with value: 0.0018523931949390579 and parameters: {'dropout_p': 0.13823393688292804, 'lr': 0.02763547323519471}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:40:08,993] Trial 279 finished with value: 0.0011687020929609928 and parameters: {'dropout_p': 0.12220532112875881, 'lr': 0.018179627845916913}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:40:26,788] Trial 280 finished with value: 0.0011948875371703678 and parameters: {'dropout_p': 0.11249829884018554, 'lr': 0.005488363498493059}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:40:44,445] Trial 281 finished with value: 0.0014864460280247067 and parameters: {'dropout_p': 0.15124766073007936, 'lr': 0.05813482819867455}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:41:02,508] Trial 282 finished with value: 0.0023171889863928615 and parameters: {'dropout_p': 0.13171010009552928, 'lr': 0.04234591186384197}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:41:20,282] Trial 283 finished with value: 0.002064851403727192 and parameters: {'dropout_p': 0.10931368770715134, 'lr': 0.03199112257660677}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:41:37,944] Trial 284 finished with value: 0.0015985511251515843 and parameters: {'dropout_p': 0.12058030557171573, 'lr': 0.05118445704301946}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:41:56,100] Trial 285 finished with value: 0.0014697526557657474 and parameters: {'dropout_p': 0.11240075371502703, 'lr': 0.001795214012072171}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:42:13,730] Trial 286 finished with value: 0.0013833359015553834 and parameters: {'dropout_p': 0.12268976161319632, 'lr': 0.026159735250709495}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:42:31,506] Trial 287 finished with value: 0.0013078064375736667 and parameters: {'dropout_p': 0.13591897045899498, 'lr': 0.020040395320093416}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:42:49,464] Trial 288 finished with value: 0.002111807380807958 and parameters: {'dropout_p': 0.10779861899591542, 'lr': 0.03894607502299641}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:43:07,206] Trial 289 finished with value: 0.002439012462362224 and parameters: {'dropout_p': 0.1274515750685865, 'lr': 0.002853620822906614}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:43:25,016] Trial 290 finished with value: 0.0017113148947582864 and parameters: {'dropout_p': 0.14528569049566334, 'lr': 0.09936295827178893}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:43:42,722] Trial 291 finished with value: 0.002889693838792041 and parameters: {'dropout_p': 0.11635833837378443, 'lr': 0.030665004537892965}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:44:00,898] Trial 292 finished with value: 0.0012712392080025249 and parameters: {'dropout_p': 0.1554612968909575, 'lr': 0.013701073618638388}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:44:18,582] Trial 293 finished with value: 0.0013475097572406196 and parameters: {'dropout_p': 0.10535331594841307, 'lr': 0.024270096195166804}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:44:36,328] Trial 294 finished with value: 0.0019715306655745854 and parameters: {'dropout_p': 0.1168549988185783, 'lr': 0.03766281814455822}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:44:54,377] Trial 295 finished with value: 0.0019056915068465159 and parameters: {'dropout_p': 0.12809543303472015, 'lr': 0.049267619319083106}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:45:12,052] Trial 296 finished with value: 0.001178017371531785 and parameters: {'dropout_p': 0.10761456927180293, 'lr': 0.06549792702246388}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:45:29,815] Trial 297 finished with value: 0.0010690319694244294 and parameters: {'dropout_p': 0.1391790351337181, 'lr': 0.03328874859661387}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:45:47,565] Trial 298 finished with value: 0.001107154023576991 and parameters: {'dropout_p': 0.12147088840406932, 'lr': 0.043632790635799626}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:46:05,640] Trial 299 finished with value: 0.001607628068367784 and parameters: {'dropout_p': 0.11492571555557504, 'lr': 0.016061606710585992}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:46:23,393] Trial 300 finished with value: 0.0012816486070220004 and parameters: {'dropout_p': 0.13228079483703192, 'lr': 0.024946820839192647}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:46:41,013] Trial 301 finished with value: 0.0015106151990149726 and parameters: {'dropout_p': 0.10242024851587443, 'lr': 0.05437590387465571}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:46:59,108] Trial 302 finished with value: 0.0009410590249952772 and parameters: {'dropout_p': 0.10073074098447257, 'lr': 0.007065828981248785}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:47:16,760] Trial 303 finished with value: 0.0013152382231147101 and parameters: {'dropout_p': 0.10699373792126218, 'lr': 0.007949667385475149}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:47:34,554] Trial 304 finished with value: 0.0014431244708148115 and parameters: {'dropout_p': 0.10111870954286897, 'lr': 0.004125812771681101}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:47:52,697] Trial 305 finished with value: 0.0015501850580647116 and parameters: {'dropout_p': 0.11268483001168755, 'lr': 0.005132414708354534}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:48:10,376] Trial 306 finished with value: 0.0011769551469886072 and parameters: {'dropout_p': 0.100559601890282, 'lr': 0.00603981456730003}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:48:28,158] Trial 307 finished with value: 0.001217548385673845 and parameters: {'dropout_p': 0.12159353873286605, 'lr': 0.020708250655765342}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:48:45,799] Trial 308 finished with value: 0.0016807509192071793 and parameters: {'dropout_p': 0.11177177395190646, 'lr': 0.006897107843166913}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:49:03,830] Trial 309 finished with value: 0.0023424911865208534 and parameters: {'dropout_p': 0.11478700929416757, 'lr': 0.0122314161209112}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:49:21,623] Trial 310 finished with value: 0.0021765695999814163 and parameters: {'dropout_p': 0.12428565298217407, 'lr': 0.003655284990207074}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:49:39,252] Trial 311 finished with value: 0.001565027698712948 and parameters: {'dropout_p': 0.10049121157491929, 'lr': 0.004579799640346713}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:49:57,408] Trial 312 finished with value: 0.0024869993610070282 and parameters: {'dropout_p': 0.1084581618090445, 'lr': 0.02899703938335006}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:50:15,068] Trial 313 finished with value: 0.0017013486361844412 and parameters: {'dropout_p': 0.11862664496016959, 'lr': 0.01864396049118255}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:50:32,856] Trial 314 finished with value: 0.0010298185071339126 and parameters: {'dropout_p': 0.1296013510105127, 'lr': 0.0779876276109106}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:50:50,918] Trial 315 finished with value: 0.0013587622153809554 and parameters: {'dropout_p': 0.10835171698659635, 'lr': 0.00943738698719842}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:51:08,582] Trial 316 finished with value: 0.0008925310694090389 and parameters: {'dropout_p': 0.11817416839440646, 'lr': 0.023769281389796653}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:51:26,358] Trial 317 finished with value: 0.0029391923464232835 and parameters: {'dropout_p': 0.13489919205725084, 'lr': 0.02339551889427877}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:51:44,056] Trial 318 finished with value: 0.0013280116993862469 and parameters: {'dropout_p': 0.12523306020210673, 'lr': 0.03558739094395017}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:52:02,254] Trial 319 finished with value: 0.0014141519880084778 and parameters: {'dropout_p': 0.1197511989410576, 'lr': 0.015154510969834098}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:52:19,960] Trial 320 finished with value: 0.0009283054304290338 and parameters: {'dropout_p': 0.10033924460602488, 'lr': 0.0032399362995289634}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:52:37,716] Trial 321 finished with value: 0.0012233654013553276 and parameters: {'dropout_p': 0.10047677891748455, 'lr': 0.0024774052321863012}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:52:55,790] Trial 322 finished with value: 0.001597229998253727 and parameters: {'dropout_p': 0.10820450072176101, 'lr': 0.0034247742701307166}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:53:13,445] Trial 323 finished with value: 0.002430694109636015 and parameters: {'dropout_p': 0.11257519399601341, 'lr': 0.006450771113128573}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:53:31,222] Trial 324 finished with value: 0.0009647544599560061 and parameters: {'dropout_p': 0.1169309355180196, 'lr': 0.004938925975868767}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:53:49,234] Trial 325 finished with value: 0.0010235892406331036 and parameters: {'dropout_p': 0.11752094424362056, 'lr': 0.004612286146476324}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:54:07,075] Trial 326 finished with value: 0.0013711846694933905 and parameters: {'dropout_p': 0.10037457143220513, 'lr': 0.005268032847182897}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:54:24,867] Trial 327 finished with value: 0.0010214236547432488 and parameters: {'dropout_p': 0.107917110599788, 'lr': 0.0037010596708705198}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:54:42,551] Trial 328 finished with value: 0.0015383056238649827 and parameters: {'dropout_p': 0.1147364858243802, 'lr': 0.003039984068756141}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:55:00,582] Trial 329 finished with value: 0.0012252809318986076 and parameters: {'dropout_p': 0.1077161507868304, 'lr': 0.004144233410257515}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:55:18,276] Trial 330 finished with value: 0.0015744552879806179 and parameters: {'dropout_p': 0.1230924242740932, 'lr': 0.0050207007437605465}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:55:35,998] Trial 331 finished with value: 0.001235900709328396 and parameters: {'dropout_p': 0.10059569490134654, 'lr': 0.01904354309465573}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:55:54,195] Trial 332 finished with value: 0.0019527250877812408 and parameters: {'dropout_p': 0.11562033517593422, 'lr': 0.0058580473929523355}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:56:11,867] Trial 333 finished with value: 0.0010935319027485207 and parameters: {'dropout_p': 0.1295755689135805, 'lr': 0.006774117703023329}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:56:29,664] Trial 334 finished with value: 0.0013229293255644188 and parameters: {'dropout_p': 0.10798434429652448, 'lr': 0.0031866960828637637}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:56:47,386] Trial 335 finished with value: 0.001368967876968898 and parameters: {'dropout_p': 0.1203148831573498, 'lr': 0.007911196633143772}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:57:05,373] Trial 336 finished with value: 0.0009690120517523116 and parameters: {'dropout_p': 0.11352049819739968, 'lr': 0.024668580961383912}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:57:23,138] Trial 337 finished with value: 0.0013964493298859548 and parameters: {'dropout_p': 0.10014995113802533, 'lr': 0.02832500979653799}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:57:40,821] Trial 338 finished with value: 0.0011856815888095225 and parameters: {'dropout_p': 0.11236748444454825, 'lr': 0.02092679601905344}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:57:58,986] Trial 339 finished with value: 0.0016030884960292876 and parameters: {'dropout_p': 0.11016347019998472, 'lr': 0.00207314288380481}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:58:16,644] Trial 340 finished with value: 0.0009933495641412803 and parameters: {'dropout_p': 0.119992873118348, 'lr': 0.003919686108766172}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:58:34,424] Trial 341 finished with value: 0.0014040608388526693 and parameters: {'dropout_p': 0.10682844835913598, 'lr': 0.024263444284697764}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:58:52,528] Trial 342 finished with value: 0.0021145404919188046 and parameters: {'dropout_p': 0.367758162350201, 'lr': 0.016412329096051486}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:59:10,169] Trial 343 finished with value: 0.0016867915477571827 and parameters: {'dropout_p': 0.11807637026907063, 'lr': 0.0319166552214631}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:59:27,934] Trial 344 finished with value: 0.0015312835676612065 and parameters: {'dropout_p': 0.11399340310343824, 'lr': 0.004731711513773072}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 03:59:45,624] Trial 345 finished with value: 0.0017741154665827817 and parameters: {'dropout_p': 0.10042854816611736, 'lr': 0.029023572259425562}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:00:03,817] Trial 346 finished with value: 0.001948906130769339 and parameters: {'dropout_p': 0.1261454731926352, 'lr': 0.06990775527267705}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:00:21,578] Trial 347 finished with value: 0.001468415316812982 and parameters: {'dropout_p': 0.10990454936265831, 'lr': 0.012084717623959922}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:00:39,250] Trial 348 finished with value: 0.002977471497092859 and parameters: {'dropout_p': 0.12537485275534205, 'lr': 0.000562399322160269}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:00:57,292] Trial 349 finished with value: 0.0010143355900435382 and parameters: {'dropout_p': 0.11511518075089275, 'lr': 0.03590357693732968}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:01:14,966] Trial 350 finished with value: 0.0015262222858056763 and parameters: {'dropout_p': 0.10822775986098168, 'lr': 0.023254306763724298}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:01:32,753] Trial 351 finished with value: 0.0017831824001425382 and parameters: {'dropout_p': 0.12031930225274964, 'lr': 0.03799366925496244}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:01:52,067] Trial 352 finished with value: 0.0012346106337972076 and parameters: {'dropout_p': 0.12900486151658827, 'lr': 0.02651492218506155}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:02:10,623] Trial 353 finished with value: 0.001704066431866458 and parameters: {'dropout_p': 0.10766930529574431, 'lr': 0.010452361040120805}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:02:28,537] Trial 354 finished with value: 0.0012604278802359277 and parameters: {'dropout_p': 0.11442617786031131, 'lr': 0.020012158510222026}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:02:46,622] Trial 355 finished with value: 0.0032716763752240396 and parameters: {'dropout_p': 0.11954328301133665, 'lr': 0.05201538472756756}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:03:04,361] Trial 356 finished with value: 0.001925468409108389 and parameters: {'dropout_p': 0.4193655267069173, 'lr': 0.08640225618499435}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:03:22,119] Trial 357 finished with value: 0.0014788305121684266 and parameters: {'dropout_p': 0.10011304945488056, 'lr': 0.06430705352222477}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:03:39,763] Trial 358 finished with value: 0.0012305633596015211 and parameters: {'dropout_p': 0.13645781728382247, 'lr': 0.0323339044588741}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:03:57,800] Trial 359 finished with value: 0.0015854976617417772 and parameters: {'dropout_p': 0.10718958246484986, 'lr': 0.005807247267145995}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:04:15,457] Trial 360 finished with value: 0.0010687561102196517 and parameters: {'dropout_p': 0.12657053951609568, 'lr': 0.017843245770542634}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:04:33,207] Trial 361 finished with value: 0.001962570749339782 and parameters: {'dropout_p': 0.11604744900247217, 'lr': 0.04153367530080812}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:04:51,326] Trial 362 finished with value: 0.0013134624585751464 and parameters: {'dropout_p': 0.10678005709399836, 'lr': 0.027847630379083572}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:05:08,968] Trial 363 finished with value: 0.001294776710592934 and parameters: {'dropout_p': 0.12956186032116374, 'lr': 0.022150120921386827}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:05:26,775] Trial 364 finished with value: 0.0010906825073011344 and parameters: {'dropout_p': 0.12072845533728746, 'lr': 0.03545635023321679}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:05:44,434] Trial 365 finished with value: 0.0007461680538556691 and parameters: {'dropout_p': 0.11506785946605108, 'lr': 0.05909950393126002}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:06:02,219] Trial 366 finished with value: 0.0015502256823473964 and parameters: {'dropout_p': 0.18451176269247133, 'lr': 0.06118365512916052}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:06:19,853] Trial 367 finished with value: 0.001965166614540708 and parameters: {'dropout_p': 0.4376476510543622, 'lr': 0.05621119027350637}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:06:37,628] Trial 368 finished with value: 0.0011721392360748237 and parameters: {'dropout_p': 0.13506992378071467, 'lr': 0.07131567306791332}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:06:55,653] Trial 369 finished with value: 0.0013143897365458133 and parameters: {'dropout_p': 0.11403736494524115, 'lr': 0.04895249881571421}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:07:13,322] Trial 370 finished with value: 0.0026382732789753185 and parameters: {'dropout_p': 0.12367288305473204, 'lr': 0.0012537867287232773}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:07:31,096] Trial 371 finished with value: 0.003381110379081546 and parameters: {'dropout_p': 0.10567913843262039, 'lr': 0.004292876871241954}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:07:48,775] Trial 372 finished with value: 0.0012004524780783272 and parameters: {'dropout_p': 0.10089967791593002, 'lr': 0.07873650224131064}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:08:06,522] Trial 373 finished with value: 0.000956760782195338 and parameters: {'dropout_p': 0.11493534463802349, 'lr': 0.0028397146584250147}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:08:24,253] Trial 374 finished with value: 0.001338504068451012 and parameters: {'dropout_p': 0.11374014142197023, 'lr': 0.002733897829095337}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:08:41,876] Trial 375 finished with value: 0.001584417171710038 and parameters: {'dropout_p': 0.12998138785357533, 'lr': 0.0031564001130930863}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:08:59,962] Trial 376 finished with value: 0.0026698573526803223 and parameters: {'dropout_p': 0.1056271627000096, 'lr': 0.002174529742306749}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:09:17,607] Trial 377 finished with value: 0.001614472788914689 and parameters: {'dropout_p': 0.1002409904443028, 'lr': 0.00351299983791714}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:09:35,345] Trial 378 finished with value: 0.0011390957339372475 and parameters: {'dropout_p': 0.12275549777154926, 'lr': 0.0024515240362789053}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:09:53,085] Trial 379 finished with value: 0.0019921826143527452 and parameters: {'dropout_p': 0.11552220824025256, 'lr': 0.0016535203470602184}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:10:10,738] Trial 380 finished with value: 0.0012763504344847534 and parameters: {'dropout_p': 0.14293422623289323, 'lr': 0.004648722124348456}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:10:28,468] Trial 381 finished with value: 0.0010999392097290448 and parameters: {'dropout_p': 0.11106865718226488, 'lr': 0.003640728775102961}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:10:46,106] Trial 382 finished with value: 0.0018137923323681875 and parameters: {'dropout_p': 0.10000134202603614, 'lr': 0.005344753790286831}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:11:04,122] Trial 383 finished with value: 0.0014667451843628748 and parameters: {'dropout_p': 0.12335873643669142, 'lr': 0.0029137088886190612}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:11:21,866] Trial 384 finished with value: 0.004880874814168211 and parameters: {'dropout_p': 0.13463081719320213, 'lr': 0.00024340935009039367}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:11:39,501] Trial 385 finished with value: 0.0014119458635850543 and parameters: {'dropout_p': 0.11211242406826341, 'lr': 0.007093357953543893}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:11:57,254] Trial 386 finished with value: 0.001212176572141479 and parameters: {'dropout_p': 0.12052016263075771, 'lr': 0.004109151203125942}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:12:14,867] Trial 387 finished with value: 0.0018929493791124605 and parameters: {'dropout_p': 0.23278887883395605, 'lr': 0.05108764226814655}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:12:32,622] Trial 388 finished with value: 0.0032620566146969996 and parameters: {'dropout_p': 0.31204294306235947, 'lr': 0.06305629657576688}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:12:50,605] Trial 389 finished with value: 0.0015720139839900523 and parameters: {'dropout_p': 0.10785449002514096, 'lr': 0.00846147179504235}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:13:08,300] Trial 390 finished with value: 0.002323083957949511 and parameters: {'dropout_p': 0.33753723695258453, 'lr': 0.09897872322600844}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:13:26,057] Trial 391 finished with value: 0.001512379371920705 and parameters: {'dropout_p': 0.13222286574453831, 'lr': 0.04428254728060869}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:13:43,706] Trial 392 finished with value: 0.002644339592146207 and parameters: {'dropout_p': 0.11427567217289833, 'lr': 0.031533985148660224}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:14:01,443] Trial 393 finished with value: 0.0013045773537962591 and parameters: {'dropout_p': 0.22004340801962502, 'lr': 0.08078036892311792}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:14:19,102] Trial 394 finished with value: 0.001735476281314293 and parameters: {'dropout_p': 0.12452482190310556, 'lr': 0.03947264105264192}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:14:36,826] Trial 395 finished with value: 0.0016531728746028965 and parameters: {'dropout_p': 0.1410811821280802, 'lr': 0.026952057118123086}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:14:54,886] Trial 396 finished with value: 0.0020683258168703446 and parameters: {'dropout_p': 0.10780700004285881, 'lr': 0.013457055752522804}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:15:12,525] Trial 397 finished with value: 0.0015454823806424589 and parameters: {'dropout_p': 0.11754473023402467, 'lr': 0.05682082478619254}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:15:30,296] Trial 398 finished with value: 0.0011687762550199744 and parameters: {'dropout_p': 0.12859054845287735, 'lr': 0.0059174587941508835}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:15:47,981] Trial 399 finished with value: 0.0011493133143182022 and parameters: {'dropout_p': 0.10678890512679652, 'lr': 0.032459627928719675}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:16:05,719] Trial 400 finished with value: 0.0017575299450180183 and parameters: {'dropout_p': 0.11641088453126441, 'lr': 0.017045311577175277}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:16:23,447] Trial 401 finished with value: 0.0015505192987479717 and parameters: {'dropout_p': 0.10772979892535098, 'lr': 0.02404869235213994}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:16:41,099] Trial 402 finished with value: 0.0013448570675734348 and parameters: {'dropout_p': 0.1238030230064299, 'lr': 0.06944550704770353}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:16:59,110] Trial 403 finished with value: 0.006228569637058397 and parameters: {'dropout_p': 0.17493354258042224, 'lr': 4.1834155530062644e-05}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:17:16,754] Trial 404 finished with value: 0.0008932677355893803 and parameters: {'dropout_p': 0.2865861256269738, 'lr': 0.045104586618760004}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:17:34,529] Trial 405 finished with value: 0.0009798728410165326 and parameters: {'dropout_p': 0.13984644905591995, 'lr': 0.04617706774768121}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:17:52,285] Trial 406 finished with value: 0.002445876359118092 and parameters: {'dropout_p': 0.15905740440479926, 'lr': 0.054512052539210175}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:18:09,971] Trial 407 finished with value: 0.0015157871657989338 and parameters: {'dropout_p': 0.1501342160850995, 'lr': 0.046561106946871704}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:18:27,725] Trial 408 finished with value: 0.008650837204122786 and parameters: {'dropout_p': 0.14096372064854984, 'lr': 1.459224901265771e-05}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:18:45,362] Trial 409 finished with value: 0.001145165776862006 and parameters: {'dropout_p': 0.13469776231454084, 'lr': 0.06174935350824971}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:19:03,410] Trial 410 finished with value: 0.0011946390565662458 and parameters: {'dropout_p': 0.19504200681632716, 'lr': 0.04610667077334252}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:19:21,174] Trial 411 finished with value: 0.0035744423779904377 and parameters: {'dropout_p': 0.46960902088813683, 'lr': 0.053094389776591075}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:19:38,835] Trial 412 finished with value: 0.002196984495693118 and parameters: {'dropout_p': 0.29023889105775, 'lr': 0.03917808183638699}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:19:56,587] Trial 413 finished with value: 0.0012594652992291566 and parameters: {'dropout_p': 0.14452326670700094, 'lr': 0.07066082997458385}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:20:14,252] Trial 414 finished with value: 0.0017095632271647108 and parameters: {'dropout_p': 0.3251692474205695, 'lr': 0.04255918948389637}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:20:31,909] Trial 415 finished with value: 0.0020284790193124684 and parameters: {'dropout_p': 0.12945296273194778, 'lr': 0.004449704420583567}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:20:49,936] Trial 416 finished with value: 0.002128716784928911 and parameters: {'dropout_p': 0.39200032537440677, 'lr': 0.05849745186787153}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:21:07,628] Trial 417 finished with value: 0.005490441170078497 and parameters: {'dropout_p': 0.40210383023094337, 'lr': 0.0037084197711454558}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:21:25,396] Trial 418 finished with value: 0.0014748462895357404 and parameters: {'dropout_p': 0.11894432351613157, 'lr': 0.08271114333216893}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:21:43,154] Trial 419 finished with value: 0.0036422571205304835 and parameters: {'dropout_p': 0.360732325676826, 'lr': 0.03722393475196737}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:22:00,918] Trial 420 finished with value: 0.0028922422542670334 and parameters: {'dropout_p': 0.13805235116872308, 'lr': 0.0009354629908832873}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:22:18,615] Trial 421 finished with value: 0.0025230243707213915 and parameters: {'dropout_p': 0.11269530167724563, 'lr': 0.002565274768168137}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:22:36,488] Trial 422 finished with value: 0.0012353316351575707 and parameters: {'dropout_p': 0.25229773669882316, 'lr': 0.04903740625537789}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:22:54,518] Trial 423 finished with value: 0.0019606541832441924 and parameters: {'dropout_p': 0.2680762165789222, 'lr': 0.0031668119055510897}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:23:12,347] Trial 424 finished with value: 0.0015194502680959488 and parameters: {'dropout_p': 0.1549801593084044, 'lr': 0.0344879405548403}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:23:30,298] Trial 425 finished with value: 0.0020334041220003746 and parameters: {'dropout_p': 0.12064841975067944, 'lr': 0.005171864723730387}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:23:48,054] Trial 426 finished with value: 0.000886813508367352 and parameters: {'dropout_p': 0.1278399049041616, 'lr': 0.06782384997801033}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:24:05,915] Trial 427 finished with value: 0.0025269114588025118 and parameters: {'dropout_p': 0.12663047953578194, 'lr': 0.08537736025961674}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:24:23,862] Trial 428 finished with value: 0.002293503879624079 and parameters: {'dropout_p': 0.20480665825834607, 'lr': 0.07539802188568276}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:24:41,570] Trial 429 finished with value: 0.00270677155777094 and parameters: {'dropout_p': 0.11377233670108192, 'lr': 0.06821494636477377}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:24:59,588] Trial 430 finished with value: 0.0009532091639493683 and parameters: {'dropout_p': 0.1000074749681406, 'lr': 0.06948276963534197}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:25:17,247] Trial 431 finished with value: 0.002510353404071971 and parameters: {'dropout_p': 0.10015686169535418, 'lr': 0.06177845459279321}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:25:35,088] Trial 432 finished with value: 0.0021406033539900747 and parameters: {'dropout_p': 0.10657556194785725, 'lr': 0.09162760019308304}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:25:53,338] Trial 433 finished with value: 0.0013018754247744889 and parameters: {'dropout_p': 0.34823365615977336, 'lr': 0.07076016795395074}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:26:11,557] Trial 434 finished with value: 0.001102605279964652 and parameters: {'dropout_p': 0.10033857912480826, 'lr': 0.05374959066760561}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:26:30,298] Trial 435 finished with value: 0.0010532030759368824 and parameters: {'dropout_p': 0.10717877508644601, 'lr': 0.09732120527908891}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:26:48,706] Trial 436 finished with value: 0.001475877568165623 and parameters: {'dropout_p': 0.11927664903929451, 'lr': 0.07892794634807737}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:27:06,688] Trial 437 finished with value: 0.0027726282091771804 and parameters: {'dropout_p': 0.11041861175099585, 'lr': 0.06309587527466076}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:27:24,543] Trial 438 finished with value: 0.0009943615508308439 and parameters: {'dropout_p': 0.12886692900602933, 'lr': 0.06301465289945772}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:27:42,285] Trial 439 finished with value: 0.0015756043341153597 and parameters: {'dropout_p': 0.10860472382884119, 'lr': 0.0499332888992904}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:28:00,454] Trial 440 finished with value: 0.002320883461799712 and parameters: {'dropout_p': 0.12110058564497195, 'lr': 0.07952765871014333}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:28:18,086] Trial 441 finished with value: 0.0013923160917179121 and parameters: {'dropout_p': 0.11469099018470823, 'lr': 0.006392122097221815}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:28:35,853] Trial 442 finished with value: 0.001381754066647453 and parameters: {'dropout_p': 0.30234111504221195, 'lr': 0.05789449191646654}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:28:53,842] Trial 443 finished with value: 0.0013742285680935628 and parameters: {'dropout_p': 0.10011522450732728, 'lr': 0.04267410967844788}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:29:11,473] Trial 444 finished with value: 0.0035832555612593173 and parameters: {'dropout_p': 0.13265595732457877, 'lr': 9.902002093590002e-05}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:29:29,235] Trial 445 finished with value: 0.0011951599133352311 and parameters: {'dropout_p': 0.10716393902501775, 'lr': 0.004244557598596465}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:29:46,893] Trial 446 finished with value: 0.002192502822794097 and parameters: {'dropout_p': 0.12287868071606582, 'lr': 0.07004695401644531}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:30:04,620] Trial 447 finished with value: 0.001631231301675301 and parameters: {'dropout_p': 0.260120086208239, 'lr': 0.05446832856898379}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:30:22,341] Trial 448 finished with value: 0.0013689184316229646 and parameters: {'dropout_p': 0.11690717366873606, 'lr': 0.003372461567532706}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:30:40,103] Trial 449 finished with value: 0.0015575733485379195 and parameters: {'dropout_p': 0.10034124332940422, 'lr': 0.042552826868761974}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:30:58,324] Trial 450 finished with value: 0.001548614885552555 and parameters: {'dropout_p': 0.11283694349261414, 'lr': 0.02995449045142346}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:31:15,953] Trial 451 finished with value: 0.0016967035927710258 and parameters: {'dropout_p': 0.1289822298472848, 'lr': 0.03753196473467765}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:31:33,928] Trial 452 finished with value: 0.003314047506573195 and parameters: {'dropout_p': 0.3763944748601445, 'lr': 0.007576652325762056}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:31:51,978] Trial 453 finished with value: 0.0015751002506877393 and parameters: {'dropout_p': 0.2432482934647103, 'lr': 0.0049540458619968895}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:32:09,933] Trial 454 finished with value: 0.0017709218157401106 and parameters: {'dropout_p': 0.21359886682835688, 'lr': 0.06863887609127041}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:32:27,952] Trial 455 finished with value: 0.0011424537079150854 and parameters: {'dropout_p': 0.1676642031100676, 'lr': 0.05676506592557692}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:32:45,924] Trial 456 finished with value: 0.0010110602088473852 and parameters: {'dropout_p': 0.10685910685395716, 'lr': 0.08651696799487968}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:33:04,212] Trial 457 finished with value: 0.0037426691779072633 and parameters: {'dropout_p': 0.1177135198379932, 'lr': 0.04965098330305561}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:33:22,342] Trial 458 finished with value: 0.0015216929010148602 and parameters: {'dropout_p': 0.12448084919908896, 'lr': 0.03344551291969358}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:33:40,345] Trial 459 finished with value: 0.0013957021430398438 and parameters: {'dropout_p': 0.10708308842424734, 'lr': 0.0022050944653910923}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:33:58,606] Trial 460 finished with value: 0.0026037702280521705 and parameters: {'dropout_p': 0.1001660968839046, 'lr': 0.002908309668916177}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:34:16,545] Trial 461 finished with value: 0.0014536320713204305 and parameters: {'dropout_p': 0.13528745556039146, 'lr': 0.039928555253716705}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:34:34,579] Trial 462 finished with value: 0.0036718894065022297 and parameters: {'dropout_p': 0.11407161755045485, 'lr': 0.0007770334582732817}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:34:52,778] Trial 463 finished with value: 0.0019003455220988977 and parameters: {'dropout_p': 0.12310240055635284, 'lr': 0.029027361154192504}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:35:10,733] Trial 464 finished with value: 0.0014567182998705501 and parameters: {'dropout_p': 0.112465007129348, 'lr': 0.04750363954483716}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:35:28,800] Trial 465 finished with value: 0.0028751374417551605 and parameters: {'dropout_p': 0.14439268289001891, 'lr': 0.010275159738070137}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:35:46,755] Trial 466 finished with value: 0.001386677467397141 and parameters: {'dropout_p': 0.13188367890954758, 'lr': 0.005507410285843364}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:36:04,885] Trial 467 finished with value: 0.0024000323649710628 and parameters: {'dropout_p': 0.4486802069937085, 'lr': 0.058417052907037935}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:36:23,108] Trial 468 finished with value: 0.0017590447978221649 and parameters: {'dropout_p': 0.12014364441453233, 'lr': 0.0017778442002754208}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:36:41,143] Trial 469 finished with value: 0.0010753901799226858 and parameters: {'dropout_p': 0.1074101914109641, 'lr': 0.03356951375569197}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:36:59,474] Trial 470 finished with value: 0.0011720401766281395 and parameters: {'dropout_p': 0.10003076425419258, 'lr': 0.09825535827372862}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:37:17,493] Trial 471 finished with value: 0.0008009920088843684 and parameters: {'dropout_p': 0.11388150997867252, 'lr': 0.07232537805892782}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:37:35,572] Trial 472 finished with value: 0.0013290544983287449 and parameters: {'dropout_p': 0.11055141641616006, 'lr': 0.07717768853745156}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:37:53,794] Trial 473 finished with value: 0.001887313100446928 and parameters: {'dropout_p': 0.12659736556373924, 'lr': 0.08155073773285648}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:38:11,764] Trial 474 finished with value: 0.0019360285780062603 and parameters: {'dropout_p': 0.10734795145401181, 'lr': 0.0671920329780911}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:38:29,796] Trial 475 finished with value: 0.0022730317400492324 and parameters: {'dropout_p': 0.27945980482116195, 'lr': 0.04671145705849586}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:38:47,751] Trial 476 finished with value: 0.0009779928571199564 and parameters: {'dropout_p': 0.11702908021660381, 'lr': 0.0662087489933531}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:39:05,783] Trial 477 finished with value: 0.003557199187504858 and parameters: {'dropout_p': 0.13288785911314363, 'lr': 0.05704069017077793}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:39:23,832] Trial 478 finished with value: 0.0010562987028260252 and parameters: {'dropout_p': 0.15040181597762173, 'lr': 0.07986728743110132}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:39:41,755] Trial 479 finished with value: 0.0013903808065163074 and parameters: {'dropout_p': 0.12246963485197633, 'lr': 0.053543470001099436}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:40:00,077] Trial 480 finished with value: 0.000963932167034816 and parameters: {'dropout_p': 0.10777211264163516, 'lr': 0.03976472289940712}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:40:18,127] Trial 481 finished with value: 0.0017951329074835424 and parameters: {'dropout_p': 0.11410096286708458, 'lr': 0.07146792899246157}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:40:36,194] Trial 482 finished with value: 0.001523742711876691 and parameters: {'dropout_p': 0.13923423654555364, 'lr': 0.020178721955639696}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:40:54,195] Trial 483 finished with value: 0.0015601356819166783 and parameters: {'dropout_p': 0.1260602338841063, 'lr': 0.02725705281380799}. Best is trial 103 with value: 0.00074258090234948.\n",
      "[I 2024-11-13 04:41:12,169] Trial 484 finished with value: 0.0005869729237254167 and parameters: {'dropout_p': 0.10830718268190546, 'lr': 0.09638266753852863}. Best is trial 484 with value: 0.0005869729237254167.\n",
      "[I 2024-11-13 04:41:30,219] Trial 485 finished with value: 0.001649400204515934 and parameters: {'dropout_p': 0.11610635524360582, 'lr': 0.0934973842422373}. Best is trial 484 with value: 0.0005869729237254167.\n",
      "[I 2024-11-13 04:41:48,537] Trial 486 finished with value: 0.0010120965588350831 and parameters: {'dropout_p': 0.10722234499887327, 'lr': 0.08407260848354846}. Best is trial 484 with value: 0.0005869729237254167.\n",
      "[I 2024-11-13 04:42:06,586] Trial 487 finished with value: 0.0012515412992456188 and parameters: {'dropout_p': 0.10062497358121766, 'lr': 0.09447520197779533}. Best is trial 484 with value: 0.0005869729237254167.\n",
      "[I 2024-11-13 04:42:24,635] Trial 488 finished with value: 0.0012691329156631188 and parameters: {'dropout_p': 0.12183286547991175, 'lr': 0.09606280454023305}. Best is trial 484 with value: 0.0005869729237254167.\n",
      "[I 2024-11-13 04:42:42,589] Trial 489 finished with value: 0.0017524531206579356 and parameters: {'dropout_p': 0.1313944771347761, 'lr': 0.07167518646242786}. Best is trial 484 with value: 0.0005869729237254167.\n",
      "[I 2024-11-13 04:43:00,622] Trial 490 finished with value: 0.0022517076334456375 and parameters: {'dropout_p': 0.11442213936477623, 'lr': 0.06503422740917161}. Best is trial 484 with value: 0.0005869729237254167.\n",
      "[I 2024-11-13 04:43:18,545] Trial 491 finished with value: 0.0019853805610798 and parameters: {'dropout_p': 0.10726771384987042, 'lr': 0.07604204265234717}. Best is trial 484 with value: 0.0005869729237254167.\n",
      "[I 2024-11-13 04:43:36,563] Trial 492 finished with value: 0.0022463240282930156 and parameters: {'dropout_p': 0.10023950043459551, 'lr': 0.05921662143482216}. Best is trial 484 with value: 0.0005869729237254167.\n",
      "[I 2024-11-13 04:43:54,752] Trial 493 finished with value: 0.0011633983862811966 and parameters: {'dropout_p': 0.13900429979839996, 'lr': 0.04989187486872408}. Best is trial 484 with value: 0.0005869729237254167.\n",
      "[I 2024-11-13 04:44:12,709] Trial 494 finished with value: 0.0012367596674126328 and parameters: {'dropout_p': 0.12590090301658585, 'lr': 0.09935439761746338}. Best is trial 484 with value: 0.0005869729237254167.\n",
      "[I 2024-11-13 04:44:30,757] Trial 495 finished with value: 0.0015699125796284775 and parameters: {'dropout_p': 0.11440115291022723, 'lr': 0.04396235705884664}. Best is trial 484 with value: 0.0005869729237254167.\n",
      "[I 2024-11-13 04:44:48,711] Trial 496 finished with value: 0.0012724556741230853 and parameters: {'dropout_p': 0.11985316597077589, 'lr': 0.06440643972081095}. Best is trial 484 with value: 0.0005869729237254167.\n",
      "[I 2024-11-13 04:45:06,747] Trial 497 finished with value: 0.0018949892177858069 and parameters: {'dropout_p': 0.32137780300641794, 'lr': 0.08124128288421548}. Best is trial 484 with value: 0.0005869729237254167.\n",
      "[I 2024-11-13 04:45:24,749] Trial 498 finished with value: 0.0019158754558638888 and parameters: {'dropout_p': 0.1615344710942722, 'lr': 0.0514647479599987}. Best is trial 484 with value: 0.0005869729237254167.\n",
      "[I 2024-11-13 04:45:42,674] Trial 499 finished with value: 0.0010984065797773213 and parameters: {'dropout_p': 0.10018564039112758, 'lr': 0.03653236437720602}. Best is trial 484 with value: 0.0005869729237254167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'dropout_p': 0.10830718268190546, 'lr': 0.09638266753852863}\n",
      "Best MAE: 0.0005869729237254167\n"
     ]
    }
   ],
   "source": [
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=500)\n",
    "\n",
    "# Print best parameters and best value\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best MAE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters: {'dropout_p': 0.10830718268190546, 'lr': 0.09638266753852863}\n",
    "Best MAE: 0.0005869729237254167"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters: {'dropout_p': 0.20862014926048447, 'lr': 0.0002448376394581503}\n",
    "Best MAE: 0.00049047276004533371"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = 100000\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = generate_and_prepare_training_data(num_train_samples, batch_size)\n",
    "n_features = train_loader.dataset.tensors[0].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_p = 0.10830718268190546\n",
    "lr = 0.09638266753852863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "optimizers = []\n",
    "schedulers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append( BlackScholesNet(input_size=n_features, output_size=1, hidden_size=128, dropout_p=dropout_p))\n",
    "models.append( FeedforwardNN(input_size=n_features, output_size=1, hidden_size=128))\n",
    "models.append( ResNet(input_size=n_features, output_size=1, hidden_size=128, num_blocks=4))\n",
    "models.append( SIREN(input_size=n_features, out_size=1, hidden_size=128, hidden_layers=4))\n",
    "# models.append( CNN(input_channels=n_features, output_size=1))\n",
    "models.append( TransformerModel(input_size=n_features, output_size=1, hidden_size=128, num_heads=4, num_layers=4))\n",
    "models.append( Autoencoder(input_size=n_features, hidden_size=128, latent_dim=4))\n",
    "models.append( PINN(input_size=n_features, output_size=1, hidden_size=128))\n",
    "# models.append( MDN(input_size=n_features, output_size=1, hidden_size=128, num_components=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "\toptimizer = optim.NAdam(model.parameters(), lr=lr)\n",
    "\tscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\toptimizers.append(optimizer)\n",
    "\tschedulers.append(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('models\\\\Black Model_mae.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "\tmodel.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters: {'hidden_size': 256, 'dropout_p': 0.16165214075232218, 'lr': 0.0024867405570057574, 'batch_size': 64, 'optimizer': 'NAdam'}\n",
    "Best MAE: 0.003318011008932989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters: {'hidden_size': 128, 'dropout_p': 0.3974039374569882, 'lr': 0.012408717790861197, 'batch_size': 128, 'optimizer': 'NAdam'}\n",
    "Best MAE: 0.008668262018621945"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_stages = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "\tif isinstance(m, nn.Linear):\n",
    "\t\tnn.init.xavier_uniform_(m.weight)\n",
    "\t\tif m.bias is not None:\n",
    "\t\t\tnn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "\tmodel.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(y_pred, y_true, delta=1.0):\n",
    "\terror = y_true - y_pred\n",
    "\tis_small_error = torch.abs(error) <= delta\n",
    "\tsmall_error_loss = 0.5 * error**2\n",
    "\tlarge_error_loss = delta * (torch.abs(error) - 0.5 * delta)\n",
    "\n",
    "\treturn torch.where(is_small_error, small_error_loss, large_error_loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 01:57:17 ] ***** Stage [1/1] ******************************************************************************************************************************************************\n",
      "[ 01:57:19 ] ----- Epoch [1/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 0.0006164860572768361     | MSE: 0.0028085483186428215     | MAE: 0.03959589209837654       | MRE: 1238187.8357990088        |\n",
      "[ 01:57:22 ] ----- Epoch [2/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 0.00014561837257630244    | MSE: 0.0003577709197416124     | MAE: 0.014340423312230238      | MRE: 476061.4230647505         |\n",
      "[ 01:57:24 ] ----- Epoch [3/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 9.931912993352884e-05     | MSE: 0.0002280881301404223     | MAE: 0.011340588484009938      | MRE: 307928.5241811395         |\n",
      "[ 01:57:26 ] ----- Epoch [4/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 7.527241251140965e-05     | MSE: 0.00016859613274817204    | MAE: 0.009498374320236369      | MRE: 215871.64319041974        |\n",
      "[ 01:57:29 ] ----- Epoch [5/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 7.293038897411679e-05     | MSE: 0.00016390776917060733    | MAE: 0.0092895197697063        | MRE: 212761.83444691097        |\n",
      "[ 01:57:31 ] ----- Epoch [6/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 6.421147225636607e-05     | MSE: 0.0001425552505114961     | MAE: 0.008620174712577904      | MRE: 198692.2359145008         |\n",
      "[ 01:57:33 ] ----- Epoch [7/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 6.271845598238314e-05     | MSE: 0.00013968178897122744    | MAE: 0.00849251845778768       | MRE: 186424.18652742382        |\n",
      "[ 01:57:35 ] ----- Epoch [8/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 6.684955610723266e-05     | MSE: 0.00014778069309140062    | MAE: 0.008831477638134588      | MRE: 208710.75913369577        |\n",
      "[ 01:57:38 ] ----- Epoch [9/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 5.9756427609266526e-05    | MSE: 0.00013103864279836617    | MAE: 0.008262510568392832      | MRE: 183254.83288107958        |\n",
      "[ 01:57:40 ] ----- Epoch [10/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 6.845019034873959e-05     | MSE: 0.0001515409156246567     | MAE: 0.008928024386534165      | MRE: 212983.86932433405        |\n",
      "[ 01:57:42 ] ----- Epoch [11/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 6.190107053213148e-05     | MSE: 0.00013686615033125965    | MAE: 0.008398725907489468      | MRE: 187424.21484591364        |\n",
      "[ 01:57:44 ] ----- Epoch [12/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 6.102918577233675e-05     | MSE: 0.0001333627685738695     | MAE: 0.008374670101351537      | MRE: 170943.7119222523         |\n",
      "[ 01:57:47 ] ----- Epoch [13/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 6.501974499478637e-05     | MSE: 0.00014397742004399462    | MAE: 0.008600190480755901      | MRE: 176952.4417823399         |\n",
      "[ 01:57:49 ] ----- Epoch [14/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.990016200442591e-05     | MSE: 8.619870446147328e-05     | MAE: 0.006121563763118371      | MRE: 73819.4660553496          |\n",
      "[ 01:57:51 ] ----- Epoch [15/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 4.0442387555924266e-05    | MSE: 8.693314325510379e-05     | MAE: 0.006223773051038304      | MRE: 87132.99145149499         |\n",
      "[ 01:57:54 ] ----- Epoch [16/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.847762432699485e-05     | MSE: 8.206450712874945e-05     | MAE: 0.006057305651045835      | MRE: 75708.46804587673         |\n",
      "[ 01:57:56 ] ----- Epoch [17/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 4.131296220300282e-05     | MSE: 8.853241278819325e-05     | MAE: 0.006331473838027945      | MRE: 87837.60838994125         |\n",
      "[ 01:57:59 ] ----- Epoch [18/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.744090807182492e-05     | MSE: 7.978183651492657e-05     | MAE: 0.005991948093422706      | MRE: 85182.86007546983         |\n",
      "[ 01:58:01 ] ----- Epoch [19/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.935991794274709e-05     | MSE: 8.440046144920574e-05     | MAE: 0.006135478440388192      | MRE: 93844.55911257265         |\n",
      "[ 01:58:03 ] ----- Epoch [20/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.8646905251940366e-05    | MSE: 8.186677085807639e-05     | MAE: 0.006133057469580875      | MRE: 86349.89556046754         |\n",
      "[ 01:58:05 ] ----- Epoch [21/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.7592388414595126e-05    | MSE: 7.986506936200297e-05     | MAE: 0.006011458146807154      | MRE: 87584.01604086562         |\n",
      "[ 01:58:08 ] ----- Epoch [22/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.807148817273079e-05     | MSE: 8.070351189729197e-05     | MAE: 0.006056243812108048      | MRE: 81392.63555648044         |\n",
      "[ 01:58:10 ] ----- Epoch [23/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.701495542931083e-05     | MSE: 7.831528916456637e-05     | MAE: 0.005866562778918125      | MRE: 69304.22284851021         |\n",
      "[ 01:58:12 ] ----- Epoch [24/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.595622900437481e-05     | MSE: 7.596287841270873e-05     | MAE: 0.00575452629492181       | MRE: 68411.18906837319         |\n",
      "[ 01:58:14 ] ----- Epoch [25/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.689943888596672e-05     | MSE: 7.760512804433964e-05     | MAE: 0.00588413867837531       | MRE: 69392.97147645308         |\n",
      "[ 01:58:17 ] ----- Epoch [26/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.399867439276716e-05     | MSE: 7.21192188392696e-05      | MAE: 0.005605908720854215      | MRE: 69595.30095775437         |\n",
      "[ 01:58:19 ] ----- Epoch [27/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.597304475700535e-05     | MSE: 7.625728650515155e-05     | MAE: 0.005766525870560608      | MRE: 72518.29845426686         |\n",
      "[ 01:58:21 ] ----- Epoch [28/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.398624635531836e-05     | MSE: 7.128150817373285e-05     | MAE: 0.005605390039591427      | MRE: 75051.76098943004         |\n",
      "[ 01:58:23 ] ----- Epoch [29/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.528351597356258e-05     | MSE: 7.457272787448329e-05     | MAE: 0.005746780838706983      | MRE: 69515.3893002882          |\n",
      "[ 01:58:25 ] ----- Epoch [30/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.441110804047445e-05     | MSE: 7.272158702569112e-05     | MAE: 0.005658798577647131      | MRE: 77334.98994410937         |\n",
      "[ 01:58:28 ] ----- Epoch [31/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.746406444591714e-05     | MSE: 7.95325922116037e-05      | MAE: 0.005930702554305454      | MRE: 74361.09762601476         |\n",
      "[ 01:58:30 ] ----- Epoch [32/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.597435147860603e-05     | MSE: 7.719297214400653e-05     | MAE: 0.005758715693467441      | MRE: 73174.23741976544         |\n",
      "[ 01:58:32 ] ----- Epoch [33/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.462251041382609e-05     | MSE: 7.286393528061952e-05     | MAE: 0.0056653497485023635     | MRE: 71939.67317052222         |\n",
      "[ 01:58:34 ] ----- Epoch [34/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.5556590078221586e-05    | MSE: 7.434387112093471e-05     | MAE: 0.005794465497713659      | MRE: 70562.73878990655         |\n",
      "[ 01:58:36 ] ----- Epoch [35/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.351970229784548e-05     | MSE: 7.057319082415905e-05     | MAE: 0.005579284280762963      | MRE: 71902.78034981193         |\n",
      "[ 01:58:38 ] ----- Epoch [36/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.348065448606409e-05     | MSE: 6.997934426841009e-05     | MAE: 0.005592432475595925      | MRE: 68915.93931753731         |\n",
      "[ 01:58:40 ] ----- Epoch [37/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.2636281194619304e-05    | MSE: 6.77524927360149e-05      | MAE: 0.005546147854101323      | MRE: 71667.4951345017          |\n",
      "[ 01:58:42 ] ----- Epoch [38/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.456213323449296e-05     | MSE: 7.27362915758024e-05      | MAE: 0.0056650920165337475     | MRE: 75962.3697295481          |\n",
      "[ 01:58:44 ] ----- Epoch [39/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.6560152608657145e-05    | MSE: 7.705048605191031e-05     | MAE: 0.005840554330468285      | MRE: 71394.24268333908         |\n",
      "[ 01:58:47 ] ----- Epoch [40/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.6800186668675675e-05    | MSE: 7.78066492600036e-05      | MAE: 0.005835025590849013      | MRE: 70239.44145495332         |\n",
      "[ 01:58:49 ] ----- Epoch [41/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.4209945702497585e-05    | MSE: 7.192542543156106e-05     | MAE: 0.005662471107721757      | MRE: 72693.43891374885         |\n",
      "[ 01:58:51 ] ----- Epoch [42/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.620236850325005e-05     | MSE: 7.639209340324016e-05     | MAE: 0.0058154156705874215     | MRE: 70975.00866466507         |\n",
      "[ 01:58:53 ] ----- Epoch [43/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.4541034740174266e-05    | MSE: 7.246895807944447e-05     | MAE: 0.005654301329640536      | MRE: 67282.30645367387         |\n",
      "[ 01:58:55 ] ----- Epoch [44/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.59186951635957e-05      | MSE: 7.581513926896461e-05     | MAE: 0.005781743634317881      | MRE: 76649.75902879308         |\n",
      "[ 01:58:57 ] ----- Epoch [45/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.570992499478615e-05     | MSE: 7.469805537066316e-05     | MAE: 0.0057979841875831035     | MRE: 69148.37415235072         |\n",
      "[ 01:59:00 ] ----- Epoch [46/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.599143456236738e-05     | MSE: 7.551319788941695e-05     | MAE: 0.005804143118309729      | MRE: 71302.83492487225         |\n",
      "[ 01:59:02 ] ----- Epoch [47/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.573653438017578e-05     | MSE: 7.481644563987534e-05     | MAE: 0.005776986866164869      | MRE: 72675.49240213983         |\n",
      "[ 01:59:04 ] ----- Epoch [48/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.7901256409621415e-05    | MSE: 8.083821909279993e-05     | MAE: 0.005881695943825095      | MRE: 75798.05618145138         |\n",
      "[ 01:59:06 ] ----- Epoch [49/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.54342850493682e-05      | MSE: 7.454335529606138e-05     | MAE: 0.005720995791565856      | MRE: 66768.00010788371         |\n",
      "[ 01:59:08 ] ----- Epoch [50/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.3565291462021254e-05    | MSE: 7.082058268137371e-05     | MAE: 0.005581276837967559      | MRE: 72946.28363511471         |\n",
      "[ 01:59:10 ] ----- Epoch [51/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.622567661085325e-05     | MSE: 7.598653070663516e-05     | MAE: 0.005833043004401681      | MRE: 72300.92893343237         |\n",
      "[ 01:59:12 ] ----- Epoch [52/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.450595112024338e-05     | MSE: 7.242255944648937e-05     | MAE: 0.005650986333264497      | MRE: 73195.04376903674         |\n",
      "[ 01:59:14 ] ----- Epoch [53/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.434326944422931e-05     | MSE: 7.249506700218064e-05     | MAE: 0.005612265468042933      | MRE: 72777.81653333566         |\n",
      "[ 01:59:17 ] ----- Epoch [54/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.4831138249489716e-05    | MSE: 7.408821290729287e-05     | MAE: 0.0056284449745838796     | MRE: 71994.85588760026         |\n",
      "[ 01:59:19 ] ----- Epoch [55/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.58826847732194e-05      | MSE: 7.595289727243228e-05     | MAE: 0.005786899312550673      | MRE: 71507.73329913874         |\n",
      "[ 01:59:21 ] ----- Epoch [56/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.490176599774849e-05     | MSE: 7.338455507665447e-05     | MAE: 0.005721070741038664      | MRE: 74754.8224367762          |\n",
      "[ 01:59:23 ] ----- Epoch [57/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.607879446111829e-05     | MSE: 7.612339536903358e-05     | MAE: 0.00579733823302192       | MRE: 71898.30321302473         |\n",
      "[ 01:59:25 ] ----- Epoch [58/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.40473313959041e-05      | MSE: 7.19149714618187e-05      | MAE: 0.005605735514517648      | MRE: 71385.29047765613         |\n",
      "[ 01:59:27 ] ----- Epoch [59/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.46742058631122e-05      | MSE: 7.277117148326369e-05     | MAE: 0.005662021911387242      | MRE: 71594.68866132178         |\n",
      "[ 01:59:30 ] ----- Epoch [60/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.568043432886005e-05     | MSE: 7.578001432110743e-05     | MAE: 0.005720273038521563      | MRE: 74231.98401879641         |\n",
      "[ 01:59:32 ] ----- Epoch [61/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.6151241335449576e-05    | MSE: 7.644152009826499e-05     | MAE: 0.005795683924355355      | MRE: 71399.60816965482         |\n",
      "[ 01:59:34 ] ----- Epoch [62/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.719297600611436e-05     | MSE: 7.873324672238697e-05     | MAE: 0.005868589725070173      | MRE: 73731.97241342405         |\n",
      "[ 01:59:36 ] ----- Epoch [63/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.353043847604853e-05     | MSE: 7.056170723044005e-05     | MAE: 0.005548375354807189      | MRE: 70991.58079661237         |\n",
      "[ 01:59:38 ] ----- Epoch [64/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.437056363044962e-05     | MSE: 7.23548247276842e-05      | MAE: 0.0056461470883894995     | MRE: 71520.92316657455         |\n",
      "[ 01:59:40 ] ----- Epoch [65/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.422241443389852e-05     | MSE: 7.248583836844416e-05     | MAE: 0.005594920693988356      | MRE: 75464.24846257456         |\n",
      "[ 01:59:42 ] ----- Epoch [66/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.499481980877363e-05     | MSE: 7.374141134998588e-05     | MAE: 0.0057165372105987145     | MRE: 73822.38622014398         |\n",
      "[ 01:59:44 ] ----- Epoch [67/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.375968993511424e-05     | MSE: 7.061287950729546e-05     | MAE: 0.005618914429631822      | MRE: 74093.04464807446         |\n",
      "[ 01:59:47 ] ----- Epoch [68/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.594158819340452e-05     | MSE: 7.579777790721367e-05     | MAE: 0.005781418534643633      | MRE: 72175.29759839202         |\n",
      "[ 01:59:49 ] ----- Epoch [69/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.548392402820347e-05     | MSE: 7.51566219188683e-05      | MAE: 0.005738228508016347      | MRE: 69338.48527866675         |\n",
      "[ 01:59:51 ] ----- Epoch [70/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.81236099670903e-05      | MSE: 8.117782481930576e-05     | MAE: 0.0059379625421806075     | MRE: 73351.56850855077         |\n",
      "[ 01:59:53 ] ----- Epoch [71/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.531566452038362e-05     | MSE: 7.468815656463937e-05     | MAE: 0.005720300237188673      | MRE: 74761.63117994521         |\n",
      "[ 01:59:55 ] ----- Epoch [72/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.3148608121465905e-05    | MSE: 6.920353448745584e-05     | MAE: 0.005569120097603107      | MRE: 69799.3933070013          |\n",
      "[ 01:59:58 ] ----- Epoch [73/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.44299565495177e-05      | MSE: 7.18506179278249e-05      | MAE: 0.005685562945113074      | MRE: 68587.1374336574          |\n",
      "[ 02:00:00 ] ----- Epoch [74/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.54597131928511e-05      | MSE: 7.469948684080939e-05     | MAE: 0.0057236390573197436     | MRE: 72361.86832055029         |\n",
      "[ 02:00:02 ] ----- Epoch [75/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.2877980500493e-05       | MSE: 6.873418371657553e-05     | MAE: 0.005536103615673614      | MRE: 72450.02567571927         |\n",
      "[ 02:00:04 ] ----- Epoch [76/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.4466168492845115e-05    | MSE: 7.310333368555172e-05     | MAE: 0.005622011559427153      | MRE: 76485.86948219655         |\n",
      "[ 02:00:06 ] ----- Epoch [77/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.519037962281462e-05     | MSE: 7.413621406574413e-05     | MAE: 0.005702009410814965      | MRE: 69210.45734316186         |\n",
      "[ 02:00:08 ] ----- Epoch [78/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.517406936792309e-05     | MSE: 7.438713558423536e-05     | MAE: 0.005687645429718887      | MRE: 71701.92121722233         |\n",
      "[ 02:00:11 ] ----- Epoch [79/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.593639838041094e-05     | MSE: 7.627064628525199e-05     | MAE: 0.005715423942870401      | MRE: 70676.55326519228         |\n",
      "[ 02:00:13 ] ----- Epoch [80/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.450270756490688e-05     | MSE: 7.277760900361343e-05     | MAE: 0.005636329538051247      | MRE: 71003.12038511431         |\n",
      "[ 02:00:15 ] ----- Epoch [81/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.417124504249786e-05     | MSE: 7.134501130760076e-05     | MAE: 0.0056623321850867        | MRE: 75981.92597743239         |\n",
      "[ 02:00:17 ] ----- Epoch [82/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.436583628560805e-05     | MSE: 7.244560593054795e-05     | MAE: 0.005636490805143877      | MRE: 73927.05542204466         |\n",
      "[ 02:00:19 ] ----- Epoch [83/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.538843028734913e-05     | MSE: 7.462257345869036e-05     | MAE: 0.005709489690371993      | MRE: 73809.78868358015         |\n",
      "[ 02:00:21 ] ----- Epoch [84/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.48382106786265e-05      | MSE: 7.363715208826738e-05     | MAE: 0.005658747716251582      | MRE: 71867.92596141358         |\n",
      "[ 02:00:23 ] ----- Epoch [85/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.559683439133839e-05     | MSE: 7.551671472263736e-05     | MAE: 0.0057462933497722255     | MRE: 71712.16612739039         |\n",
      "[ 02:00:26 ] ----- Epoch [86/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.5679039881087936e-05    | MSE: 7.613407320434076e-05     | MAE: 0.005728229434596961      | MRE: 71712.07357607498         |\n",
      "[ 02:00:28 ] ----- Epoch [87/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.348975764341982e-05     | MSE: 7.015045214057209e-05     | MAE: 0.005573853419423528      | MRE: 72774.09232097272         |\n",
      "[ 02:00:30 ] ----- Epoch [88/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.2908716671014116e-05    | MSE: 6.973959229372529e-05     | MAE: 0.00547241052392904       | MRE: 69310.47869466784         |\n",
      "[ 02:00:32 ] ----- Epoch [89/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.356225969105296e-05     | MSE: 7.02189341702087e-05      | MAE: 0.005581050076907749      | MRE: 70138.29829061232         |\n",
      "[ 02:00:34 ] ----- Epoch [90/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.6782947084525016e-05    | MSE: 7.699958357985093e-05     | MAE: 0.005877697176123081      | MRE: 71968.8184828323          |\n",
      "[ 02:00:36 ] ----- Epoch [91/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.412338177102118e-05     | MSE: 7.190525706349344e-05     | MAE: 0.005651235864758162      | MRE: 69751.38188037399         |\n",
      "[ 02:00:38 ] ----- Epoch [92/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.500119944598683e-05     | MSE: 7.362181116569407e-05     | MAE: 0.005701980325670062      | MRE: 70258.34142956886         |\n",
      "[ 02:00:40 ] ----- Epoch [93/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.370940764657787e-05     | MSE: 7.079136412454922e-05     | MAE: 0.005571846628827886      | MRE: 69193.10821842724         |\n",
      "[ 02:00:42 ] ----- Epoch [94/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.4564784131239625e-05    | MSE: 7.269570240942219e-05     | MAE: 0.00566033936288166       | MRE: 68008.64250602068         |\n",
      "[ 02:00:45 ] ----- Epoch [95/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.6139131226084226e-05    | MSE: 7.72570876410065e-05      | MAE: 0.005748254899159417      | MRE: 68934.507990612           |\n",
      "[ 02:00:47 ] ----- Epoch [96/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.4343594963813974e-05    | MSE: 7.251190121067583e-05     | MAE: 0.005635445196843727      | MRE: 72842.29358674547         |\n",
      "[ 02:00:49 ] ----- Epoch [97/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.4988226537216236e-05    | MSE: 7.413454717627101e-05     | MAE: 0.00569042533246595       | MRE: 75088.33292395578         |\n",
      "[ 02:00:51 ] ----- Epoch [98/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.284922257272185e-05     | MSE: 6.925541750482891e-05     | MAE: 0.005496532962241705      | MRE: 73737.99298284842         |\n",
      "[ 02:00:53 ] ----- Epoch [99/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.6363758312044435e-05    | MSE: 7.625551609185384e-05     | MAE: 0.005819207036149803      | MRE: 72582.89349581573         |\n",
      "[ 02:00:56 ] ----- Epoch [100/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | Huber loss: 3.470271450666816e-05     | MSE: 7.27874764918689e-05      | MAE: 0.0056897390587675465     | MRE: 78000.20636169016         |\n"
     ]
    }
   ],
   "source": [
    "for stage in range(num_stages):\n",
    "\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ***** Stage [{stage+1}/{num_stages}] {'*'*150}\")\n",
    "\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tepoch_huber = 0.\n",
    "\t\tepoch_mae = 0.\n",
    "\t\tepoch_mre = 0.\n",
    "\t\tepoch_mse = 0.\n",
    "\n",
    "\t\tfor X_batch, y_batch in train_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\t\t\t# X_batch = X_batch.unsqueeze(1)  # Add a dimension for sequence length\n",
    "\t\t\tmodel.train()\n",
    "\n",
    "\t\t\toutputs = model(X_batch)\n",
    "\t\t\t# outputs = (outputs[:, 0] + outputs[:, 1] ) / 2\n",
    "\n",
    "\t\t\ty = y_batch\n",
    "\n",
    "\t\t\t# Calculate losses\n",
    "\t\t\thub_loss = huber_loss(outputs, y, 0.02)\n",
    "\t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "\t\t\tmask = y >= 1e-10\n",
    "\t\t\ty_m = y[mask]\n",
    "\t\t\trelative_errors = torch.abs(outputs[mask] - y_m ) / y_m\n",
    "\t\t\tmre_loss = relative_errors.mean()\n",
    "\n",
    "\t\t\t# Backpropagation\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\thub_loss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t# Accumulate losses\n",
    "\t\t\tepoch_mse += mse_loss.item()\n",
    "\t\t\tepoch_mae += mae_loss.item()\n",
    "\t\t\tepoch_mre += mre_loss.item()\n",
    "\t\t\tepoch_huber += hub_loss\n",
    "\n",
    "\t\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "\n",
    "\t\tavg_epoch_huber = epoch_huber / len(train_loader)\n",
    "\t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "\t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "\t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\n",
    "\t\tprint(f\"{model.name:<50} | Huber loss: {avg_epoch_huber:<25} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\n",
    "\t\tscheduler.step(avg_epoch_huber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-cosh loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18:51:10 ] ***** Stage [1/1] ******************************************************************************************************************************************************\n",
      "[ 18:51:30 ] ----- Epoch [1/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 0.01731447072122037       | MAE: 0.089106594409645         | MRE: 3058633.5212305137        |\n",
      "[ 18:51:50 ] ----- Epoch [2/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 0.0010450003118724588     | MAE: 0.023971658696214888      | MRE: 771303.588995485          |\n",
      "[ 18:52:09 ] ----- Epoch [3/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 0.0001512994754532175     | MAE: 0.00895387339441951       | MRE: 210626.51115082315        |\n",
      "[ 18:52:27 ] ----- Epoch [4/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 6.892608815181244e-05     | MAE: 0.005883380302780205      | MRE: 111147.05435583208        |\n",
      "[ 18:52:45 ] ----- Epoch [5/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 4.9353556588203586e-05    | MAE: 0.004968252232131193      | MRE: 89373.80513092178         |\n",
      "[ 18:53:02 ] ----- Epoch [6/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 3.903264970802214e-05     | MAE: 0.004442454011402691      | MRE: 77508.10814262812         |\n",
      "[ 18:53:19 ] ----- Epoch [7/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 3.368304325566162e-05     | MAE: 0.0041201268446925815     | MRE: 69080.51673518943         |\n",
      "[ 18:53:36 ] ----- Epoch [8/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.956845673858399e-05     | MAE: 0.00385377370228547       | MRE: 63424.132843474166        |\n",
      "[ 18:53:53 ] ----- Epoch [9/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.7425744214238394e-05    | MAE: 0.0036998401798948245     | MRE: 58765.5387860732          |\n",
      "[ 18:54:10 ] ----- Epoch [10/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.4939494013544563e-05    | MAE: 0.003519000832304912      | MRE: 53088.027463344246        |\n",
      "[ 18:54:27 ] ----- Epoch [11/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.3431339014483393e-05    | MAE: 0.0033873751352765423     | MRE: 49596.209813927715        |\n",
      "[ 18:54:44 ] ----- Epoch [12/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.2073221655830494e-05    | MAE: 0.0032872964734381215     | MRE: 45795.7671171294          |\n",
      "[ 18:55:01 ] ----- Epoch [13/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 2.084050045904518e-05     | MAE: 0.0031834157982392804     | MRE: 44370.02082890216         |\n",
      "[ 18:55:18 ] ----- Epoch [14/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.9599185384201923e-05    | MAE: 0.003092811103534611      | MRE: 40402.83255294311         |\n",
      "[ 18:55:35 ] ----- Epoch [15/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.942398345676197e-05     | MAE: 0.003049764804336584      | MRE: 38675.91596824273         |\n",
      "[ 18:55:52 ] ----- Epoch [16/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.8326963362392304e-05    | MAE: 0.0029648561416231053     | MRE: 37599.43025517452         |\n",
      "[ 18:56:09 ] ----- Epoch [17/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.7815382839989627e-05    | MAE: 0.002926117903623292      | MRE: 36467.50197642514         |\n",
      "[ 18:56:27 ] ----- Epoch [18/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.7085708220998428e-05    | MAE: 0.0028566735476514334     | MRE: 34857.12117580216         |\n",
      "[ 18:56:47 ] ----- Epoch [19/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.664699292385959e-05     | MAE: 0.0028183495533419126     | MRE: 33416.366910919016        |\n",
      "[ 18:57:06 ] ----- Epoch [20/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.617160993766033e-05     | MAE: 0.0027698345718942087     | MRE: 32453.09566223582         |\n",
      "[ 18:57:24 ] ----- Epoch [21/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.568822873353176e-05     | MAE: 0.002725351934926964      | MRE: 30692.10454301053         |\n",
      "[ 18:57:42 ] ----- Epoch [22/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.541930846803333e-05     | MAE: 0.002688442294558928      | MRE: 29721.88937755512         |\n",
      "[ 18:58:00 ] ----- Epoch [23/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.523920125001209e-05     | MAE: 0.0026733518137175855     | MRE: 29054.824303924455        |\n",
      "[ 18:58:18 ] ----- Epoch [24/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.4769747799491174e-05    | MAE: 0.0026342328758102098     | MRE: 28172.53923078817         |\n",
      "[ 18:58:35 ] ----- Epoch [25/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.4599723825824199e-05    | MAE: 0.002613716768853416      | MRE: 27587.680738012714        |\n",
      "[ 18:58:53 ] ----- Epoch [26/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.4126480054870121e-05    | MAE: 0.002568947940246465      | MRE: 26875.012025421187        |\n",
      "[ 18:59:10 ] ----- Epoch [27/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.3942346808017669e-05    | MAE: 0.0025501496988805466     | MRE: 25503.138978476985        |\n",
      "[ 18:59:28 ] ----- Epoch [28/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.3692698933634936e-05    | MAE: 0.0025199557347813984     | MRE: 25726.191536663966        |\n",
      "[ 18:59:46 ] ----- Epoch [29/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.3380714134394212e-05    | MAE: 0.0024847053966230237     | MRE: 24492.420727477875        |\n",
      "[ 19:00:03 ] ----- Epoch [30/30] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model                                        | Huber loss: 2.805671036771152e-05     | MSE: 1.3421092845980374e-05    | MAE: 0.0024886848291776017     | MRE: 23859.429674730753        |\n"
     ]
    }
   ],
   "source": [
    "for stage in range(num_stages):\n",
    "\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ***** Stage [{stage+1}/{num_stages}] {'*'*150}\")\n",
    "\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tcnt = 0\n",
    "\t\tepoch_lcosh = 0.\n",
    "\t\tepoch_mae = 0.\n",
    "\t\tepoch_mre = 0.\n",
    "\t\tepoch_mse = 0.\n",
    "\n",
    "\t\tfor X_batch, y_batch in train_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\t\t\tmodel.train()\n",
    "\n",
    "\t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "\t\t\toutputs = (outputs[:, 0] + outputs[:, 1] ) / 2\n",
    "\t\t\ty = y_batch[:, 0]\n",
    "\n",
    "\t\t\t# Calculate losses\n",
    "\t\t\tlcosh_loss = torch.mean(torch.log(torch.cosh(outputs-y)))\n",
    "\t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "\t\t\tmask = y >= 1e-10\n",
    "\t\t\ty_m = y[mask]\n",
    "\t\t\trelative_errors = torch.abs(outputs[mask] - y_m ) / y_m\n",
    "\t\t\tmre_loss = relative_errors.sum()\n",
    "\n",
    "\t\t\tcnt += len(relative_errors)\n",
    "\n",
    "\t\t\t# Backpropagation\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tlcosh_loss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t# Accumulate losses\n",
    "\t\t\tepoch_mse += mse_loss.item()\n",
    "\t\t\tepoch_mae += mae_loss.item()\n",
    "\t\t\tepoch_mre += mre_loss.item()\n",
    "\t\t\tepoch_lcosh += hub_loss\n",
    "\n",
    "\t\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "\n",
    "\t\tavg_epoch_lcosh = epoch_lcosh / len(train_loader)\n",
    "\t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "\t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "\t\tavg_epoch_mre = epoch_mre / cnt\n",
    "\n",
    "\t\tprint(f\"{model.name:<50} | Huber loss: {avg_epoch_lcosh:<25} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\n",
    "\t\tscheduler.step(avg_epoch_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n",
      "SIREN model is training\n",
      "Transformer model is training\n",
      "Autoencoder model is training\n",
      "PINN model is training\n",
      "Black Model without activation is training\n",
      "FFN model is training\n",
      "ResNet model is training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m     30\u001b[0m optimizers[i]\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 31\u001b[0m \u001b[43mmse_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m optimizers[i]\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Accumulate losses for this model\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/python/BlackFormulaApproximation/.venv/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/python/BlackFormulaApproximation/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/python/BlackFormulaApproximation/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\t# Initialize epoch metrics for each model\n",
    "\tepoch_mae = [0.] * len(models)\n",
    "\tepoch_mre = [0.] * len(models)\n",
    "\tepoch_mse = [0.] * len(models)\n",
    "\n",
    "\tfor X_batch, y_batch in train_loader:\n",
    "\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\t\t# Loop over each model\n",
    "\t\tfor i, model in enumerate(models):\n",
    "\t\t\tmodel.train()\n",
    "\n",
    "\t\t\t# Forward pass\n",
    "\t\t\toutputs = model(X_batch)\n",
    "\t\t\toutputs = outputs[:, 0]\n",
    "\t\t\ty = y_batch[:, 0]\n",
    "\n",
    "\t\t\t# Calculate losses\n",
    "\t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "\t\t\tmask = y >= 1e-10\n",
    "\t\t\ty_m = y[mask]\n",
    "\t\t\trelative_errors = torch.abs(outputs[mask] - y_m ) / y_m\n",
    "\t\t\tmre_loss = relative_errors.mean()\n",
    "\n",
    "\t\t\t# Backpropagation\n",
    "\t\t\toptimizers[i].zero_grad()\n",
    "\t\t\tmse_loss.backward()\n",
    "\t\t\toptimizers[i].step()\n",
    "\n",
    "\t\t\t# Accumulate losses for this model\n",
    "\t\t\tepoch_mse[i] += mse_loss.item()\n",
    "\t\t\tepoch_mae[i] += mae_loss.item()\n",
    "\t\t\tepoch_mre[i] += mre_loss.item()\n",
    "\n",
    "\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "\t# Average metrics for each model\n",
    "\tfor i in range(len(models)):\n",
    "\t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "\t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "\t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\n",
    "\t\tprint(f\"{models.name:<50} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\n",
    "\t\t# Scheduler step\n",
    "\t\tschedulers[i].step(avg_epoch_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 02:36:41 ] ***** Stage [1/1] ******************************************************************************************************************************************************\n",
      "[ 02:36:43 ] ----- Epoch [1/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.2033266645362455        | MAE: 0.1933763983580105        | MRE: 6175101.603659511         |\n",
      "[ 02:36:45 ] ----- Epoch [2/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.04957884548806898       | MAE: 0.1329738964021373        | MRE: 4241745.057257743         |\n",
      "[ 02:36:47 ] ----- Epoch [3/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.023205482205769592      | MAE: 0.08499887448250351       | MRE: 2961400.6460449444        |\n",
      "[ 02:36:49 ] ----- Epoch [4/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0422513143615508        | MAE: 0.11528850974835307       | MRE: 3870503.3827892314        |\n",
      "[ 02:36:51 ] ----- Epoch [5/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.022418029558597233      | MAE: 0.08173828377369727       | MRE: 2576952.2737555853        |\n",
      "[ 02:36:53 ] ----- Epoch [6/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.018715096668886697      | MAE: 0.07786766049348423       | MRE: 2509831.024762089         |\n",
      "[ 02:36:55 ] ----- Epoch [7/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.017180033450546323      | MAE: 0.07656688465499445       | MRE: 2603850.142747371         |\n",
      "[ 02:36:57 ] ----- Epoch [8/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.014277837310049122      | MAE: 0.0767227382708567        | MRE: 2507366.684626274         |\n",
      "[ 02:36:59 ] ----- Epoch [9/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.013386798227303532      | MAE: 0.07427287786847085       | MRE: 2511009.1043207985        |\n",
      "[ 02:37:01 ] ----- Epoch [10/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00943589601262402       | MAE: 0.05919361874220877       | MRE: 2101419.7493857793        |\n",
      "[ 02:37:03 ] ----- Epoch [11/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.010931214160932545      | MAE: 0.05858578738351481       | MRE: 1926387.947126511         |\n",
      "[ 02:37:06 ] ----- Epoch [12/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.007401911125468343      | MAE: 0.05473174259382886       | MRE: 1826692.2348923997        |\n",
      "[ 02:37:08 ] ----- Epoch [13/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.004584709575087301      | MAE: 0.048349662630761805      | MRE: 1667935.7430703149        |\n",
      "[ 02:37:10 ] ----- Epoch [14/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00723604332191402       | MAE: 0.05453644202501541       | MRE: 1826411.3687459175        |\n",
      "[ 02:37:12 ] ----- Epoch [15/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.005600554708006854      | MAE: 0.049870920078098825      | MRE: 1606581.6333060553        |\n",
      "[ 02:37:13 ] ----- Epoch [16/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0036837845882281314     | MAE: 0.04394663096130655       | MRE: 1401177.3820370378        |\n",
      "[ 02:37:15 ] ----- Epoch [17/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.004389759193737277      | MAE: 0.047696916528547226      | MRE: 1578282.3579154273        |\n",
      "[ 02:37:17 ] ----- Epoch [18/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.003970248116348643      | MAE: 0.04253554885063447       | MRE: 1367655.9197805817        |\n",
      "[ 02:37:19 ] ----- Epoch [19/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.004694368794027784      | MAE: 0.04528621400741525       | MRE: 1551566.4014492151        |\n",
      "[ 02:37:21 ] ----- Epoch [20/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0031742040841204566     | MAE: 0.041354480876228825      | MRE: 1353425.1552149167        |\n",
      "[ 02:37:23 ] ----- Epoch [21/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0029170712157156474     | MAE: 0.04003460026390884       | MRE: 1271315.060428035         |\n",
      "[ 02:37:25 ] ----- Epoch [22/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0026613011785391956     | MAE: 0.037906335385130205      | MRE: 1229522.9022010888        |\n",
      "[ 02:37:27 ] ----- Epoch [23/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0029897471614697994     | MAE: 0.04081546436504926       | MRE: 1295297.2890516315        |\n",
      "[ 02:37:29 ] ----- Epoch [24/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.003000222847682804      | MAE: 0.03946272530153494       | MRE: 1296429.1075046635        |\n",
      "[ 02:37:31 ] ----- Epoch [25/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.003245971590479455      | MAE: 0.041512314019657694      | MRE: 1346519.3381137925        |\n",
      "[ 02:37:33 ] ----- Epoch [26/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.003928313220261949      | MAE: 0.041177819655350174      | MRE: 1367714.7470837086        |\n",
      "[ 02:37:35 ] ----- Epoch [27/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0004151704051469149     | MAE: 0.013768091979853198      | MRE: 348802.79946009186        |\n",
      "[ 02:37:37 ] ----- Epoch [28/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0003281947171386593     | MAE: 0.012052217378126381      | MRE: 244133.16472819226        |\n",
      "[ 02:37:39 ] ----- Epoch [29/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0002699486073357731     | MAE: 0.010710480724891811      | MRE: 178134.10117174033        |\n",
      "[ 02:37:41 ] ----- Epoch [30/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0002509465970075213     | MAE: 0.010232202861391353      | MRE: 129783.7880683444         |\n",
      "[ 02:37:42 ] ----- Epoch [31/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0002282937904379395     | MAE: 0.009822144359136583      | MRE: 131602.04682567637        |\n",
      "[ 02:37:44 ] ----- Epoch [32/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00022484234803326993    | MAE: 0.009767594086637995      | MRE: 134115.81198253023        |\n",
      "[ 02:37:46 ] ----- Epoch [33/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00020937226968276043    | MAE: 0.009492293052348628      | MRE: 122610.82951776644        |\n",
      "[ 02:37:48 ] ----- Epoch [34/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00021459151222656922    | MAE: 0.009556129616409424      | MRE: 122740.14255179784        |\n",
      "[ 02:37:50 ] ----- Epoch [35/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001987525379573031     | MAE: 0.009250215069715174      | MRE: 119035.28717256941        |\n",
      "[ 02:37:52 ] ----- Epoch [36/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00019871503718386736    | MAE: 0.00921248581331377       | MRE: 122735.08453702785        |\n",
      "[ 02:37:54 ] ----- Epoch [37/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00019180234788127783    | MAE: 0.009131140757734853      | MRE: 114785.24699881788        |\n",
      "[ 02:37:56 ] ----- Epoch [38/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00017762608808395399    | MAE: 0.008803150675053568      | MRE: 106308.89035863789        |\n",
      "[ 02:37:58 ] ----- Epoch [39/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001810468371543584     | MAE: 0.00879643860030478       | MRE: 108835.15785793925        |\n",
      "[ 02:38:00 ] ----- Epoch [40/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00016854154125093467    | MAE: 0.008532921395289519      | MRE: 111762.1249853521         |\n",
      "[ 02:38:02 ] ----- Epoch [41/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00017471163704266295    | MAE: 0.008717020008673646      | MRE: 108733.64696421837        |\n",
      "[ 02:38:04 ] ----- Epoch [42/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00016329684904314222    | MAE: 0.008344955735053613      | MRE: 102860.21150439138        |\n",
      "[ 02:38:06 ] ----- Epoch [43/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00016723004561777053    | MAE: 0.008487702944107665      | MRE: 106673.13271861318        |\n",
      "[ 02:38:08 ] ----- Epoch [44/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00016320349009154778    | MAE: 0.008503160336923445      | MRE: 110129.23586880471        |\n",
      "[ 02:38:10 ] ----- Epoch [45/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00015929431580890389    | MAE: 0.008322266481262592      | MRE: 107326.33644501297        |\n",
      "[ 02:38:12 ] ----- Epoch [46/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00016551574766235266    | MAE: 0.008521743518113035      | MRE: 105413.2535053789         |\n",
      "[ 02:38:14 ] ----- Epoch [47/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00016386061708186693    | MAE: 0.008387354214546958      | MRE: 106967.85259079053        |\n",
      "[ 02:38:16 ] ----- Epoch [48/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001524700256678572     | MAE: 0.008184863523503116      | MRE: 108855.36256531127        |\n",
      "[ 02:38:18 ] ----- Epoch [49/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001565408875877968     | MAE: 0.008236363021263005      | MRE: 107351.70684346318        |\n",
      "[ 02:38:20 ] ----- Epoch [50/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00015949129578017192    | MAE: 0.00833052715683024       | MRE: 102790.0701008545         |\n",
      "[ 02:38:22 ] ----- Epoch [51/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001538236069798514     | MAE: 0.0082470978537322        | MRE: 108919.34210879102        |\n",
      "[ 02:38:24 ] ----- Epoch [52/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00015579187342688964    | MAE: 0.008249024185332191      | MRE: 103804.3920322089         |\n",
      "[ 02:38:26 ] ----- Epoch [53/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00014105352634262707    | MAE: 0.007328508615709439      | MRE: 39876.24301674564         |\n",
      "[ 02:38:27 ] ----- Epoch [54/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00014357047759702303    | MAE: 0.007333950514017479      | MRE: 40914.31245752065         |\n",
      "[ 02:38:29 ] ----- Epoch [55/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001366197797931883     | MAE: 0.007149063753236767      | MRE: 38992.383349903634        |\n",
      "[ 02:38:31 ] ----- Epoch [56/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013820292396701212    | MAE: 0.0071554256927095945     | MRE: 40649.47423178771         |\n",
      "[ 02:38:33 ] ----- Epoch [57/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013348669931432863    | MAE: 0.007050937695133442      | MRE: 38421.66946261908         |\n",
      "[ 02:38:35 ] ----- Epoch [58/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001360480221139427     | MAE: 0.0071618264127847366     | MRE: 38032.81137012413         |\n",
      "[ 02:38:37 ] ----- Epoch [59/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013025557247019884    | MAE: 0.006964036985640024      | MRE: 36335.62758363581         |\n",
      "[ 02:38:39 ] ----- Epoch [60/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001354176939719821     | MAE: 0.0071439156155528125     | MRE: 37019.1731741583          |\n",
      "[ 02:38:41 ] ----- Epoch [61/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013670389276062645    | MAE: 0.007140723055125927      | MRE: 36611.1390511502          |\n",
      "[ 02:38:43 ] ----- Epoch [62/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013044237245812422    | MAE: 0.006962977914252608      | MRE: 37732.049466300195        |\n",
      "[ 02:38:45 ] ----- Epoch [63/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00014712489474201499    | MAE: 0.0074068099165122605     | MRE: 41025.65833687377         |\n",
      "[ 02:38:47 ] ----- Epoch [64/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013385154787436774    | MAE: 0.007053276875575729      | MRE: 34749.84708794661         |\n",
      "[ 02:38:49 ] ----- Epoch [65/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001315750244819311     | MAE: 0.0070803476234486485     | MRE: 38007.26937652038         |\n",
      "[ 02:38:51 ] ----- Epoch [66/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013812568906382188    | MAE: 0.00715977831214459       | MRE: 36704.144990624634        |\n",
      "[ 02:38:53 ] ----- Epoch [67/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001321322109868002     | MAE: 0.006882964763964199      | MRE: 24762.422386711864        |\n",
      "[ 02:38:54 ] ----- Epoch [68/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001377986297019771     | MAE: 0.007067281349713968      | MRE: 24182.49670001961         |\n",
      "[ 02:38:56 ] ----- Epoch [69/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001367951427918708     | MAE: 0.00703728432531366       | MRE: 24398.47335757061         |\n",
      "[ 02:38:58 ] ----- Epoch [70/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013250582211695794    | MAE: 0.006945059659841479      | MRE: 24105.485628741462        |\n",
      "[ 02:39:00 ] ----- Epoch [71/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013774499376450163    | MAE: 0.00702905586282492       | MRE: 23756.297092191086        |\n",
      "[ 02:39:02 ] ----- Epoch [72/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013781578364171967    | MAE: 0.007059502282077293      | MRE: 23255.681904302128        |\n",
      "[ 02:39:04 ] ----- Epoch [73/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00012776247591242445    | MAE: 0.006847240843138012      | MRE: 23048.63988151626         |\n",
      "[ 02:39:07 ] ----- Epoch [74/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013795175778611967    | MAE: 0.00709000622369904       | MRE: 21933.2649151932          |\n",
      "[ 02:39:08 ] ----- Epoch [75/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013371497778410732    | MAE: 0.00695416316450143       | MRE: 22618.60961545097         |\n",
      "[ 02:39:10 ] ----- Epoch [76/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001378396062276857     | MAE: 0.00703161130320361       | MRE: 21124.97816133795         |\n",
      "[ 02:39:12 ] ----- Epoch [77/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013114835874524714    | MAE: 0.006863648537744321      | MRE: 19261.299173060233        |\n",
      "[ 02:39:14 ] ----- Epoch [78/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00012941597525555052    | MAE: 0.00682964096240469       | MRE: 20791.4356881216          |\n",
      "[ 02:39:16 ] ----- Epoch [79/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013050265038879838    | MAE: 0.0068627602586905714     | MRE: 21144.215711362354        |\n",
      "[ 02:39:18 ] ----- Epoch [80/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013588181308749381    | MAE: 0.006999882278050489      | MRE: 22129.488007436627        |\n",
      "[ 02:39:20 ] ----- Epoch [81/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00014128007276296376    | MAE: 0.0071071420216893035     | MRE: 22028.919102682612        |\n",
      "[ 02:39:22 ] ----- Epoch [82/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013445652182134539    | MAE: 0.006917656284087475      | MRE: 20857.11745850397         |\n",
      "[ 02:39:24 ] ----- Epoch [83/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001322777076267669     | MAE: 0.006910089982457606      | MRE: 21988.485447417283        |\n",
      "[ 02:39:26 ] ----- Epoch [84/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013736920046368296    | MAE: 0.0070074542440327165     | MRE: 22957.41201110682         |\n",
      "[ 02:39:28 ] ----- Epoch [85/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00012931945933761954    | MAE: 0.006814289020867125      | MRE: 20425.472735158957        |\n",
      "[ 02:39:30 ] ----- Epoch [86/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001310560776748985     | MAE: 0.0068218462472728544     | MRE: 22218.42683738199         |\n",
      "[ 02:39:32 ] ----- Epoch [87/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013630910941356408    | MAE: 0.007004096401399654      | MRE: 20057.43836782972         |\n",
      "[ 02:39:34 ] ----- Epoch [88/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001308160370918092     | MAE: 0.006828446807602191      | MRE: 20897.18905550735         |\n",
      "[ 02:39:36 ] ----- Epoch [89/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001377321747984424     | MAE: 0.007010809546039173      | MRE: 21057.263961143428        |\n",
      "[ 02:39:38 ] ----- Epoch [90/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013120596845161918    | MAE: 0.0068630008789497265     | MRE: 21392.2234469113          |\n",
      "[ 02:39:40 ] ----- Epoch [91/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001305863348090939     | MAE: 0.006879731889616785      | MRE: 20619.545541567666        |\n",
      "[ 02:39:41 ] ----- Epoch [92/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00012896572961919252    | MAE: 0.006771890101777798      | MRE: 21322.33058214077         |\n",
      "[ 02:39:43 ] ----- Epoch [93/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013492966516758157    | MAE: 0.006977543317784856      | MRE: 21951.111619740786        |\n",
      "[ 02:39:45 ] ----- Epoch [94/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013413293177203176    | MAE: 0.0069435212198294466     | MRE: 21366.745918072666        |\n",
      "[ 02:39:47 ] ----- Epoch [95/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013062337369109916    | MAE: 0.0068710276473407704     | MRE: 21083.733539201916        |\n",
      "[ 02:39:49 ] ----- Epoch [96/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013217098357464665    | MAE: 0.006888705805712252      | MRE: 23260.390896651432        |\n",
      "[ 02:39:51 ] ----- Epoch [97/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013116891961240616    | MAE: 0.0068439352625655455     | MRE: 21370.123692164285        |\n",
      "[ 02:39:53 ] ----- Epoch [98/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00014054518763372575    | MAE: 0.007106135371696925      | MRE: 19860.11106154147         |\n",
      "[ 02:39:55 ] ----- Epoch [99/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.0001291978436205026     | MAE: 0.0067945412354222055     | MRE: 20597.065400204945        |\n",
      "[ 02:39:57 ] ----- Epoch [100/100] ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     | MSE: 0.00013028171795055051    | MAE: 0.006868624826533733      | MRE: 21012.512177270957        |\n"
     ]
    }
   ],
   "source": [
    "for stage in range(num_stages):\n",
    "\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ***** Stage [{stage+1}/{num_stages}] {'*'*150}\")\n",
    "\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tepoch_mae = 0.\n",
    "\t\tepoch_mre = 0.\n",
    "\t\tepoch_mse = 0.\n",
    "\n",
    "\t\tfor X_batch, y_batch in train_loader:\n",
    "\t\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\t\t\tmodel.train()\n",
    "\n",
    "\t\t\toutputs = model(X_batch)\n",
    "\t\t\t# outputs = (outputs[:, 0] + outputs[:, 1] ) / 2\n",
    "\t\t\toutputs=outputs[:, 0]\n",
    "\t\t\ty = y_batch[:, 0]\n",
    "\n",
    "\t\t\t# Calculate losses\n",
    "\t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "\t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "\t\t\tmask = y >= 1e-10\n",
    "\t\t\ty_m = y[mask]\n",
    "\t\t\trelative_errors = torch.abs(outputs[mask] - y_m ) / y_m\n",
    "\t\t\tmre_loss = relative_errors.mean()\n",
    "\n",
    "\t\t\t# Backpropagation\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tmae_loss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t# Accumulate losses\n",
    "\t\t\tepoch_mse += mse_loss.item()\n",
    "\t\t\tepoch_mae += mae_loss.item()\n",
    "\t\t\tepoch_mre += mre_loss.item()\n",
    "\n",
    "\t\tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "\n",
    "\t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "\t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "\t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\n",
    "\t\tprint(f\"{model.name:<50} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\n",
    "\t\tscheduler.step(avg_epoch_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRE Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "# \t# Initialize epoch metrics for each model\n",
    "# \tepoch_mae = [0.] * len(models)\n",
    "# \tepoch_mre = [0.] * len(models)\n",
    "# \tepoch_mse = [0.] * len(models)\n",
    "\n",
    "# \tfor X_batch, y_batch in train_loader:\n",
    "# \t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "# \t\t# Loop over each model\n",
    "# \t\tfor i, model in enumerate(models):\n",
    "# \t\t\tmodel.train()\n",
    "\n",
    "# \t\t\t# Forward pass\n",
    "# \t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "# \t\t\toutputs = outputs[:, 0] + outputs[:, 1] / X_batch[:, 0]\n",
    "# \t\t\ty = y_batch[:, 0]\n",
    "\n",
    "# \t\t\t# Calculate losses\n",
    "# \t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "# \t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "# \t\t\trelative_errors = torch.abs(outputs - y) / (y + 1e-8)\n",
    "# \t\t\tmre_loss = relative_errors.mean()\n",
    "\n",
    "# \t\t\t# Backpropagation\n",
    "# \t\t\toptimizers.zero_grad()\n",
    "# \t\t\tmre_loss.backward()\n",
    "# \t\t\toptimizers.step()\n",
    "\n",
    "# \t\t\t# Accumulate losses for this model\n",
    "# \t\t\tepoch_mse += mse_loss.item()\n",
    "# \t\t\tepoch_mae += mae_loss.item()\n",
    "# \t\t\tepoch_mre += mre_loss.item()\n",
    "\n",
    "# \tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "# \t# Average metrics for each model\n",
    "# \tfor i in range(len(models)):\n",
    "# \t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "# \t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "# \t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\n",
    "# \t\tprint(f\"{models.name:<50} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\n",
    "# \t\t# Scheduler step\n",
    "# \t\tschedulers.step(avg_epoch_mre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "# \t# Initialize epoch metrics for each model\n",
    "# \tepoch_mae = [0.] * len(models)\n",
    "# \tepoch_mre = [0.] * len(models)\n",
    "# \tepoch_mse = [0.] * len(models)\n",
    "\n",
    "# \tfor X_batch, y_batch in train_loader:\n",
    "# \t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "# \t\t# Loop over each model\n",
    "# \t\tfor i, model in enumerate(models):\n",
    "# \t\t\tmodel.train()\n",
    "\n",
    "# \t\t\t# Forward pass\n",
    "# \t\t\toutputs = model(X_batch, X_batch[:, 0])\n",
    "# \t\t\toutputs = outputs[:, 0] + outputs[:, 1] / X_batch[:, 0]\n",
    "# \t\t\ty = y_batch[:, 0]\n",
    "\n",
    "# \t\t\t# Calculate losses\n",
    "# \t\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "# \t\t\tmae_loss = F.l1_loss(outputs, y)\n",
    "# \t\t\trelative_errors = torch.abs(outputs - y) / (y + 1e-8)\n",
    "# \t\t\tmre_loss = relative_errors.mean()\n",
    "\n",
    "# \t\t\t# Composite loss\n",
    "# \t\t\tcomposite_loss = (weights_mse * mse_loss +\n",
    "# \t\t\t\t\t\t\t  weights_mae * mae_loss +\n",
    "# \t\t\t\t\t\t\t  weights_mre * mre_loss)\n",
    "\n",
    "# \t\t\t# Backpropagation\n",
    "# \t\t\toptimizers.zero_grad()\n",
    "# \t\t\tcomposite_loss.backward()\n",
    "# \t\t\toptimizers.step()\n",
    "\n",
    "# \t\t\t# Accumulate losses for this model\n",
    "# \t\t\tepoch_mse += mse_loss.item()\n",
    "# \t\t\tepoch_mae += mae_loss.item()\n",
    "# \t\t\tepoch_mre += mre_loss.item()\n",
    "\n",
    "# \tprint(f\"[ {datetime.now().strftime(\"%H:%M:%S\")} ] ----- Epoch [{epoch+1}/{num_epochs}] {'-'*150}\")\n",
    "# \t# Compute average metrics for each model\n",
    "# \tfor i in range(len(models)):\n",
    "# \t\tavg_epoch_mse = epoch_mse / len(train_loader)\n",
    "# \t\tavg_epoch_mae = epoch_mae / len(train_loader)\n",
    "# \t\tavg_epoch_mre = epoch_mre / len(train_loader)\n",
    "\n",
    "# \t\tprint(f\"{models.name:<50} | MSE: {avg_epoch_mse:<25} | MAE: {avg_epoch_mae:<25} | MRE: {avg_epoch_mre:<25} |\")\n",
    "\n",
    "# \t\t# Update weights for loss adjustment\n",
    "# \t\tweights_mse = avg_epoch_mse / target_loss\n",
    "# \t\tweights_mae = avg_epoch_mae / target_loss\n",
    "# \t\tweights_mre = avg_epoch_mre / target_loss\n",
    "\n",
    "# \t\t# Scheduler step\n",
    "# \t\tschedulers.step(composite_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"models/{model.name}_mae_52.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = 'models'\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for model_name in [m for m in os.listdir(models_path) if m.endswith('pth')]:\n",
    "\tprint(model_name)\n",
    "\t# model = BlackScholesNet(input_size=5, hidden_size=128, output_size=2)\n",
    "\t# model.load_state_dict(torch.load(os.path.join(models_path, model_name)))\n",
    "\t# model.to(device)\n",
    "\n",
    "\t# models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BlackScholesNet(input_size=5, hidden_size=128, output_size=2)\n",
    "model.load_state_dict(torch.load(f\"models\\\\black.pth\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 20000\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_static_test_data(num_test_samples, 'static_test_data_m.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serpo\\AppData\\Local\\Temp\\ipykernel_4680\\2774688652.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_test_tensor, y_test_tensor = torch.load(file_name)\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor, y_test_tensor = load_static_test_data('static_test_data_m.pt')\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Black Model without activation                     Results | MSE: 4.2055868646587654e-07    | MAE: 0.00451268110162455       | Max AE: 0.08146280012130169       | MRE: 10940.277957825232        | Max RE: 9272840.882569332        \n"
     ]
    }
   ],
   "source": [
    "# Initialize metrics for each model\n",
    "test_losses = 0.\n",
    "test_maes = 0.\n",
    "test_max_aes = 0.\n",
    "test_mres = 0.\n",
    "test_max_res = 0.\n",
    "cnt = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "\tfor X_batch, y_batch in test_loader:\n",
    "\t\tX_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\t\t# Forward pass\n",
    "\t\toutputs = model(X_batch)\n",
    "\t\t# outputs = (outputs[:, 0] + outputs[:, 1]) / 2\n",
    "\t\toutputs = outputs[:, 0]\n",
    "\n",
    "\t\ty = y_batch[:, 0]\n",
    "\n",
    "\t\t# Mean Squared Error (MSE)\n",
    "\t\tmse_loss = F.mse_loss(outputs, y)\n",
    "\t\ttest_losses += mse_loss.item()\n",
    "\n",
    "\t\t# Mean Absolute Error (MAE)\n",
    "\t\tabs_errors = torch.abs(outputs - y)\n",
    "\t\ttest_maes += abs_errors.sum().item()\n",
    "\n",
    "\t\t# Maximum Absolute Error (Max AE)\n",
    "\t\tmax_ae = abs_errors.max().item()\n",
    "\t\ttest_max_aes = max(test_max_aes, max_ae)\n",
    "\n",
    "\t\t# Mean Relative Error (MRE)\n",
    "\t\tmask = y >= 1e-10\n",
    "\t\ty_m = y[mask]\n",
    "\t\trelative_errors = torch.abs(outputs[mask] - y_m ) / y_m\n",
    "\n",
    "\t\t# Calculate MRE\n",
    "\t\ttest_mres += relative_errors.sum().item()\n",
    "\t\tcnt += len(relative_errors)\n",
    "\n",
    "\t\t# Calculate max relative error\n",
    "\t\ttest_max_res = max(test_max_res, relative_errors.max().item())\n",
    "\n",
    "\n",
    "# Calculate the average metrics over all test samples for each model\n",
    "avg_test_loss = test_losses / len(test_loader.dataset)\n",
    "avg_test_mae = test_maes / len(test_loader.dataset)\n",
    "avg_test_mre = test_mres / cnt\n",
    "\n",
    "print('-'*250)\n",
    "print(f\"{model.name:<50} Results | MSE: {avg_test_loss:<25} | MAE: {avg_test_mae:<25} | Max AE: {test_max_aes:<25} | MRE: {avg_test_mre:<25} | Max RE: {test_max_res:<25}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model without activation\t\t\t\t\t Results | MSE: 6.318817860136378e-08\t | MAE: 0.0009265426649857153\t | Max AE: 0.06433858529715808\t   | MRE: 5802.172805252652\t\t | Max RE: 4261342.999367215  \n",
    "128 hid_sz m size of ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model without activation\t\t\t\t\t Results | MSE: 1.6209543008076999e-07\t| MAE: 0.0024346850476961745\t | Max AE: 0.07303780266972237\t   | MRE: 5075.648672021843\t\t | Max RE: 3539802.196658173\t\t\n",
    "64 hid_sz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black ResNet Model\t\t\t\t\t\t\t\t Results | MSE: 1.0580289371034923e-07\t| MAE: 0.0025658051734388544\t | Max AE: 0.05611778693486996\t   | MRE: 186458.27062391344\t\t| Max RE: 58482321.75801978   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black ResNet Model\t\t\t\t\t\t\t\t Results | MSE: 2.8335606296519785e-08\t| MAE: 0.0014160330767518587\t | Max AE: 0.007916218192563523\t  | MRE: 104935.5520285946\t\t | Max RE: 30905757.920977533  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model without activation\t\t\t\t\t Results | MSE: 1.124798628428752e-07\t | MAE: 0.0024631195551487453\t | Max AE: 0.037993997379657585\t  | MRE: 13487.431753687495\t\t| Max RE: 3748383.199971202\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 1.860992115070968e-09\t | MAE: 0.0004510874317589473\t | Max AE: 0.015712605802571444\t  | MRE: 3039.6012895961358\t\t| Max RE: 24053090.766225673\t   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 4.3176854823214384e-08\t| MAE: 0.002548539893560493\t  | Max AE: 0.02216988133309572\t   | MRE: 52930.97271546223\t\t | Max RE: 74994568.97747828\t\t\n",
    "\n",
    "\n",
    "weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 2.3365065048548754e-08\t| MAE: 0.0019228472067950922\t | Max AE: 0.020785850080788537\t  | MRE: 19540.95551665145\t\t | Max RE: 38428277.40361217\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Deep Model\t\t\t\t\t\t\t\t   Results | MSE: 1.2292241128713081e-08\t| MAE: 0.0014149500863335678\t | Max AE: 0.026046665725385276\t  | MRE: 15973.972288640323\t\t| Max RE: 13644321.567340782\t   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black CNN Model\t\t\t\t\t\t\t\t\tResults | MSE: 1.6229420763649162e-08\t| MAE: 0.0016403877602419335\t | Max AE: 0.02096367339459762\t   | MRE: 39130.069827259045\t\t| Max RE: 49456677.41935457\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black ResNet Model\t\t\t\t\t\t\t\t Results | MSE: 1.357335095783607e-07\t | MAE: 0.004738837337220532\t  | Max AE: 0.021764388623186998\t  | MRE: 147254.71198362616\t\t| Max RE: 146963541.83840838\t   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 1.6345862189413596e-07\t| MAE: 0.005929486075345317\t  | Max AE: 0.024445273630216757\t  | MRE: 308086.0669714369\t\t | Max RE: 102909205.05644394\t   \n",
    "\n",
    "\n",
    "hub no activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 6.311032924102108e-08\t | MAE: 0.0024049330370174466\t | Max AE: 0.0486327963291493\t\t| MRE: 0.17257685070773462\t   | Max RE: 13.89843139038193\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 4.767372257527874e-09\t | MAE: 0.0008842677848565959\t | Max AE: 0.010480693476281389\t  | MRE: 8610.273830920263\t\t | Max RE: 24765156.665712476   \n",
    "</br>\n",
    "delta 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 1.7072262899170862e-08\t| MAE: 0.0014622379697655967\t | Max AE: 0.012304333512939192\t  | MRE: 19133.356655940905\t\t| Max RE: 32084991.04810058\t\t\n",
    "</br>\n",
    "Huber loss delta = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 6.5584848876120205e-09\t| MAE: 0.0010204205638990932\t | Max AE: 0.01436321507469207\t   | MRE: 21704.53521771374\t\t | Max RE: 39553088.01572265\n",
    "</br>\n",
    "Huber loss delta = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 9.577022434796093e-09\t | MAE: 0.001128070044492659\t  | Max AE: 0.01750700016971668\t   | MRE: 0.0\t\t\t\t\t   | Max RE: 0.0   \n",
    "with grad norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 3.437281101835667e-08\t | MAE: 0.0014345937355705574\t | Max AE: 0.026702327077854637\t  | MRE: 0.0\t\t\t\t\t   | Max RE: 0.0\t\t  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 4.870335576499605e-09\t | MAE: 0.0006644182282886656\t | Max AE: 0.02035231469468729\t   | MRE: 0.0\t\t\t\t\t   | Max RE: 0.0\t "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 3.0745519796730916e-09\t| MAE: 0.0006669217488797097\t | Max AE: 0.01045388565348454\t   | MRE: 0.0\t\t\t\t\t   | Max RE: 0.0\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 5.394526925641141e-09\t | MAE: 0.0007469986503670395\t | Max AE: 0.024494726553518364\t  | MRE: 0.0\t\t\t\t\t   | Max RE: 0.0   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Black Model\t\t\t\t\t\t\t\t\t\tResults | MSE: 9.944437335789435e-10\t | MAE: 0.0002790903619311921\t | Max AE: 0.020291466710218475\t  | MRE: 0.0\t\t\t\t\t   | Max RE: 5.520420072604463e+31\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Base Model\t\t\t\t\t\t\t\t\t\t Results | MSE: 3.700808076204782e-09\t | MAE: 0.0006494232504191063\t | Max AE: 0.02520344930434637\t   | MRE: 207.39712310149338\t\t| Max RE: 115508.51118180675 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Normal\n",
    "\n",
    "def d1(K, T, sigma, F):\n",
    "\treturn (torch.log(F / K) + (0.5 * sigma**2) * T) / (sigma * torch.sqrt(T))\n",
    "\n",
    "def d2(d1, T, sigma):\n",
    "\treturn d1 - sigma * torch.sqrt(T)\n",
    "\n",
    "def delta(d1, F=1, option_type='call'):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\n",
    "\tif option_type == 'call':\n",
    "\t\treturn normal_dist.cdf(d1)\n",
    "\telif option_type == 'put':\n",
    "\t\treturn normal_dist.cdf(d1) - 1\n",
    "\telse:\n",
    "\t\traise ValueError(\"Option type must be 'call' or 'put'\")\n",
    "\n",
    "def gamma(T, sigma, d1, F=1):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\tpdf_d1 = torch.exp(normal_dist.log_prob(d1))\n",
    "\n",
    "\treturn pdf_d1 / (F * sigma * torch.sqrt(T))\n",
    "\n",
    "def theta(K, T, sigma, d1, d2, F=1, r=0, option_type='call'):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\tpdf_d1 = torch.exp(normal_dist.log_prob(d1))\n",
    "\n",
    "\tif option_type == 'call':\n",
    "\t\treturn (-F * pdf_d1 * sigma / (2 * torch.sqrt(T)) - r * K * torch.exp(-r * T) * normal_dist.cdf(d2))\n",
    "\telif option_type == 'put':\n",
    "\t\treturn (-F * pdf_d1 * sigma / (2 * torch.sqrt(T)) + r * K * torch.exp(-r * T) * normal_dist.cdf(-d2))\n",
    "\telse:\n",
    "\t\traise ValueError(\"Option type must be 'call' or 'put'\")\n",
    "\n",
    "def vega(T, d1, F=1):\n",
    "\tnormal_dist = Normal(0, 1)\n",
    "\tpdf_d1 = torch.exp(normal_dist.log_prob(d1))\n",
    "\n",
    "\treturn F * pdf_d1 * torch.sqrt(T)\n",
    "\n",
    "def greeks(K, T, sigma, F=1, r=0, option_type='call'):\n",
    "\tdp = d1(K, T, sigma, F)\n",
    "\tdm = d2(dp, T, sigma)\n",
    "\n",
    "\treturn delta(dp, F, option_type), gamma(T, sigma, dp, F), theta(K, T, sigma, dp, dm, F, r, option_type), vega(T, dp, F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 20000\n",
    "K = np.random.uniform(1, 2.5, num_samples)\n",
    "T = np.random.uniform(0.004, 4, num_samples)\n",
    "sigma = np.random.uniform(0.1, 0.5, num_samples)\n",
    "\n",
    "#  \n",
    "X = np.vstack((K, T, np.log(K), sigma * np.sqrt(T))).T\n",
    "# X = scaler.fit_transform(X)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "prices = torch.tensor(black_model(1, K, T, sigma), dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "greeks_result = greeks(X_tensor[:, 0],X_tensor[:, 1], X_tensor[:, 3] / torch.sqrt(X_tensor[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Black Scholes Net\n",
      "Mean Squared Error (MSE): 0.00019129475982090213\n",
      "Mean Absolute Error (MAE): 0.008392075799808637\n",
      "Max Absolute Error (MAE): 0.06874600830798266\n",
      "Mean Relative Error (MRE): 7803.016820621607\n",
      "Max Relative Error (MRE): 3614406.206458734\n"
     ]
    }
   ],
   "source": [
    "#    \n",
    "y = model(X_tensor)\n",
    "# y = (y[:, 0] + y[:, 1] ) / 2\n",
    "y = y[:, 0]\n",
    "\n",
    "abs_errors = torch.abs(y - prices)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "mse = F.mse_loss(y, prices).item()\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = F.l1_loss(y, prices)\n",
    "\n",
    "# Mean Relative Error (MRE)\n",
    "mask = prices >= 1e-10\n",
    "y_m = prices[mask]\n",
    "relative_errors = torch.abs(y[mask] - y_m ) / y_m\n",
    "mre = relative_errors.mean().item()\n",
    "max_mre = relative_errors.max().item()\n",
    "\n",
    "print(model.name)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae.item()}\")\n",
    "print(f\"Max Absolute Error (MAE): {abs_errors.max().item()}\")\n",
    "print(f\"Mean Relative Error (MRE): {mre}\")\n",
    "print(f\"Max Relative Error (MRE): {max_mre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#  seed  \n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses for current model:\n",
      "Delta:  0.042062057584169525\n",
      "Gamma:  0.4063527065205174\n",
      "Theta:  0.0013791814731462268\n",
      "Vega:  0.0542447592479735\n",
      "Optimized Black Scholes Net\n"
     ]
    }
   ],
   "source": [
    "model.zero_grad()  #   \n",
    "\n",
    "y = model(X_tensor)\n",
    "# y = (y[:, 0] + y[:, 1] ) / 2\n",
    "\n",
    "y.backward(torch.ones_like(y), retain_graph=True)\n",
    "K_grad = X_tensor.grad[:, 0].clone()\n",
    "T_grad = X_tensor.grad[:, 1].clone()\n",
    "sigma_grad = (X_tensor.grad[:, 3] / torch.sqrt(X_tensor[:, 1])).clone()\n",
    "\n",
    "X_tensor.grad.zero_()\n",
    "\n",
    "y = model(X_tensor)\n",
    "# y = (y[:, 0] + y[:, 1] ) / 2\n",
    "\n",
    "y.backward(torch.ones_like(y), retain_graph=True)\n",
    "delta_grad = X_tensor.grad[:, 0].clone().requires_grad_(True)\n",
    "\n",
    "X_tensor.grad.zero_()\n",
    "\n",
    "#    ()\n",
    "y = model(X_tensor)\n",
    "#y = (y[:, 0] + y[:, 1] ) / 2\n",
    "\n",
    "y.backward(torch.ones_like(y), retain_graph=True)\n",
    "delta_grad.backward(torch.ones_like(delta_grad), retain_graph=True)\n",
    "gamma_grad = X_tensor.grad[:, 0].clone()\n",
    "\n",
    "delta_loss = F.mse_loss(delta_grad, greeks_result[0]).item()\n",
    "gamma_loss = F.mse_loss(gamma_grad, greeks_result[1]).item()\n",
    "theta_loss = F.mse_loss(T_grad, greeks_result[2]).item()\n",
    "vega_loss = F.mse_loss(sigma_grad, greeks_result[3]).item()\n",
    "\n",
    "print(\"Losses for current model:\")\n",
    "print('Delta: ', delta_loss)\n",
    "print('Gamma: ', gamma_loss)\n",
    "print('Theta: ', theta_loss)\n",
    "print('Vega: ', vega_loss)\n",
    "\n",
    "print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.03840783685662016\n",
    "# Gamma:  0.3949252876906595\n",
    "# Theta:  0.0013525013536893962\n",
    "# Vega:  0.05303354700018913\n",
    "# Black Model without activation\n",
    "# 4 features 100 epochs 100k size of train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.07002200651184401\n",
    "# Gamma:  0.530716834946635\n",
    "# Theta:  0.0013875311415749527\n",
    "# Vega:  0.06860741523103477\n",
    "# Black Model without activation\n",
    "# 4 features 100 epochs 10k size of train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.06471299801971224\n",
    "# Gamma:  0.44321279099703076\n",
    "# Theta:  0.004059831016096307\n",
    "# Vega:  0.10431985297626094\n",
    "# Black ResNet Model\n",
    "# 64 hidden size and 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.07888154450938009\n",
    "# Gamma:  0.4840537113065917\n",
    "# Theta:  0.0014586058836390592\n",
    "# Vega:  0.07845643866992827\n",
    "# Black ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.09284443305834009\n",
    "# Gamma:  0.5210671480727084\n",
    "# Theta:  0.0013278433010317388\n",
    "# Vega:  0.07444485311843482\n",
    "# Black Model without activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.023927056489781124\n",
    "# Black Model without activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.04097502044021693\n",
    "# Black Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.23041457848259805\n",
    "# Black Model\n",
    "# weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.09470602026672634\n",
    "# Gamma:  0.4605984598995799\n",
    "# Black Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.07544267106592446\n",
    "# Gamma:  0.4395989266865998\n",
    "# Black Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for the RNN model:\n",
    "# Delta Loss:  0.08094750341367543\n",
    "# Gamma Loss:  0.4721712001137761"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.03421519741554771\n",
    "# Gamma:  0.37361078598119973\n",
    "# Black ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for current model:\n",
    "# Delta:  0.02984523250068021\n",
    "# Gamma:  0.32884577927187386 hub no act"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
